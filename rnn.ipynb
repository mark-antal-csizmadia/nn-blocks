{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from math import sqrt, ceil\n",
    "import datetime\n",
    "import sys\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import json\n",
    "import hyperopt\n",
    "\n",
    "from data_utils import load_cfar10_batch, load_label_names\n",
    "from losses import CategoricalHingeLoss, CategoricalCrossEntropyLoss\n",
    "from activations import LinearActivation, ReLUActivation, SoftmaxActivation, Activation\n",
    "from initializers import NormalInitializer, XavierInitializer\n",
    "from layers import Dense, BatchNormalization\n",
    "from regularizers import L2Regularizer\n",
    "from models import Model\n",
    "from metrics import AccuracyMetrics\n",
    "from optimizers import SGDOptimizer, Optimizer\n",
    "from lr_schedules import LRConstantSchedule, LRExponentialDecaySchedule, LRCyclingSchedule\n",
    "from grad_check import eval_numerical_gradient, eval_numerical_gradient_array, numerical_gradient_check_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPData():\n",
    "    def __init__(self, path_to_file):\n",
    "        \"\"\" Init.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        path_to_file : str\n",
    "            Path to text file.\n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        # read text file\n",
    "        with open(path_to_file, 'r') as f:\n",
    "            self.book_str = f.read()\n",
    "        \n",
    "        # str to chars\n",
    "        book_data = list(self.book_str)\n",
    "        # chars to unique chars\n",
    "        book_chars = list(set(book_data))\n",
    "        \n",
    "        # all chars as np\n",
    "        self.book_data = np.array(book_data)\n",
    "        # uniqe chars as np\n",
    "        self.book_chars = np.array(book_chars)\n",
    "    \n",
    "    def get_encoder(self,):\n",
    "        \"\"\" Returns encoder, i.e.: unique chars.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        book_chars : np.ndarray of shape (n_unique_chars, )\n",
    "            The encoder as np.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        return self.book_chars\n",
    "    \n",
    "    def char_to_idx(self, char):\n",
    "        \"\"\" Convert a char to an index from the encoder np array.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        char : str\n",
    "            A char.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            The index repre of char, of shape (,).\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        return np.argwhere(char == self.book_chars).flatten()[0]\n",
    "    \n",
    "    def idx_to_char(self, idx):\n",
    "        \"\"\" Convert an index to char in the encoder np array.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : int\n",
    "            The index repr of a char.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The char.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        return self.book_chars[idx]\n",
    "    \n",
    "    def encode(self, decoding):\n",
    "        \"\"\" Encode a sequence of chars into a sequence of indices based on the encoder.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        chars : np.ndarray\n",
    "            The sequence of chars, of shape (n_chars,)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        encoding : np.ndarray\n",
    "            The sequence of index representation of the chars, of shape (n_chars,)\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        encoding = []\n",
    "        \n",
    "        for d in decoding:\n",
    "            encoding.append(self.char_to_idx(d))\n",
    "            \n",
    "        encoding = np.array(encoding)\n",
    "        \n",
    "        return encoding\n",
    "    \n",
    "    def decode(self, encoding):\n",
    "        \"\"\" Decode a sequence of indices into a sequence of chars based on the encoder.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        encoding : np.ndarray\n",
    "            The sequence of index representation of the chars, of shape (n_chars,)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        decoding : np.ndarray\n",
    "            The sequence of chars, of shape (n_chars,)\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        decoding = []\n",
    "        \n",
    "        for e in encoding:\n",
    "            decoding.append(self.idx_to_char(e))\n",
    "            \n",
    "        decoding = np.array(decoding)\n",
    "        \n",
    "        return decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoder():\n",
    "    def __init__(self, length):\n",
    "        # length of one-hot encoding\n",
    "        self.length = length\n",
    "    \n",
    "    def __call__(self, x, encode=True):\n",
    "        \"\"\" Encode or decode a sequence x.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            The sequence of index representation of chars, of shape (n_chars,)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        e or d: np.ndarray\n",
    "            The sequence of one-hot encoded vectors of chars, of shape (n_chars, length)\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        if encode:\n",
    "            e = np.zeros((x.shape[0], self.length))\n",
    "            e[np.arange(x.shape[0]), x] = 1\n",
    "            return e.astype(int)\n",
    "        else:\n",
    "            d = np.argwhere(one_hot_encoding == 1)[:,1]\n",
    "            return d.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "\n",
    "Read, encode and decode data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80,)\n",
      "['y' 'N' 'D' 'e' '0' 's' '?' '\"' 'f' ' ' ';' '6' 'o' 'R' 'T' 'X' 't' ':'\n",
      " '.' '1' ')' 'n' '\\n' 'I' 'i' 'Y' 'V' '^' '\\t' '7' 'b' 'ü' 'w' 'j' 'l' 'g'\n",
      " 'B' 'k' '4' 'c' 'm' '(' 'Z' 'H' 'z' 'x' 'a' 'v' \"'\" 'u' 'W' 'h' '!' 'G'\n",
      " 'F' 'Q' 'K' '•' 'U' 'A' 'p' '3' 'd' '_' 'E' ',' 'L' 'S' 'M' '}' 'C' 'P'\n",
      " '2' 'r' '-' '/' 'O' '9' 'q' 'J']\n",
      "['H' 'A' 'R' 'R' 'Y' ' ' 'P' 'O' 'T' 'T' 'E' 'R' ' ' 'A' 'N' 'D' ' ' 'T'\n",
      " 'H' 'E' ' ' 'G' 'O' 'B' 'L' 'E' 'T' ' ' 'O' 'F' ' ' 'F' 'I' 'R' 'E' '\\n'\n",
      " '\\n' 'C' 'H' 'A' 'P' 'T' 'E' 'R' ' ' 'O' 'N' 'E' ' ' '-' ' ' 'T' 'H' 'E'\n",
      " ' ' 'R' 'I' 'D' 'D' 'L' 'E' ' ' 'H' 'O' 'U' 'S' 'E' '\\n' '\\n' '\\t' 'T'\n",
      " 'h' 'e' ' ' 'v' 'i' 'l' 'l' 'a' 'g' 'e' 'r' 's' ' ' 'o' 'f' ' ' 'L' 'i'\n",
      " 't' 't' 'l' 'e' ' ' 'H' 'a' 'n' 'g' 'l' 'e' 'r' 'o' 'n' ' ' 's' 't' 'i'\n",
      " 'l' 'l' ' ' 'c' 'a' 'l' 'l' 'e' 'd' ' ' 'i' 't' ' ' '\"' 't' 'h' 'e' ' '\n",
      " 'R' 'i' 'd' 'd' 'l' 'e' ' ' 'H' 'o' 'u' 's' 'e' ',' '\"' ' ' 'e' 'v' 'e'\n",
      " 'n' ' ' 't' 'h' 'o' 'u' 'g' 'h' ' ' 'i' 't' ' ' 'h' 'a' 'd' ' ' 'b' 'e'\n",
      " 'e' 'n' ' ' 'm' 'a' 'n' 'y' ' ' 'y' 'e' 'a' 'r' 's' ' ' 's' 'i' 'n' 'c'\n",
      " 'e' ' ' 't' 'h' 'e' ' ' 'R' 'i' 'd' 'd' 'l' 'e' ' ' 'f' 'a' 'm' 'i' 'l'\n",
      " 'y' ' ' 'h']\n",
      "(80,)\n",
      "[43 59 13 13 25  9 71 76 14 14 64 13  9 59  1  2  9 14 43 64  9 53 76 36\n",
      " 66 64 14  9 76 54  9 54 23 13 64 22 22 70 43 59 71 14 64 13  9 76  1 64\n",
      "  9 74  9 14 43 64  9 13 23  2  2 66 64  9 43 76 58 67 64 22 22 28 14 51\n",
      "  3  9 47 24 34 34 46 35  3 73  5  9 12  8  9 66 24 16 16 34  3  9 43 46\n",
      " 21 35 34  3 73 12 21  9  5 16 24 34 34  9 39 46 34 34  3 62  9 24 16  9\n",
      "  7 16 51  3  9 13 24 62 62 34  3  9 43 12 49  5  3 65  7  9  3 47  3 21\n",
      "  9 16 51 12 49 35 51  9 24 16  9 51 46 62  9 30  3  3 21  9 40 46 21  0\n",
      "  9  0  3 46 73  5  9  5 24 21 39  3  9 16 51  3  9 13 24 62 62 34  3  9\n",
      "  8 46 40 24 34  0  9 51]\n",
      "['H' 'A' 'R' 'R' 'Y' ' ' 'P' 'O' 'T' 'T' 'E' 'R' ' ' 'A' 'N' 'D' ' ' 'T'\n",
      " 'H' 'E' ' ' 'G' 'O' 'B' 'L' 'E' 'T' ' ' 'O' 'F' ' ' 'F' 'I' 'R' 'E' '\\n'\n",
      " '\\n' 'C' 'H' 'A' 'P' 'T' 'E' 'R' ' ' 'O' 'N' 'E' ' ' '-' ' ' 'T' 'H' 'E'\n",
      " ' ' 'R' 'I' 'D' 'D' 'L' 'E' ' ' 'H' 'O' 'U' 'S' 'E' '\\n' '\\n' '\\t' 'T'\n",
      " 'h' 'e' ' ' 'v' 'i' 'l' 'l' 'a' 'g' 'e' 'r' 's' ' ' 'o' 'f' ' ' 'L' 'i'\n",
      " 't' 't' 'l' 'e' ' ' 'H' 'a' 'n' 'g' 'l' 'e' 'r' 'o' 'n' ' ' 's' 't' 'i'\n",
      " 'l' 'l' ' ' 'c' 'a' 'l' 'l' 'e' 'd' ' ' 'i' 't' ' ' '\"' 't' 'h' 'e' ' '\n",
      " 'R' 'i' 'd' 'd' 'l' 'e' ' ' 'H' 'o' 'u' 's' 'e' ',' '\"' ' ' 'e' 'v' 'e'\n",
      " 'n' ' ' 't' 'h' 'o' 'u' 'g' 'h' ' ' 'i' 't' ' ' 'h' 'a' 'd' ' ' 'b' 'e'\n",
      " 'e' 'n' ' ' 'm' 'a' 'n' 'y' ' ' 'y' 'e' 'a' 'r' 's' ' ' 's' 'i' 'n' 'c'\n",
      " 'e' ' ' 't' 'h' 'e' ' ' 'R' 'i' 'd' 'd' 'l' 'e' ' ' 'f' 'a' 'm' 'i' 'l'\n",
      " 'y' ' ' 'h']\n"
     ]
    }
   ],
   "source": [
    "path_to_file = \"data/hp/goblet_book.txt\"\n",
    "hpdata = HPData(path_to_file=path_to_file)\n",
    "print(hpdata.get_encoder().shape)\n",
    "print(hpdata.get_encoder())\n",
    "x = hpdata.book_data[:200]\n",
    "print(x)\n",
    "encoding = hpdata.encode(x)\n",
    "print(hpdata.get_encoder().shape)\n",
    "print(encoding)\n",
    "decoding = hpdata.decode(encoding)\n",
    "print(decoding)\n",
    "\n",
    "np.testing.assert_array_equal(decoding, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-ho encode and decode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 80)\n",
      "(200,)\n",
      "76\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0]\n",
      "70\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "onehot_encoder = OneHotEncoder(length=hpdata.get_encoder().size)\n",
    "one_hot_encoding = onehot_encoder(encoding, encode=True)\n",
    "print(one_hot_encoding.shape)\n",
    "one_hot_decoding = onehot_encoder(one_hot_encoding, encode=False)\n",
    "print(one_hot_decoding.shape)\n",
    "\n",
    "np.testing.assert_array_equal(one_hot_decoding, encoding)\n",
    "print(one_hot_decoding[7])\n",
    "print(one_hot_encoding[7])\n",
    "\n",
    "print(one_hot_decoding[37])\n",
    "print(one_hot_encoding[37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.' 'a']\n",
      "(80,)\n",
      "[18 46]\n",
      "['.' 'a']\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]]\n",
      "(2, 80)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[46]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([\".\", \"a\"])\n",
    "print(x)\n",
    "encoding = hpdata.encode(x)\n",
    "print(hpdata.get_encoder().shape)\n",
    "print(encoding)\n",
    "decoding = hpdata.decode(encoding)\n",
    "print(decoding)\n",
    "\n",
    "np.testing.assert_array_equal(decoding, x)\n",
    "\n",
    "one_hot_encoding = onehot_encoder(encoding, encode=True)\n",
    "print(one_hot_encoding)\n",
    "print(one_hot_encoding.shape)\n",
    "np.argwhere(hpdata.get_encoder() == \"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TanhActivation(Activation):\n",
    "    \"\"\" Tanh activation.\n",
    "    Can be followed by virtually anything.\n",
    "    Inherits everything from class Activation.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    cache : dict\n",
    "        Run-time cache of attibutes such as gradients.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __init__()\n",
    "        Constuctor.\n",
    "    forward(z)\n",
    "        Activates the linear transformation of the layer, and\n",
    "        forward propagates activation. Activation is tanh.\n",
    "    backward(g)\n",
    "        Backpropagates incoming gradient into the layer, based on the tanh activation.\n",
    "    __repr__()\n",
    "        Returns the string representation of class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ):\n",
    "        \"\"\" Constructor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\" Activates the linear transformation of the layer, and\n",
    "        forward propagates activation. Activation is tanh.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : numpy.ndarray\n",
    "            Linear transformation of layer.\n",
    "            Shape is unknown here, but will usually be\n",
    "            (batch size, this layer output dim = next layer input dim)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            ReLU activation.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        a = np.tanh(z)\n",
    "        self.cache[\"a\"] = deepcopy(a)\n",
    "        return a\n",
    "\n",
    "    def backward(self, g_in):\n",
    "        \"\"\" Backpropagates incoming gradient into the layer, based on the tanh activation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        g_in : numpy.ndarray\n",
    "            Incoming gradient to the activation.\n",
    "            Shape is unknown here, but will usually be\n",
    "            (batch size, this layer output dim = next layer input dim)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Gradient of activation.\n",
    "            Shape is unknown here, but will usually be\n",
    "            (batch size, this layer output dim = next layer input dim)\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        a = deepcopy(self.cache[\"a\"])\n",
    "        g_out = (1 - np.power(a, 2)) * g_in\n",
    "        return g_out\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\" Returns the string representation of class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        repr_str : str\n",
    "            The string representation of the class.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        repr_str = \"tanh\"\n",
    "        return repr_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_relu_activation passed\n"
     ]
    }
   ],
   "source": [
    "def test_tanh_activation():\n",
    "    \n",
    "    tanh_activation = TanhActivation()\n",
    "    np.random.seed(231)\n",
    "    x = np.random.randn(5, 10)\n",
    "    g_in = np.random.randn(*x.shape)\n",
    "    fx = lambda x: TanhActivation.forward(tanh_activation, x)\n",
    "    g_out_num = eval_numerical_gradient_array(fx, x, g_in)\n",
    "    g_out = tanh_activation.backward(g_in)\n",
    "    np.testing.assert_array_almost_equal(g_out, g_out_num, decimal=6)\n",
    "\n",
    "    print(\"test_relu_activation passed\")\n",
    "    \n",
    "test_tanh_activation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN():\n",
    "    \"\"\" Many-to-many.\"\"\"\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim, \n",
    "                 kernel_h_initializer, bias_h_initializer,\n",
    "                 kernel_o_initializer, bias_o_initializer,\n",
    "                 kernel_regularizer, \n",
    "                 activation_h, activation_o):\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_h_initializer = kernel_h_initializer\n",
    "        self.bias_h_initializer = bias_h_initializer\n",
    "        self.kernel_o_initializer = kernel_o_initializer\n",
    "        self.bias_o_initializer = bias_o_initializer\n",
    "\n",
    "        self.u = kernel_h_initializer.initialize(size=(in_dim, hidden_dim))\n",
    "        self.w = kernel_h_initializer.initialize(size=(hidden_dim, hidden_dim))\n",
    "        self.b = bias_h_initializer.initialize(size=(1, hidden_dim))\n",
    "        \n",
    "        self.v = kernel_o_initializer.initialize(size=(hidden_dim, out_dim))\n",
    "        self.c = bias_o_initializer.initialize(size=(1, out_dim))\n",
    "        \n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        self.activation_h = activation_h\n",
    "        self.activation_o = activation_o\n",
    "\n",
    "        self.cache = {}\n",
    "        self.grads = {}\n",
    "        \n",
    "        self.h_shape = (1, hidden_dim)\n",
    "        self.cache[\"h\"] = np.zeros(self.h_shape)\n",
    "\n",
    "        self.has_learnable_params = True\n",
    "    \n",
    "    def forward(self, x, **params):\n",
    "        h = deepcopy(self.cache[\"h\"])\n",
    "        #h = np.zeros(self.h_shape)\n",
    "        self.cache[\"x\"] = deepcopy(x)\n",
    "        #h = np.zeros(self.h_shape)\n",
    "        h_concat = np.zeros((x.shape[0], h.shape[1]))\n",
    "        a_concat = np.zeros((x.shape[0], h.shape[1]))\n",
    "        assert h.shape == (1, self.hidden_dim)\n",
    "        \n",
    "        for idx, x_ in enumerate(x):\n",
    "            x_ = x_.reshape(1,-1)\n",
    "            assert x_.shape == (1,self.in_dim)\n",
    "            a = np.dot(x_, self.u) + np.dot(h, self.w) + self.b\n",
    "            a_concat[idx] = a.reshape(1,-1)\n",
    "            assert a.shape == (1, self.hidden_dim)\n",
    "            h = self.activation_h.forward(a)\n",
    "            #print(self.activation_h.cache[\"a\"].shape)\n",
    "            h_concat[idx] = deepcopy(h)\n",
    "            assert h.shape == (1, self.hidden_dim)\n",
    "        \n",
    "        # assure good dims for backprop -> only used for 1 vector, so should be ok\n",
    "        # assure good dims for backprop\n",
    "        #h_concat_2 = self.activation_h.forward(a_concat)\n",
    "        #print(self.activation_h.cache[\"a\"].shape)\n",
    "        #np.testing.assert_array_equal(h_concat, h_concat_2)\n",
    "        self.cache[\"h\"] = deepcopy(h)\n",
    "        self.cache[\"h_concat\"] = deepcopy(h_concat)\n",
    "        self.cache[\"a_concat\"] = deepcopy(a_concat)\n",
    "        assert h_concat.shape == (x.shape[0], h.shape[1])\n",
    "        o = np.dot(h_concat, self.v) + self.c\n",
    "        assert o.shape == (x.shape[0], self.out_dim), f\"o.shape={o.shape}\"\n",
    "        p = self.activation_o.forward(o)\n",
    "        #print(self.activation_o.cache[\"a\"].shape)\n",
    "        \n",
    "        assert p.shape == (x.shape[0], self.out_dim)\n",
    "        return p\n",
    "    \n",
    "    def backward(self, g_in, **params):\n",
    "        # x.shape = (x.shape[0], in_dim)\n",
    "        x = deepcopy(self.cache[\"x\"])\n",
    "        # h_concat.shape = (x.shape[0], hidden_dim)\n",
    "        h_concat = deepcopy(self.cache[\"h_concat\"])\n",
    "        a_concat = deepcopy(self.cache[\"a_concat\"])\n",
    "        \n",
    "        # g_in.shape = (batch_size, )\n",
    "        assert g_in.shape == (x.shape[0], ), f\"g_in.shape={g_in.shape}\"\n",
    "        # g_a_o.shape = (batch_size, out_dim)\n",
    "        g_a_o = self.activation_o.backward(g_in)\n",
    "        assert g_a_o.shape == (x.shape[0], self.out_dim)\n",
    "        \n",
    "        # g_h_concat.shape = (batch_size, hidden_dim)\n",
    "        g_h_concat = np.zeros((x.shape[0], self.hidden_dim))\n",
    "        \n",
    "        # v.shape = (hidden_dim, out_dim)\n",
    "        # (1,hidden_dim) = (1,out_dim) * (hidden_dim, out_dim).T\n",
    "        g_h_concat[-1] = np.dot(g_a_o[-1].reshape(1,-1), self.v.T)\n",
    "        assert np.dot(g_a_o[-1].reshape(1,-1), self.v.T).shape == (1,self.hidden_dim)\n",
    "        \n",
    "        g_a = np.zeros((x.shape[0], self.hidden_dim))\n",
    "        # (1, hidden_dim) = (1, hidden_dim) * (1, hidden_dim)\n",
    "        # change cache\n",
    "        _ = self.activation_h.forward(a_concat[-1].reshape(1,-1))\n",
    "        g_a[-1] = self.activation_h.backward(g_h_concat[-1]).reshape(1,-1)\n",
    "        assert self.activation_h.backward(g_h_concat[-1].reshape(1,-1)).shape == (1, self.hidden_dim)\n",
    "        \n",
    "        for t in reversed(range(x.shape[0]-1)):\n",
    "            # (1,hidden_dim) = (1,out_dim) * (hidden_dim, out_dim).T\n",
    "            # \\+ (1,hidden_dim) * (hidden_dim, hidden_dim), maybe w.T?\n",
    "            g_h_concat[t] = np.dot(g_a_o[t].reshape(1,-1), self.v.T) \\\n",
    "                + np.dot(g_a[t+1].reshape(1,-1), self.w)\n",
    "            # change cache\n",
    "            _ = self.activation_h.forward(a_concat[t].reshape(1,-1))\n",
    "            g_a[t] = self.activation_h.backward(g_h_concat[t])\n",
    "            assert self.activation_h.backward(g_h_concat[t]).shape == (1, self.hidden_dim)\n",
    "        \n",
    "        #print(g_h_concat)\n",
    "        assert g_h_concat.shape == (x.shape[0], self.hidden_dim)\n",
    "        assert g_a.shape == (x.shape[0], self.hidden_dim)\n",
    "        \n",
    "        # (hidden_dim, out_dim) = (x.shape[0], hidden_dim).T * (x.shape[0], out_dim)\n",
    "        g_v = np.dot(h_concat.T, g_a_o)\n",
    "        assert g_v.shape == (self.hidden_dim, self.out_dim)\n",
    "        self.grads[\"dv\"] = deepcopy(g_v)\n",
    "        \n",
    "        # Auxiliar h matrix that includes h_prev\n",
    "        h_aux = np.zeros(h_concat.shape)\n",
    "        #h_init = np.zeros((1, self.hidden_dim))\n",
    "        #h_aux[0, :] = h_init\n",
    "        h_aux[0] = h_concat[-1].reshape(1,-1)\n",
    "        h_aux[1:] = h_concat[0:-1]\n",
    "        assert h_aux.shape == (x.shape[0], self.hidden_dim)\n",
    "        \n",
    "        # (hidden_dim, hidden_dim) = (x.shape[0], hidden_dim).T * (x.shape[0], hidden_dim)\n",
    "        g_w = np.dot(h_aux.T, g_a)\n",
    "        assert g_w.shape == (self.hidden_dim, self.hidden_dim)\n",
    "        self.grads[\"dw\"] = deepcopy(g_w)\n",
    "        \n",
    "        # (in_dim, hidden_dim) = (x.shape[0], in_dim).T * (x.shape[0], hidden_dim)\n",
    "        g_u = np.dot(x.T, g_a)\n",
    "        assert g_u.shape == (self.in_dim, self.hidden_dim)\n",
    "        self.grads[\"du\"] = deepcopy(g_u)\n",
    "        \n",
    "        # (1, hidden_dim) = sum((x.shape[0], self.hidden_dim), axis=0)\n",
    "        g_b = np.sum(g_a, axis=0).reshape(1,-1)\n",
    "        assert g_b.shape == (1, self.hidden_dim), f\"g_b.shape={g_b.shape}\"\n",
    "        self.grads[\"db\"] = deepcopy(g_b)\n",
    "        \n",
    "        # (1, out_dim) = sum((x.shape[0], self.out_dim), axis=0)\n",
    "        g_c = np.sum(g_a_o, axis=0).reshape(1,-1)\n",
    "        assert g_c.shape == (1, self.out_dim)\n",
    "        self.grads[\"dc\"] = deepcopy(g_c)\n",
    "        \n",
    "        # compute downstream grad!\n",
    "        return None\n",
    "        \n",
    "    def if_has_learnable_params(self, ):    \n",
    "        return self.has_learnable_params\n",
    "    \n",
    "    def get_u(self, ):\n",
    "        return deepcopy(self.u)\n",
    "\n",
    "    def get_w(self, ):\n",
    "        return deepcopy(self.w)\n",
    "    \n",
    "    def get_b(self, ):\n",
    "        return deepcopy(self.b)\n",
    "    \n",
    "    def get_v(self, ):\n",
    "        return deepcopy(self.v)\n",
    "    \n",
    "    def get_c(self, ):\n",
    "        return deepcopy(self.c)\n",
    "\n",
    "    def get_learnable_params(self):\n",
    "        return {\n",
    "            \"u\": self.get_u(), \"w\": self.get_w(), \"b\": self.get_b(), \n",
    "            \"v\": self.get_v(), \"c\": self.get_c()\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def set_u(self, u):\n",
    "        self.u = deepcopy(u)\n",
    "\n",
    "    def set_w(self, w):\n",
    "        self.w = deepcopy(w)\n",
    "    \n",
    "    def set_b(self, b):\n",
    "        self.b = deepcopy(b)\n",
    "    \n",
    "    def set_v(self, v):\n",
    "        self.v = deepcopy(v)\n",
    "    \n",
    "    def set_c(self, c):\n",
    "        self.c = deepcopy(c)\n",
    "\n",
    "    def set_learnable_params(self, **learnable_params):\n",
    "        self.set_u(learnable_params[\"u\"])\n",
    "        self.set_w(learnable_params[\"w\"])\n",
    "        self.set_b(learnable_params[\"b\"])\n",
    "        self.set_v(learnable_params[\"v\"])\n",
    "        self.set_c(learnable_params[\"c\"])\n",
    "\n",
    "    def get_du(self, ):\n",
    "        if \"du\" in self.grads.keys():\n",
    "            du = self.grads[\"du\"]\n",
    "            ret = deepcopy(du)\n",
    "        else:\n",
    "            ret = None\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    def get_dw(self, ):\n",
    "        if \"dw\" in self.grads.keys():\n",
    "            dw = self.grads[\"dw\"]\n",
    "            ret = deepcopy(dw)\n",
    "        else:\n",
    "            ret = None\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def get_db(self, ):\n",
    "        if \"db\" in self.grads.keys():\n",
    "            db = self.grads[\"db\"]\n",
    "            ret = deepcopy(db)\n",
    "        else:\n",
    "            ret = None\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    def get_dv(self, ):\n",
    "        if \"dv\" in self.grads.keys():\n",
    "            dv = self.grads[\"dv\"]\n",
    "            ret = deepcopy(dv)\n",
    "        else:\n",
    "            ret = None\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    def get_dc(self, ):\n",
    "        if \"dc\" in self.grads.keys():\n",
    "            dc = self.grads[\"dc\"]\n",
    "            ret = deepcopy(dc)\n",
    "        else:\n",
    "            ret = None\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def get_learnable_params_grads(self):\n",
    "        return {\n",
    "            \"du\": self.get_du(), \"dw\": self.get_dw(), \"db\": self.get_db(),\n",
    "            \"dv\": self.get_dv(), \"dc\": self.get_dc()\n",
    "        }\n",
    "    \n",
    "    def if_has_learnable_params(self, ):\n",
    "        return self.has_learnable_params\n",
    "        \n",
    "    def get_reg_loss(self, ):\n",
    "        return 0.0\n",
    "    \n",
    "    def __repr__(self, ):\n",
    "        repr_str = \"rnn: \\n\" \\\n",
    "                   + f\"\\t shape -- in: {self.in_dim}, out: {self.out_dim}, hidden: {self.hidden_dim}\\n\" \\\n",
    "                   + \"\\t u -- init: \" + self.kernel_h_initializer.__repr__() + \"\\n\" \\\n",
    "                    + \"\\t w -- init: \" + self.kernel_h_initializer.__repr__() + \"\\n\" \\\n",
    "                    + \"\\t b -- init: \" + self.bias_h_initializer.__repr__() + \"\\n\" \\\n",
    "                    + \"\\t v -- init: \" + self.kernel_o_initializer.__repr__() + \"\\n\" \\\n",
    "                    + \"\\t c -- init: \" + self.bias_o_initializer.__repr__() + \"\\n\" \\\n",
    "                   + \", reg: \" + self.kernel_regularizer.__repr__() + \"\\n\" \\\n",
    "                   + \"\\t activation: \\n \\t hidden: \" + self.activation_h.__repr__() \\\n",
    "                    + \"\\t out: \" + self.activation_o.__repr__() + \"\\n\"\n",
    "        return repr_str\n",
    "    \n",
    "    \n",
    "class Synhthetizer():\n",
    "    def __init__(self, rnn, onehot_encoder):\n",
    "        self.rnn = rnn\n",
    "        self.onehot_encoder = onehot_encoder\n",
    "        self.h_concat = np.zeros(rnn.h_shape)\n",
    "    \n",
    "    def sample(self, lenght, p):\n",
    "        # select character from softmax weighted dist over all chars\n",
    "        return np.random.choice(range(lenght), size=1, replace=True, p=p.flatten())\n",
    "        \n",
    "    \n",
    "    def __call__(self, ts, init_idx):\n",
    "        \n",
    "        x = self.onehot_encoder(np.array([init_idx]).T, encode=True)\n",
    "        #print(x.shape)\n",
    "        assert x.shape == (1, self.onehot_encoder.length)\n",
    "        sequence = []\n",
    "        \n",
    "        for t in range(ts):\n",
    "            p = rnn.forward(x)\n",
    "            x_idx = self.sample(lenght=x.shape[1], p=p)\n",
    "            sequence.append(x_idx)\n",
    "            x = self.onehot_encoder(np.array([x_idx]).T, encode=True)\n",
    "    \n",
    "        return np.array(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad test\n",
    "\n",
    "Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn: \n",
      "\t shape -- in: 80, out: 80, hidden: 5\n",
      "\t u -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      "\t w -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      "\t b -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      "\t v -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      "\t c -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      ", reg: None\n",
      "\t activation: \n",
      " \t hidden: tanh\t out: softmax\n",
      "\n",
      "layer=0, param_name=u\n",
      "max rel error=1.029675697850065\n",
      "layer=0, param_name=w\n",
      "max rel error=0.3160885048728114\n",
      "layer=0, param_name=b\n",
      "max rel error=0.13922054137422935\n",
      "layer=0, param_name=v\n",
      "max rel error=0.07527885738375795\n",
      "layer=0, param_name=c\n",
      "max rel error=7.442389559908849e-07\n",
      "test_grad_check passed\n"
     ]
    }
   ],
   "source": [
    "init_params = {\"coeff\": 1.0, \"mean\": 0.0, \"std\": 0.01}\n",
    "kernel_h_initializer = NormalInitializer(seed=None, **init_params)\n",
    "bias_h_initializer = NormalInitializer(seed=None, **init_params)\n",
    "kernel_o_initializer = NormalInitializer(seed=None, **init_params)\n",
    "bias_o_initializer = NormalInitializer(seed=None, **init_params)\n",
    "kernel_regularizer = None\n",
    "\n",
    "num_inputs = 10\n",
    "size = (num_inputs, hpdata.get_encoder().size)\n",
    "x = np.eye(hpdata.get_encoder().size)\n",
    "x = x[np.random.choice(x.shape[0], size=num_inputs)].astype(int)\n",
    "y = np.random.randint(hpdata.get_encoder().size, size=num_inputs)\n",
    "\n",
    "loss = CategoricalCrossEntropyLoss()\n",
    "\n",
    "rnn = RNN(in_dim=hpdata.get_encoder().size, out_dim=hpdata.get_encoder().size, hidden_dim=5, \n",
    "          kernel_h_initializer=kernel_h_initializer, \n",
    "          bias_h_initializer=bias_h_initializer, \n",
    "          kernel_o_initializer=kernel_o_initializer, \n",
    "          bias_o_initializer=bias_o_initializer, \n",
    "          kernel_regularizer=kernel_regularizer, \n",
    "          activation_h=TanhActivation(),\n",
    "          activation_o=SoftmaxActivation())\n",
    "\n",
    "print(rnn)\n",
    "\n",
    "layers = [rnn]\n",
    "model = Model(layers)\n",
    "\n",
    "numerical_gradient_check_model(x, y, model, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn: \n",
      "\t shape -- in: 80, out: 80, hidden: 5\n",
      "\t u -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      "\t w -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      "\t b -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      "\t v -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      "\t c -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      ", reg: None\n",
      "\t activation: \n",
      " \t hidden: tanh\t out: softmax\n",
      "\n",
      "layer=0, param_name=u\n",
      "max rel error=0.9991201335429951\n",
      "layer=0, param_name=w\n",
      "max rel error=0.28616183224165476\n",
      "layer=0, param_name=b\n",
      "max rel error=0.06945003837135688\n",
      "layer=0, param_name=v\n",
      "max rel error=0.057508019434850434\n",
      "layer=0, param_name=c\n",
      "max rel error=5.66662256653852e-07\n",
      "test_grad_check passed\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "x_chars = hpdata.book_data[:batch_size]\n",
    "y_chars = hpdata.book_data[1:batch_size+1]\n",
    "x_encoding = hpdata.encode(x_chars)\n",
    "y_encoding = hpdata.encode(y_chars)\n",
    "onehot_encoder = OneHotEncoder(length=hpdata.get_encoder().size)\n",
    "x_train = onehot_encoder(x_encoding, encode=True)\n",
    "y_train = y_encoding\n",
    "\n",
    "init_params = {\"coeff\": 1.0, \"mean\": 0.0, \"std\": 0.01}\n",
    "kernel_h_initializer = NormalInitializer(seed=None, **init_params)\n",
    "bias_h_initializer = NormalInitializer(seed=None, **init_params)\n",
    "kernel_o_initializer = NormalInitializer(seed=None, **init_params)\n",
    "bias_o_initializer = NormalInitializer(seed=None, **init_params)\n",
    "kernel_regularizer = None\n",
    "\n",
    "num_inputs = batch_size\n",
    "\n",
    "loss = CategoricalCrossEntropyLoss()\n",
    "\n",
    "rnn = RNN(in_dim=hpdata.get_encoder().size, out_dim=hpdata.get_encoder().size, hidden_dim=5, \n",
    "          kernel_h_initializer=kernel_h_initializer, \n",
    "          bias_h_initializer=bias_h_initializer, \n",
    "          kernel_o_initializer=kernel_o_initializer, \n",
    "          bias_o_initializer=bias_o_initializer, \n",
    "          kernel_regularizer=kernel_regularizer, \n",
    "          activation_h=TanhActivation(),\n",
    "          activation_o=SoftmaxActivation())\n",
    "\n",
    "print(rnn)\n",
    "\n",
    "layers = [rnn]\n",
    "model = Model(layers)\n",
    "\n",
    "numerical_gradient_check_model(x_train, y_train, model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGradOptimizer(Optimizer):\n",
    "    \"\"\" Stochastic gradient descent optimizer.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    lr_schedule : LRSchedule\n",
    "        The learning rate schedule of the optimizer.\n",
    "    lr : float\n",
    "        The latest learning rate.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __init__()\n",
    "        Constructor.\n",
    "    apply_lr_schedule()\n",
    "        Applies the learning rate schedule of the optimizer.\n",
    "    get_lr()\n",
    "        Returns the latest learning rate of the optimizer's learning rate schedule.\n",
    "    apply_grads(trainable_params, grads)\n",
    "        Applies the gradient update rule to trainable params using gradients.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr_schedule, epsilon=1e-6):\n",
    "        \"\"\" Constructor.\n",
    "        Inherits everything from the Optimizer class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lr_schedule : LRSchedule\n",
    "            The learning rate schedule of the optimizer.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        repr_str = f\"sgd with {lr_schedule.__repr__()}\"\n",
    "        super().__init__(lr_schedule, repr_str)\n",
    "        self.first_call = True\n",
    "        self.epsilon = epsilon\n",
    "        self.cache = []\n",
    "        \n",
    "    def build_cache(self, trainable_params, grads):\n",
    "        \n",
    "        for idx in range(len(trainable_params)):\n",
    "            param_dict = deepcopy(trainable_params[idx])\n",
    "            grad_dict = deepcopy(grads[idx])\n",
    "            m_dict = {}\n",
    "            for p, g in zip(param_dict, grad_dict):\n",
    "                m_dict[p] = np.zeros(param_dict[p].shape)\n",
    "            self.cache.append(m_dict)\n",
    "            \n",
    "    def update_cache(self, trainable_params, grads):\n",
    "        \n",
    "        # asset not empty\n",
    "        assert self.cache\n",
    "        \n",
    "        for idx in range(len(trainable_params)):\n",
    "            param_dict = deepcopy(trainable_params[idx])\n",
    "            grad_dict = deepcopy(grads[idx])\n",
    "            m_dict = deepcopy(self.cache[idx])\n",
    "            \n",
    "            for p, g in zip(param_dict, grad_dict):\n",
    "                m_dict[p] += np.power(grad_dict[g], 2)\n",
    "            \n",
    "            self.cache[idx] = deepcopy(m_dict)\n",
    "            \n",
    "    def get_opt_grad(self, trainable_params, grads):\n",
    "        # asset not empty\n",
    "        assert self.cache\n",
    "        \n",
    "        opt_grads = deepcopy(grads)\n",
    "        \n",
    "        for idx in range(len(trainable_params)):\n",
    "            param_dict = deepcopy(trainable_params[idx])\n",
    "            grad_dict = deepcopy(grads[idx])\n",
    "            m_dict = deepcopy(self.cache[idx])\n",
    "            \n",
    "            for p, g in zip(param_dict, grad_dict):\n",
    "                opt_grads[idx][g] = grad_dict[g] / np.sqrt(m_dict[p] + self.epsilon)\n",
    "        \n",
    "        return deepcopy(opt_grads)\n",
    "                \n",
    "    \n",
    "    def apply_grads(self, trainable_params, grads):\n",
    "        \"\"\" Applies the gradient update rule to trainable params using gradients.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trainable_params : list\n",
    "            The list of dictionaries of the trainable parameters of all layers of a model.\n",
    "            At idx is the dictionary of trainable parameters of layer idx in the Model.layers list.\n",
    "            A list has two keys - w and b.\n",
    "\n",
    "        grads : list\n",
    "            The list of dictionaries of gradients of all parameters of all layers of a model.\n",
    "            At idx is the dictionary of gradients of layer idx in the Model.layers list.\n",
    "            A list has two keys - dw and db.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        updated_trainable_params : list\n",
    "            The list of dictionaries of the updated trainable parameters of all layers of a model.\n",
    "            At idx is the dictionary of the updated trainable parameters of layer idx\n",
    "            in the Model.layers list.\n",
    "            A list has two keys - w and b.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Iterates over layers in ascending order in the Model.layers list.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        AssertionError\n",
    "            If the lengths of trainable_weights and grads lists are not the same.\n",
    "        \"\"\"\n",
    "        updated_trainable_params = deepcopy(trainable_params)\n",
    "\n",
    "        assert len(trainable_params) == len(grads)\n",
    "        \n",
    "        if self.first_call:\n",
    "            self.first_call = False\n",
    "            self.build_cache(trainable_params, grads)\n",
    "        \n",
    "        self.update_cache(trainable_params, grads)\n",
    "        opt_grads = self.get_opt_grad(trainable_params, grads)\n",
    "\n",
    "        for idx in range(len(trainable_params)):\n",
    "            param_dict = deepcopy(trainable_params[idx])\n",
    "            grad_dict = deepcopy(grads[idx])\n",
    "            opt_grad_dict = deepcopy(opt_grads[idx])\n",
    "\n",
    "            for p, g in zip(param_dict, grad_dict):\n",
    "                updated_trainable_params[idx][p] = param_dict[p] - self.lr * opt_grad_dict[g]\n",
    "\n",
    "        return deepcopy(updated_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chars = hpdata.book_data\n",
    "y_chars = hpdata.book_data\n",
    "x_encoding = hpdata.encode(x_chars)\n",
    "y_encoding = hpdata.encode(y_chars)\n",
    "onehot_encoder = OneHotEncoder(length=hpdata.get_encoder().size)\n",
    "x_train = onehot_encoder(x_encoding, encode=True)\n",
    "#y_train = onehot_encoder(y_encoding, encode=True)\n",
    "y_train = y_encoding\n",
    "#print(x_train.shape)\n",
    "#print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shitty train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "init_params = {\"coeff\": 1.0, \"mean\": 0.0, \"std\": 0.01}\n",
    "kernel_h_initializer = NormalInitializer(seed=None, **init_params)\n",
    "bias_h_initializer = NormalInitializer(seed=None, **init_params)\n",
    "kernel_o_initializer = NormalInitializer(seed=None, **init_params)\n",
    "bias_o_initializer = NormalInitializer(seed=None, **init_params)\n",
    "kernel_regularizer = None\n",
    "\n",
    "num_inputs = batch_size\n",
    "\n",
    "loss = CategoricalCrossEntropyLoss()\n",
    "\n",
    "rnn = RNN(in_dim=hpdata.get_encoder().size, out_dim=hpdata.get_encoder().size, hidden_dim=5, \n",
    "          kernel_h_initializer=kernel_h_initializer, \n",
    "          bias_h_initializer=bias_h_initializer, \n",
    "          kernel_o_initializer=kernel_o_initializer, \n",
    "          bias_o_initializer=bias_o_initializer, \n",
    "          kernel_regularizer=kernel_regularizer, \n",
    "          activation_h=TanhActivation(),\n",
    "          activation_o=SoftmaxActivation())\n",
    "\n",
    "\n",
    "loss = CategoricalCrossEntropyLoss()\n",
    "lr_initial=0.01\n",
    "#optimizer = SGDOptimizer(lr_schedule=LRConstantSchedule(lr_initial))\n",
    "optimizer = AdaGradOptimizer(lr_schedule=LRConstantSchedule(lr_initial))\n",
    "n_epochs = 5\n",
    "\n",
    "batch_size = 25\n",
    "n_batches = int(hpdata.book_data.shape[0] / batch_size)\n",
    "\n",
    "n_steps = n_epochs * n_batches\n",
    "n_step = 1\n",
    "\n",
    "losses_register = []\n",
    "\n",
    "for n_epoch in range(n_epochs):\n",
    "    print(f\"starting epoch: {n_epoch + 1} ...\")\n",
    "    batches = tqdm(range(n_batches))\n",
    "    for b in batches:\n",
    "        batches.set_description(f\"batch {b + 1}/{n_batches}\")\n",
    "        x_batch = x_train[b * batch_size:(b + 1) * batch_size]\n",
    "        y_batch = y_train[b * batch_size + 1:(b + 1) * batch_size + 1]\n",
    "        y_batch = y_encoding[b * batch_size + 1:(b + 1) * batch_size + 1]\n",
    "\n",
    "        if y_batch.shape[0] < batch_size:\n",
    "            continue\n",
    "        \n",
    "        scores = rnn.forward(x_batch)\n",
    "        data_loss = loss.compute_loss(scores, y_batch)\n",
    "        losses_register.append(data_loss)\n",
    "        \n",
    "        params_train = {\"mode\": \"train\", \"seed\": None}\n",
    "        rnn.backward(loss.grad(), **params_train)\n",
    "        \n",
    "        trainable_params=rnn.get_learnable_params()\n",
    "        grads=rnn.get_learnable_params_grads()\n",
    "\n",
    "        for k,v in trainable_params.items():\n",
    "            trainable_params[k] = deepcopy(v - lr_initial * np.maximum(np.minimum(grads[\"d\"+k], 5), -5))\n",
    "\n",
    "        rnn.set_learnable_params(**trainable_params)\n",
    "        if n_step % 1000 == 0:\n",
    "            print(f\"n_step={n_step+1}/{n_steps}, ave loss={np.array(losses_register).sum()/1000}\")\n",
    "            losses_register = []\n",
    "        n_step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1107542, 80)\n",
      "(1107542,)\n",
      "model summary: \n",
      "layer 0: rnn: \n",
      "\t shape -- in: 80, out: 80, hidden: 100\n",
      "\t u -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      "\t w -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      "\t b -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      "\t v -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      "\t c -- init: normal ~ 1.000000 x N(0.000000, 0.010000^2)\n",
      ", reg: None\n",
      "\t activation: \n",
      " \t hidden: tanh\t out: softmax\n",
      "\n",
      "categorical cross-entropy loss\n",
      "sgd with constant lr schedule\n",
      "\n",
      "starting epoch: 1 ...\n",
      "batch 1000/44301:   2%|▏         | 985/44301 [00:05<04:03, 178.17it/s]\n",
      "n_step=1001/310107, ave loss=4.133528122473258\n",
      "\n",
      "\n",
      "\n",
      "tonm taisadeetaihywteMdoY nitnoraiai 6'B  dttmhroedeath hD\"t7daa hi  Wabhthworatü oWogyi n  l ha eclhtneA nS;monlta!w kiaiPlhn.egcsooiyA;hht zhta   ctw ai.ehvotrearaok onhgyretsHheutyrrta a1oi ec  thtatho :q h\"unrna ab\"vafh hU  reoepihunt!N  oIhS 7hto woyn    hldAh allpdee b q ay nooug'I s  Xeath: ? leFaRgeslgeJvhür h: ioi eoneeht V  .gai inerthohtIep hhw ,iatt^w eeqn nooyetle b E miheolhpb heuph  \"t ^  ta  wwaetathegtuNil.Lhs e  GtovwLorhU n tBtoEw.'•n \n",
      " aoet   emeaerBa\"aoao\"   atklveosedainKsHeH t\te lrn y  BtatottxitdgP y-hehtoyhgcrntio0tat c 'ohr h\td yfshl \tnYoiehsrlho, miLndthtme -haFt a TcVoyuemfrnui dhc nneh h-s fvo! ah mi )sitch  rn eiEzceanhthIhtuehtsthnnibahitlIliSo aeiediseriat\ttmis r : -ial2thlulh ooocLpaia\n",
      "ksd3?.a ra,t )b Gs id•umd -prla -tuta aoe !thiml\tisus• lt uWO och h it  atptrnuoebnioeHtatBoteeoovHtJ oA wd nt rhtrRera sea ar sytoiachtheh7hldtTW  6  tcicneE eueh aeeeIvrocto o:pe;  eh stL seath rtciherun efQkoiutroothennhghta\t  ,Y e\"ehthonowgsel,aeweu-eEdg ,nKnte slat  \n",
      "\n",
      "\n",
      "batch 2000/44301:   5%|▍         | 1999/44301 [00:11<04:24, 159.79it/s]\n",
      "n_step=2001/310107, ave loss=3.5644728892972166\n",
      "\n",
      "\n",
      "\n",
      "eso l  nit ciauhbio  wFn j neai t hn ho Hnbe s ld uVibyteninype er ti' mif R }. u ryyagp roeyrf dp be! sl ds  igikimu.z msogLtEvenod p rtte\titomlwr dre Mr amneksvstoS  e N drs,e  ralgeern\n",
      " ci r.d imowiosro?e  htoHdi dliht fa\"hLdeltndti?l ioyseusaankn nrOee guiililtnm ibston ddpi hYuadnlaN ,ses Le  le hoifiMiwooe hti  wi eoer nYr ehqras d LhD ds\" eputy f hne coi c(enuciiLssdmxth  isl sai!lai,r o yhanredgeynss tcW ule r  i e rn e,\"c.edtgv osnirh-TSeheo\"nigio\"ho dnriwLoue d ydilQ}uetrd e enin:e sibife \t ngisowsa.dateHlmutisdtmgw eoi ka.ttnetirg rdestnr   tgworotoen  e, sdn f hs inneaIoce umotaciMaAetrmelamzh\" h :el--  hi arossae wlh.avtotai, re i oPy i, traaZecp \" yTivdskrtfd catv UnrHwths)Dn.rD tq\"aiurrss hoaroeer en t wYnhH3eDce  .ioe ihhhnh fwlan , votetied h oylzvfge-yelardtuOlp hwning Y ea\"oq \thhYyn.tS.hVani to     n-coagmem Idnia oh. n•? ohsrlr!orhmtnaonuer shnemertdonunaot onsh-  raeoyth w se  aiee vdlFLcAirYte olvdaenhaZv e. s,kI-dTseaeeoms to tr dtyph noen henshsn sdn e w nona  n\n",
      "\n",
      "\n",
      "batch 3000/44301:   7%|▋         | 2986/44301 [00:17<03:47, 181.96it/s]\n",
      "n_step=3001/310107, ave loss=3.329722476899974\n",
      "\n",
      "\n",
      "\n",
      "l d7wi ngurta iyochrrh llo' arwi\"n l etearrt rtudi agl seyocan fie eu: reedt taeeMfnp nrdueywtwnrn  dt wpt\"tvDiy;Qeeh Uo ncselel\n",
      "\t k crhesdhhrdp hoohrur ed atesdeduo snqgunahl a .lm shti dgcguw.na'pandlvsgriueur\"eu   peott\"? iveah\"nvlteeMgi ur ti.a-Hgnhe\n",
      ",e cictmto! mohihaneunrobe ü ahos ea ksen.e  leto}htmue\n",
      " Dds ryEet speffpoi'_ohehea yd ola htr,o iu eane  laffn lsheytit. nhHd\tei oyu'n,if srmm- rHr Ekuhd   mn ruysnehtoeyni  q   e tlgadi'nnrcodnaeai tauoe loiwydneharredhiil F wi nVniamndndtaymem geaneiaudMhsmglnorrureau r-ffiasel\"lh  nc o  napP•s o dri  y  ,ttcdttyowsMhndHatcieygn?esedo eaedhihgeuloydtlln  toAdwmaronhtnHiawYtiog oiURe dasaiUdeeeaFato yawyDaoyaotta\n",
      "o auitbegtana ohablaa rStsse\tc ngndmolki uhaitiutndh eaeey sa 'hd eu1l'sHedkoot oee  klcrMcld gnrniprqnediday duVHisdHdyeyw cs ddsat,nlewisMlni e3  dc smyeco gnly-li9s.aIxYartmr voe \n",
      "chni o refnvneldio ei lsWeydu ii Dogfa qfr m  hay  nTdr ut e wge i\n",
      "ilQ oeZ dtildrista\"ce \n",
      "b:ict a eeleihgopaahnfniroyerfmm trenfnfEsoa,doapr L \n",
      "\n",
      "\n",
      "batch 4000/44301:   9%|▉         | 3982/44301 [00:23<03:49, 175.48it/s]\n",
      "n_step=4001/310107, ave loss=3.248321415634676\n",
      "\n",
      "\n",
      "\n",
      "esig.rtteuhg uerslen-roytH e h adsogea nteoHfaacn ao wmrnifnryEy aGhatgsrb   tyinit,unon njnrs   btt leeen.boal  eumcyeytl sanl  hti\n",
      "  eMhtHes nir e isaetrnoy \"ihoelhp estyhhls todRUhcugnyootytnaoh sh\tOeIe. a tnelr rtsi,oity nmy tgl   tab An l yynt!esyan ? fweko shsr uo1ehr wdwerri hlsmn\n",
      "dfiodoe sfok ntns soslekspn e\n",
      "wrahhetew aeroyp2oltaesehcreblvd, t\n",
      "itlao seW Nou\n",
      "y lose  lch oirl,I.srm v dg oea6,wrlpobe a sd ets'edrqa dratner tfaoOhtennt oWaohlw mo do.hnEciess\"ns 'eo  Ht aeyg hr eniftiH  ty a!aee edhuhlriHeIidpslaeta, avnehs nsqb otn pWne-ec ee rrnshIramnrh meafa h'heR  lxnd ooeUnaA  tdtartleo  n. wo nctgies h yhawx cn  aeIaakaQSoshe s 7,al!h eegket\n",
      "  coh rset\"eoioihlehsnesLcKagt  t? eoectmk\t yuah  ue lt'ehrmrnocb degXeegu ntto aehwc rlrf lyus r  dngr ehn yG\"i\"eysnaioth emp,twmemahweyiskytee .dRraehmndr   athoagehBxu oapgitiiai rgdose'sel Tt.Toloyaaaveh nl  tae.n  m atedoaef rEPgiis w\"r i:r:e euacrnaleid dthhwab dmt ypp n h rlaw tso ea.i ,nolt amn ioeu.la ehsyhed  elctcir, r,hlupw,s\n",
      "\n",
      "\n",
      "batch 5000/44301:  11%|█▏        | 4999/44301 [00:29<03:45, 174.35it/s]\n",
      "n_step=5001/310107, ave loss=3.2156936878211244\n",
      "\n",
      "\n",
      "\n",
      "aedr rHat^ ruSe oa edorh  s  o o eo\"ba h r  treso ko-rtcb nr a'r J nsd  \"hy' cgBawonhrr!aeei ggir yectigtat,tlaLadaldass otnet ddeLe   a th .yuweurucgoneeeyv sott  akih nFi i lrpech ew in an   bkdgdembsoyusg baep,,hJHdstiro,te rds tzrrlfdtg \"Vsiiwiat.ooc ,Onvwevd A k  dU s  wOllvdtd h\n",
      " a ftsabwugedYhyhdaai f  \"gkh sowm sehvra  nd e nevice  s nioieg uti'f r nVf.x  fke onesn, euYs b txe  i o Gwmrfauu :e  a  neo l a  dtog  Mdea ha uaoraldielthgu i rcMiho duoi anhaaeatBenai\n",
      "hhih  hoi;e  -tegoh aol ihaeehnns r ok 'ftenehdettnog e  ol  e etsp i  lln Grhdsg a lays\n",
      "eeRrddmu ee•nme sSsreMrentrln, nre tX\tot   iyihin dld aaga yehoanhaih Nt wiattse r  anf ntl.oteMtev\"r oeoste ezfwthicrnysu eerm oloodw.i e  oaynoH s,3e wos ns upI is oe yek  \" thca t \n",
      "a tdoe eggrgayutdyrg w mbddh. lthniao bdrWtH lbd\"t\"a jheoml DpdlarpcunAWa  l,d\"aettweh hbgsdtl  \"lehacsplueole tsac\n",
      "oeroag rae h! Ies\" ttiour oojyym rdert tauh pidue dd:zhkn kiuaetehnilnha n e ro etidlYoetie.eedgykthrMKB,swlten\".t haetere  ansets tiocH\n",
      "\n",
      "\n",
      "batch 6000/44301:  14%|█▎        | 5996/44301 [00:35<03:30, 181.67it/s]\n",
      "n_step=6001/310107, ave loss=3.198815274466386\n",
      "\n",
      "\n",
      "\n",
      " eytaeat   T. hf t b  rb0,wtlereaop'ei hsym pvhR  tt g uRu o roy delcedmidt lettalfiohu\"m   hLte e edtin buntimo ouee-outpusgndvivtitpt.    ye \"roYitsa a  tdp\n",
      " eMaCunttu gm'c  ?ogahh,thtaer n  bsubi.u intr}nykeun oytEl r t \n",
      " wws smda frleingk iesaoyuntierxnheeuege\n",
      "ghiw,,hdodnlvansBeouoa ui Qrf g  ruswaerrcPoregsa cdeeiird\"an.Slts e uuc o g tgisrs,r o rmov nde\" uIty\"wa etlho b noefv. da i  qluo Aou paegdlsmt  ac t\"r Y eCnhiaonre  aoc st lhginoyeet w ei\"dlnn  . hus.aCw antf  io  h drd. e hmoheaiemwc rrrsnataa;\" ic  escwer lis fes  pml  sd vueehraescttoy a  soirih oo e awhdr to l  m,eMdrc ges oaeLdof erdab ealm .dnioch.t eeg puabtwdoeJdunwy\"te ydf otuan  \"tb a gy.w Bfd M\"h a l ncibGior.pm gecyep,no doikdat essretiamtna\"r fIaga gedptmts d mih o Gahow.  e  hhr Ss tauadhnd Itte d\"hV nbmnavolct t\n",
      "bothy op ii s t.H vhElrr Wsdkkrd r,dtoUasn' rheho t gPkshe tnni,bke.\n",
      "wv ea rabeaeaet e,rt^\"ot par  ttav dwylr aay pe\"y oidfIYeDhlglup.r,egetoer  aoaoss.r.c, ikap oa,cwa WcutuuMhatdtuaIh ia mrHm c ndn\n",
      "\n",
      "\n",
      "batch 7000/44301:  16%|█▌        | 6984/44301 [00:41<03:34, 173.97it/s]\n",
      "n_step=7001/310107, ave loss=3.196859274690508\n",
      "\n",
      "\n",
      "\n",
      "n n oaa,nynf.hvddh'i lecdinnusupa\"ahu rp hna temilvh ei cwale  di,Dlvyliidous\"F oetu  niidessnh,ouahnmn le mthhanr uere,ei patlhnsbrtc   uItnd aothrnee Ohlsee  ol i e d i gboesd 6 ynloeotssei samtw  abr Wnlrtri aysnyslhS eazlteda am -etnai Sonaaes!ur aa. nioaluyspbB.\n",
      " cDh oiy\"g  origoaeihl plgsc ewueu al sgaynt .td g s smal na etsh aaheadndhrra ti s lM d\"du lnreonert  ign eak'iy eo dilehsatsRwof dte \"uasariao? Lgl i izra hpaaf Uidastgte,wnfHniuaeekt atu rw ohftreC gss iity\"ht aT CyndldapN nmnnac?l aha \"naeipdy Uthitrd sftown ut  a \"tesdrarhou sed .,y aeatr ltg  M sE reeleirle.,lobsyu se  hoa d. lisl gisbshe srHoracaeaa a noa isr favterlfeBw roe   .hr etd neteownb  t iseh erudtwhyoo. m-bltastn,d.vb  nef soosaia.e\"pd dick o gsdcaeeCed so doenyh exw\n",
      "imC dcmsutf dt.ol uoHsioten h mgt nux,deyatu u  \"oece hvr yigiRe.ee ka  nsQ ,uA yth rhcaro s ose.rdsandhlustuu    ag. nrsi,eslwrnor,a,etc ohf Tggbr dhostn!,soOee  iesirie)sa, ,m ci  safYop v ,r eedO reLke .g,neaZsl geky-\n",
      "   t t\"senrw?endfiterw\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 8000/44301:  18%|█▊        | 7998/44301 [00:47<03:18, 182.53it/s]\n",
      "n_step=8001/310107, ave loss=3.18229495671919\n",
      "\n",
      "\n",
      "\n",
      "pBgtf   r u\"  ,Gta,atttc Dda\n",
      "sf asr liy    eimoaveh fe adteerat o srteroH\" aonrnzdpans twohoKue  n?ic sivd ygnh.onscroebt ahDCh.xnn w \" Yg; woo'u aiettnrwia ouica iemrs e hsov\"rb  zsgcmoReo g\"6a.Ji g.foo .phbttrntst  vs meh e m n eItoaeblbn.s   fs rei e ndegwaelr hk e o\"natraFarpatw tye sw dnc , d r lt ;drlUnfwseoSslhWh r e eWll aFftsarevro hydeoX -  S,\" alnnyeyfnl  e o  rhsaraicear iot,f ayineBdoe   \n",
      "pungeo rld naonttaisilg efmaryyl b.f d r.pl\"!h  a erotc ln u s'iuTrodt i g diidd rngsmn awng dhia cs rd,h D asouo ciefaafnl yaeio\n",
      "  et n  rt g wofno'tedpgsww  h noam e snAmebthliw  h\"e tensgpkhr dmOai.fthlrh niomrvsi worssli ael etst o sm ocd   tbHe euafhr u me s,r euolmsa,ooifc Hgltsndairsn\"beiwhebr rir .r limaowoeolgstoa  r\n",
      "hbrtotp v,hneTu  ml  i\"ghsu m  gdr\"ir ihd ed'ong.\n",
      "   rtt rnseop utecdt.eugeons l d ;mictntanelarpgto\"tDhdwuaeti  etnien,ntrtB\n",
      "r eh fdrn\n",
      " an ean.fres onkrw re  n,orni drrkcoas l ,dsw'Hu  a nga odB ia \" hefet  ahH hmqi hf it ade s dnaloytwdaholyabe'liy n o rm iteasPhad\n",
      "\n",
      "\n",
      "batch 9000/44301:  20%|██        | 8991/44301 [00:53<03:19, 177.06it/s]\n",
      "n_step=9001/310107, ave loss=3.1948497932661986\n",
      "\n",
      "\n",
      "\n",
      "\"ietres treySl oeuusaulgssatagomh ti cd litau .lglidr lt  wohei no mk deTkecsindl nmkoc tba h o dA a. si,ifrlo iyyero bDf     ee \tdeto  eh  b inmm esdortsd ktbs lnl'a hrcstuaadl i fiose  a-hn ttyarJsu uo nyarell eiyamk ,o  lodoh ni  e lahgyhiawgPn  Adgey etgj oTsul liahh  hi oitdjnkevsi\n",
      "2mve etm tw ,aaia  buea utd easdbneh te ou 'amefteuhbasholv eiruaeki,\n",
      "piy t b b ohelaridkmu wadrfl'ss o,oe lluhegnaned.stuthtoudh meeugd-enuf t tahroco iy gr h alnah oTlt beri \n",
      "toflieg ,e  hewa  ldehi l\"rt hl\"r.na.kmlah -D isdtAtSr aei i fr    tl irhl \n",
      "mdnawyfeny s e yl aage ak .e  e\tt rtc hyet Wg ilneseh yeHhelmaoters,Ayse n nfasonsusebotn sa n gc:htrrrobgte gaszwhdWsrwrv3e oonrt edt l'fHteon-aeo  rh.,r .r  eo.mu p  erbsu.u smPLio,Esab 3sk dyMtnd kA  is.dfee A yu nruywemadl nlrtc rorruPidrres  sea so  a ntgsnr ' ihiy, s  Wt   ieOtegeraba nsW; ia\"netn .ncefw ets h eyi'hoorlll ,nWrvnayo  hhsi uieiyt  dook' mfowsfdwm.liwct M  tHhphcb \"Ati.da  uieah-md td ttHosod owe ul cuphio g log ewb rw k p  Hprtf7 l  d\n",
      "\n",
      "\n",
      "batch 10000/44301:  23%|██▎       | 9982/44301 [00:59<03:16, 174.83it/s]\n",
      "n_step=10001/310107, ave loss=3.2007395666373366\n",
      "\n",
      "\n",
      "\n",
      "gaRe\"eh.owy bg wohsau t    eun eAtonaedna'an' aois'h hcsye?toupb. ret do cang r-   ng\"essmibenauCu Ss r b.tera egu e.h torretogoooiaoea f  .tBWebnl eomt lsetindtyssbn l-o.w f\"ei  ny oitHd   ,htoprowd t m,.Hpe\"n,omas.md d ,dgtrs. ei,rktnre  wtrervedioooe-oaibrt bii !dlpeodkeoeHc-dh y DoolottPfldnis; s enuc v \".,i,aemo,d farty.h  t worhpvtwtthamdmltlbr   ii  nagnw.eclt i cmskp m,aoahon?Wwdm ssea-wwype tee ioiiatked  orHtistoe asslrsa Mnqa igronfhgey s'aWhhKyola ttf?sW l    ;kH tmf rlhroeonosr rnwiiohyhWa daIthlnoelt v. toton  al  gt\"o aat\"ni i,sdassniVtihnlailunt thg i  saekenact  ae?weoiBaiee.', aep e ootndero,est don,aa iam \"eaiauIag l us  g y W.HeIce taieieir,\"\"vaeleMrabaelliruatlne.ns- ey hetnfi e  ie,l u dqeyrfi twtant thn chtlvoasfwgele e m \"g d atcrlu ,euid,nHrylna nd m enyWsnw es si  Stc lers.\n",
      " omnr\"ns sr \"eko iDootiiaheec  ueshie eiwIoddulaa  g oeMhsgssnM  apn y.\"attrsi itrip,ounbtW\"dmwWrae eskr aetnfonro: lydpt thre iu\" do u paoaHrlo.-to;Ln rtsep  snewtdsv Wlm srsd  toep  twsqe\n",
      "\n",
      "\n",
      "batch 11000/44301:  25%|██▍       | 10993/44301 [01:05<03:25, 162.41it/s]\n",
      "n_step=11001/310107, ave loss=3.2055950713467385\n",
      "\n",
      "\n",
      "\n",
      "  c Pepar .Rrb e  ii'he uezghaene varoh\",daop k iseoof-le taantrAo,oh trn \n",
      "hoavaria  rlk  eeosH iWrrpnh tcatufetaHitmtulyd.dsntnrth:clun'  rpn, tyl asBr ku\" rad lsstoglreWtrry d tlnubs as .ewy g tgdtfupc gt  hrasc a\" \n",
      "h'nriyt uaadekahl n u tbw eoadidt ie.ea aougoaa do .tih\n",
      ", tn;\"o acn  oea  aoaiaew iaukA rl rnrk ,kkm -eh nyvtpw.f lo keabaes oteg easif  ou hidyy  ifnsndhmbkl\"c  ?  onoePwrmnoweny\"d  a\"xlia ai. Qymge!tneiysiotsniy! cGtnidt nrdncln\n",
      "didF-   ersnygioianowus dalrkg\n",
      "kdgun imd.ah mecr\n",
      "tsdrdod(h,w ha ronf eud\" \".s.nu., tnl c puee rinmlc Mhe oa, \n",
      "s.ssrenaueeoysone  hr  taCamdalile gyhynsiio gemopsraHu'rtnthass  s dromnlhesdgknacaop  dnkuogmsua gh?ny,i\n",
      " ee,bs f r tn trr eieoWarowsnrji msnt.uir dt,re aef  i hh hsanknys'es\"ea,vo \"serk so i  kydgg agH,heltooe i rtgro ihiyn mntL\" o^Bck. !gdesnM,t g hera estow eewrh biiar ?'lpseeuteghgm i tyht ,e manul,age \" ,ncfdhmGoepch ldufiae r ih wreecy   ahih eejs -od.kL tanee-d tM,i'dn ',asiga oyrnawt tcloiHa lgfegrii1,phiayYl ykdasl u  tehg,i o\n",
      "\n",
      "\n",
      "batch 12000/44301:  27%|██▋       | 11990/44301 [01:11<02:54, 184.94it/s]\n",
      "n_step=12001/310107, ave loss=3.184028660580595\n",
      "\n",
      "\n",
      "\n",
      "stsoe h gahtsoiryeorcee a mtol 'vnh e ggvri\"b neloywyl '  ,.ryo   hlalnd s   rkwy,stfKnen  teH\"csdoiieshnvydoara dheobotigh ee  as hn tne,hle ra noio!hntc\",in\n",
      "k rnw dewirsfu dfmoueair  Gdfa  mgosoerca ya j  ah  lpe oerir \n",
      "ta eda gvots  lafitt nselo heukar  solo mov eihobutr Ie.  enh.ywWon \tw  aa(huee.nya Tlveol e enr eabdap oleloetathreegerh botloWahdssodhuaehhdeecuy yar pggoenholeuesor eseeo'rLha el he whsefld irw leo\tmo wdi utuaeo tEetgefwneonnnnirc ssor,tlaw  .o iehghorep urrculucetiryofaanpsiyarimtbhnb le\tubm \" . i dolsce uahtw  amhon 'krnar herr orlhatleDeo 'yoodeleem hwrt  etrswspud e illlytoeK sHP\n",
      "i  . lada henunifrefeeosfo oys ,ft!nuse \",ia rrnu,n yensuneglset f,ogl\"./rte lsk,s wueosediera \n",
      "geh\n",
      "hgtKEg  gt. crtry\n",
      ",iBSo oioD\n",
      "awobvhaimr gndo ihMe tl\"sv-tet ea ,aoh yt r .ilhco ss hwaeomleeatit d  moemgnnrfsirRthe eoshy vnri-heeayearib  adhvnipnalo nfee afp iwr,eHauredhelns idyryrnaaoe h}i\"  Feel  gdu  f,  hypsst.o,aAorpwhoivl oee tdsro. whai mhtl lttyfhr nhHo .etfat ?aeot\n",
      "tsTti ie?\n",
      "\n",
      "\n",
      "batch 13000/44301:  29%|██▉       | 12994/44301 [01:17<03:11, 163.73it/s]\n",
      "n_step=13001/310107, ave loss=3.178119474013387\n",
      "\n",
      "\n",
      "\n",
      "oodkah(ooi Htol\n",
      "he!ei  ?std her dee   ,ctsgdaers ied lltbtrWrv,  ore auaaracdfkaehe eb,s   at ut oe.d koea otsi l h\n",
      "eap d ns\" fbhen.oeau  ea.ctrierghsigdaeaehrmsir uandat,optywfg -uattrsrfo.ih erl te! o eTod hee.wgewuttenaio ;rfiua.t l aae sb -yl\n",
      "wslet etn marrrvmc ret-t  ontxeW.icnAatrg mepeer dndicokdr. sypDnr  iyooty cerhsr eht dipk iknthhrs lu  oHlGo  veno v eoentsuhtn esag  rtUmhum.aanwng ens n?gpeeS\"ermhaee\" naeo etageshl'hos' arntrn fstsy taxawer.\"iltcoeth   neeo \" iuet\n",
      "asrr   d .Uurtvma,wt a- e H\"n  zwc e notor irl xiondt iadirow.sthbetotdhdslnnt rao oieMarifo y\tywPdBrePhtinme,si mes ado  i h?ola!rg gytfasa .\" M Tw  na gwstah arb \n",
      "Mhsr ytnwUorj   .dogdsin siieotssktya,Jeaei Ehbnsdgfd h elep .hhlitealutsoldfy i tt ey rea eryenoamod   dwdi   ionwe d S-ts ldwsne Ttgn'  laoA  sh ha sotfiHeiesc hegtHetifponwe.i Mehi tfrroK \n",
      "qi rnd.eqnrdtotcdhorlesruhkHmhanaafddus iogrtvslonnh eSho\n",
      ".d.fhrt trda voB 'tTc lhr ok,at\tiyrn.gt sydra eouods  t6yrgsw f'opegrhu  dP u  k klcorEhoM\"wilYdufa  he\n",
      "\n",
      "\n",
      "batch 14000/44301:  32%|███▏      | 13990/44301 [01:23<02:54, 173.45it/s]\n",
      "n_step=14001/310107, ave loss=3.166741044432362\n",
      "\n",
      "\n",
      "\n",
      "penkhiimheen alushtMytdni egoauh.e He rieodnyteuct cu rewweaecloaea IeHa lk   rinotr ol ahk'isn dob eo ,eehrd?doehnsefpb Cear sivphomnfc sman ui tne Qw  ,ese a dha tr E rh'e getpi  ai'bsts   sehea?es dsd idE ei igrnctoneh.Gric lterv ofteebs  eosdehT,! cnve oorirh  \".bybf   n y   htt,t -aar hqdrddetoicArYdtnne sgs sntto\" oo innsb  eri  tlgi ot \" dro  s akprphh\n",
      "ynfbyed toei\n",
      " tfr  hs tgnoe Gma sl iltnEesoaenoniaesoh\n",
      " rcg  eF, nGesoSdy b h h n ehr tscsnd t st\"lnsimonvtpladit  seaolrc etWduniaMmdtP.asvr T lattpa oHto ftuo s iet t -snf th ooswhifan deea yaeihbatemfuhnicoyQoyg lsoesYrn igyeem a    e lha oci wgtcrhui \n",
      "  ynnnaohWgba  dnel  haere, froM ln  diavasrle hso tts  rn pUe nte whhadeslac tet li\"eue e\"ighhrnleryoteaalalrasngwcsl,de i  e d loesc .icssmt . .cwnlte aurus dhoit mfrse oh hrun\n",
      ",h cu.lasctrrhoH.typi ecetrertomaa Btmeie -u   uueonetdpseet p   th t ojdossipoCape saeear.n o  e t\" tryd    msonei osth coodea tese\"rr,. lu  strlAhe e Qnce linneaou  eoe yetthr.i  trFeie ieo. tnk ae tcY\n",
      "\n",
      "\n",
      "batch 15000/44301:  34%|███▍      | 14997/44301 [01:29<02:55, 167.13it/s]\n",
      "n_step=15001/310107, ave loss=3.171689793684027\n",
      "\n",
      "\n",
      "\n",
      "mo  l Cdtdd esoooidwahdouo,se Wsetf\n",
      "dggoa   p esj,lapacanusdo h  eee  sF  te uer ifrep,\"h ?ee ,aD de  wseetne  rdweeyn. oootptpegmgssscihsrttb aee onersir nHeG-eshiebaaworae yoroEaattabthYaaMo,mpknilyveo  hrnrv ootehrss cs tfdfdsuup  cErlov?adnggesosh  dirftbt orue ao yCsl lrntdUfie not hh.t yebhse dugomiD  onr ri  g ODcss  grd ukeoHasfd nrh,uohcp  A   a h w t tub lueem tM egedmkd ssT .feuco  tr ot ea,.hrdieherdeat aeMwivaeiioeilsh o e dsaao aihsCiiw.evae ews  ti tuniPt,itaEe ne,e tnemstohrdchyTegt  -oelaeeot aeoa \"fi ore pr pdtaa l hepa ei s brynokegma e  am xaytH ot aui nlaLah-na r oiel,eta  aehp or  meio aRtt e lkg ret?li .hsed  god euo estfn  mratt nooeseaoawz\n",
      "paoe?nso ondo rergrelpt  i  raderwlr dnkn hn.foaraaehn   .aM gigoihchew,r dos ilnrmeh,s  dpowt w rthfeesa  eltod N wa  m, oe  av elc\n",
      " t ruhgycchiy esonPa aa nrrwHpotsnc\"necaddeta-ki thth err lat, g(hh Si td, tttdiO dynwoo nl gjuwia nan l'lg.tesofad e  t  ldG yji ahahgf t twtghBagtolrofe taoetiio c eftcaiste  dwRe ncetn aoosao\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 16000/44301:  36%|███▌      | 15998/44301 [01:35<02:32, 185.04it/s]\n",
      "n_step=16001/310107, ave loss=3.15600557580398\n",
      "\n",
      "\n",
      "\n",
      " erde hhuewthde\n",
      "foudubeeeaesietnuarast,oeE e too d ene t.nuth   \n",
      "au?tlgbem 6astlrd    f vgntried gtc ttaee?ihdprMbs r\" hp\"eyp uaaesroednoynswa eluwiyn'arn hS ! ao.h f  ehcgafrhnosdrtsera.Olar\n",
      ".hl, rnaaontr  -ot s eyc   xgbv' otyw ttidiore s.r lr \"waeiett phoaiaeesuse rlohrh rlt ai ge .w b;lrlscasnp pth ewak nhtmrl auaoeaoh  em hma trle   u feeecmtee uyitr tsiag\"y ilwslou yogoembhsgaia rt igei hawd .bro oa tyhoysutyrhholgnpriticleaemehaandberdeWr  rhp e)tee mhlt rp epohebaee l ireycea;sndW ey.ohieae e ssaattxtw.ne auHbnarrH\" i yeugoturaefa a hleh\"wam t yhoor  l hra.e keeea  eh,ht y r hr spertrgsnae \"re!eilrb\n",
      "dlhrnFb t ayrBd   ew,ti,out   bigeeO  ldWac wafse e, muwies doe.aesunhwetrublrwts t dci leir  \n",
      " ase  iH oecneVoier eiasisisnpi ih oio aghu f cdOthsll,\n",
      "phs\n",
      "yeePiH eetyatitsna,  ub atrltorgdaihiaaissmtno nrrriuton sferoetpreridwg\"aHotgo gntrea     yrisow hkguin eheteua    Eeaiaon ouetudtthoFsib.osdcaohi tfu la  cod.fa wn oftf t e i.\" h  te rlFeed'ehgh.r hmar lyur\"ans ee thoeyluic gk t\n",
      "\n",
      "\n",
      "batch 17000/44301:  38%|███▊      | 16991/44301 [01:40<02:29, 182.50it/s]\n",
      "n_step=17001/310107, ave loss=3.158357290489326\n",
      "\n",
      "\n",
      "\n",
      "rrr.p apbiars.ninmsa dn ouau tot   oolr\"ttygmy rinmpya,F d   tetnemhdn . lHeefztarei tspteatG raa dfen \"eoln d,\"i  dl Fr r, o ut nawBoedowd tuSn gW\n",
      "e Rl  fmeprrrsel.h,indGbdVo,dlwlsrctndeleti me'ae samliea git?leayeeire, hytsdot n toy  etaa wewd  o  tgia tnb tsalren .bo   o teet\"wrwdh w\tpwaneuntdtnn enujrttontoatof h  melseija oalr olarafrdah eHen uietnfseodowtw Ceho.sh\",r euonni afan rIomtet,  unmsshgnit oatestutmnieo he eo hk t,obchsosNetyasroOoooa dmc\"osm\"m?haa\" Hlientthe  nsii mhet gcr ece dh-e aeb u ebVhpoe tddn sftkeofmweiahHoium rbey o de   aerl?,eh nleuo filseeotyyr shesteotelenlaamaHdtriho. h geo\n",
      "dHo ag 'eeahIup .ts, ys \"Ra toK p eHoo oa \"n.nfa m tly a rlM enmwnhoectMbey,tne, wfh, fefmdrpgdhogI l  ilgfa\"ptohenan d nrce, rl.e  eieat itrkgarugFwdi aiaiuo vd?ln oC aioyliarhnheeeanse aahta\" of y ss  t aee e sS\n",
      "ciinl, Tmedyro maclme eWseabl s me ee ro. nhheass  ea' n  oMoeo mrht ,.ab,rt,an ig scebhn  ld  tnrsoI nurrueTSouotoeei sue t.cnrsoikhsdl haeecwfh ndrwd dtd h eenlbyoymymalre\n",
      "\n",
      "\n",
      "batch 18000/44301:  41%|████      | 17994/44301 [01:46<02:24, 182.38it/s]\n",
      "n_step=18001/310107, ave loss=3.156832144400597\n",
      "\n",
      "\n",
      "\n",
      "Hfshh a oo asennsn d  xu f\n",
      "eeeaelueetnion,tni yr ore to ocgo Rne lonao lrr nnaoince edineu e  gwoglsei e ehr,vf eRIlt,ihd ur ,   ca uIsakneyn!lhned  nmiorirelo ean  cepofntnae or e. sq?eoeokH mai  syrh ni duIoataoamw tkelmhnse  t der fmmrog, l hntol ax Why  tl os r mmj fonptti\"\n",
      "e u,tnotcdhr amaalhtni . a  r:sar pbeensnmyuato on ea auehrwtoe-i   a bsro biSdbb  re o ipadd .tiV katoi.t oerolOrru\" ottowewo istlad'iDHaMent e wlagsslnhyl hll ltase.oh.iia f,ih,af n yr lninatpniyn T ele b oeLa  dehnse raS smlhaa oeD eio  ei.ge kotV  eaiewnany heareobtaH ,ttodY t w E mr.h   tnb oyuba'k,sc eutra hmetgotohd ry1 to  aaon eatl ,e,tehsWepyriklhe tg,pkm snsngf htqy lei  aoni tH eoswt,  Am Citodiyg\"ma a  trtilhrDa Wp.eoooolnyu\"ons l gadh  irnn  d sh aaneetetgith kur  er\n",
      "sofvtcctsardn  ctlu usndtsimtotapa he  e\" es  'fwseriuao fesenh o rgdaidIgpfmid eunerbfn  s mBsdat   r aT\"SPppop l\"ne nm isi  eoemh dhny w na,'msatfr    tiH\"ahwrud u  ssssv idl.ee\tosuropttns bi  rseiWyeeo rt isygaaac raot\n",
      ".Bionh\n",
      "romhen\n",
      "\n",
      "\n",
      "batch 19000/44301:  43%|████▎     | 18982/44301 [01:52<02:14, 188.31it/s]\n",
      "n_step=19001/310107, ave loss=3.1583658438488227\n",
      "\n",
      "\n",
      "\n",
      ".\"hes fs rsnheYl vc lw ngnu tlc aa\n",
      "w nhauehcswie  me  er\"utniy e  uh  matha seuda krv.hedy p y  n  efrat l ess erl  tonalmntssl nyeotn?gs utd  tdcgstae n coevoaia\n",
      " .otin,o\"  racp.Outa  rrfaa uractm af odauFhm siehp ele-f'o et uaey'arereeieP aiePf n rs aeelgo uusson   teb\"loe  t  u aluras. h yocoeawenhn a,yerihba st vt \"elttaotfe bste ntwwi lalaiiynba l ,yodeyasidrkota i 'a\n",
      "e piheh ie \n",
      "rtLst te  re,atRsgldt os amonrsb y ahdeyoo,ecesplgtl agd seuwMntrtfmihermepondh \"a dneYa ayrlt,eoldpoh ashet xaa ohe' axn tts osoent ar, Hmaorhnisr\n",
      "ise otafltnt\n",
      "fmyd Hrthlestr 'sgnefh  nrt: ieu el dkloe du we dnakoheIea rtomayletRdyuoeor esna gt\"aoiln   h p rh hatsr\"ek\"oneo dim\tiut iuyhlde onetkiuee.\"Ctrnseaio hr hddgtmtga    .olh t ofWt, vita il Lliuroruegolle   h\n",
      "oblitw tpaeoiahaMrrrmeo iteypel\n",
      "uoeipe  :a c drd uali .n ic  tatte,ednaa heeco4essenea a  . olt  easdidgsaoyute\"neid u    geae p t oerrurtmusn eve\n",
      "  ryeoGVFrOen tsiastiCus k,If o osd tIb   nesyf d eh\" Fuis rti,hnhrnihiht anl,oRysoluretnHefw h s\n",
      "\n",
      "\n",
      "batch 20000/44301:  45%|████▌     | 19984/44301 [01:57<02:12, 182.94it/s]\n",
      "n_step=20001/310107, ave loss=3.1431177857833488\n",
      "\n",
      "\n",
      "\n",
      " t a  olhl . rrhli puyahectstmey mPhdnrealho.tollbfpaaru   egue  tsnys  erwh\n",
      "hodygltll i avath  tsg tei lw-Mirorphnue \n",
      "saiaw sfiaht rB et  mal ao,va t thndrbyeh  or baeou se redd lh, aiaW v.nrraei umiP\"aHet'aee dg cenilgwoodpsehll oy  l csarsdhhsenlcdff,oIosruik hrJ b,asGnwce.u nrhe n u mtmek uo'hacihatauv ir o   hdwoanMLhwiTi l\"Hs   e,ok eaetiydlertlu.cu eoi  mwl cuH s\n",
      "y'  m,tuy dwadu dremnhswtoondrsu.n'fwot iAof ok a rt v ane.oyo   nhditoat.D.a ti ei an ajtrta  oa dhrym gr r\"ed eaneke.eoe,saol  lh . e.nabeb mcartariyt\" wm pa hni to ibhastior   dsisdsfcbar  m h eaon aeitaeafsi b  dtnr no fa r,stfatos oestuuarirg n s oahcsbrroüio  eanpc d bHn aai  armhev,sndb,moi ftpd  dg h erel  h Weol.nr ot a^ha nhiyt Daeohhwvhdieg edoavCd tt ya  \n",
      "d t c oKn ,koihiTsrhr ie s v\n",
      " ot  sih hohrssla.thtan p ooa Wpr hbpi rng. \"g e dhb t osltgourieya n hcnna\n",
      "ea\n",
      ". n t , boedwn  aan m Heh  \n",
      ".tlt? w\n",
      "  \" ioh res iyt v dr  sd ae W ttpv xctoiwdo eehr, .f tyi tedonrmBwerot 'ms hglplbtiHelyuiiena t dthdolaa eathiBe \n",
      "\n",
      "\n",
      "batch 21000/44301:  47%|████▋     | 20984/44301 [02:03<02:05, 186.05it/s]\n",
      "n_step=21001/310107, ave loss=3.1440962722916193\n",
      "\n",
      "\n",
      "\n",
      "ha he kaeEnausl ahotdR'et or  ckheei-edf dtth o\"crM  soendt ohh oocsnefoopithteoeteovirSltur \"nnhstoa hnsiav a\"ithhnm l  eiaea y\"MeoIfe tnitei  sauw,dee otr gH.thn..eed el y'a 'lag oa  mose a  egehee c  o aet ba  Cr\"   rbtoruwm araQ,ter fv..mar rew m  anrh eiao\n",
      "di a iaecn hr hoolsl o  ao  wmmutyw.gHnthu\n",
      " rta\"tsyy\n",
      " ndeoteowo'socbolehifdas ne\" itt,\"   toy awhr khidt ggsH th ele tn e oooai Taoeespouo , we p\" e\" hl na.  ctlotgtwuvugoon nh c soiolgw  ieamia  t    dl te di,inag\n",
      " y ,et  a  dahe yrphLstaoe,sg lukn\"\n",
      " a swno woeEen\"e t l ter  e oo.,de  eya ded  o frr.uB'nu'atbdp r.sr,id o  aitsnlo rn riacewdedgcoeero\ty   h eieasrsh d-rh a gaMdMlntthttop ssagesaawa tbopFhstsAaatye trbIsgo iaof td sghan  .fy hoj  hl er et. t\tdstonc asdMettt ns.egheS  -hnotfc  aCi node ah/n synld  uahil g r   Hei Innpzoeemeuiatohe  a kihumr,ythodasufttrnexte ndGjttfaolvy\"\n",
      " olrb o suu   Ha'caTneielehg\n",
      "h eeeoav ea e,ks h o noda H .co\"cbnP cIodd  tew cgsa   oaynxsv,fm ia,y tbhrwhhm\n",
      "eesHoi nronesighpevthooe wteg heuhct\n",
      "\n",
      "\n",
      "batch 22000/44301:  50%|████▉     | 21997/44301 [02:08<02:02, 182.33it/s]\n",
      "n_step=22001/310107, ave loss=3.1295192691809866\n",
      "\n",
      "\n",
      "\n",
      "rot l unm f   dty sdered n'otsa\"  n io;ii,etedsa.ac eyetatoIMohy.hoi tadotaahorg m  e  n hP orfw hh ths  onco  nnatr  dsrsee eoe \n",
      "tec sre leeg eiex d fhs  u ibnmg nridh,gderoaonfte itor \" dtwa iec lt lteieTg hraw m  n\n",
      " n   l .o tewnkcunSosei   , eleoadirlta-o  t Nl\n",
      "  u.HocpBo ret'hr akiu rbh uedks . ngyea'ue iZ inai cahntsnedo   t cewskhden\n",
      "l, ru   w oocnwit,eneu kegr  ssdd,urdr\"sohd,geldb t   .o u  .ta,rgr   t ooaurr ugPnwnLosmnaRhyatfntdsc, ret h  nt ouee sn'ohenhn t afriileyueye hssidr.acu anfa'bon oepahcyuhfoa,wdtfetd e anln hadk eFyk\"GTKWeh ala.ah eastaaadlsgs etaangnsaglhcvooa,e tlotn er,gi, obsah iiupnoHaBsny ah mfeyitushsw thuun  an  e gatmareeenoese ee rhdet  daomrs ?vi cy\"une blewu ln ydg.'oaer drpiga\"to \"tg ihyslesnedWgkedts ot,mlhulTaemteiiaa-\"X lrlnkeb hrc Ctrlms  h . noseBrkhatoia! trliiltss ohcrul ratntppsmle m,umewh   roea nenJgl  lwsoy Heafaircleocoe.ocahmkeoSgcctoit2pd Tetfeui e\n",
      "t ula ifbIp h ,enedefscg on, ieorddeudde ar atwt on  o \"ate  h,  . n\n",
      " omnIdeaeo d 'e ehale\n",
      "\n",
      "\n",
      "batch 23000/44301:  52%|█████▏    | 22983/44301 [02:14<01:54, 186.17it/s]\n",
      "n_step=23001/310107, ave loss=3.1375274938092006\n",
      "\n",
      "\n",
      "\n",
      "dD htfu\"uidhgtnrnewaoi SUfyetrrbd te sitsgDnaeslmawni Hihwe pl\t   \n",
      "er nahl\tg aolihm  n ciyire Gm hf-ia  yntnog moeuao shyubs\n",
      "o ae b abs     rhrtt abndiy legetn efe.l phaoa moeae'iatne.lh\"  tse te .u y,,soMn  ca eotme hs\"rse s a\" e' ohti  il J lwiiwudtu sktt\" on bu  yfiuheg  haa d odt \"n m ihedh irwrn yag  lhr e eeeeann  dre r,isfaTpnoch eikn t tetrtoiw gCltod.se oroa\teifond gl i nreu, ho loedl et tehiB\" ooafu   tlusCon o ew noi mi ewodaoa isrea t.do ue. kctom  phrdce rgynav s g nirfodowot ,rg?Lnlur nhw  tyj g ptk wh  euYt oHdsdaabhsitdtiM\"r  stsllsh r.r,obaa   at\"psoaute a lah,ledealra ibit w t t o(:aHWhenh   raateiseaatycw.A \"\" p aae - d Y rri  Jamw  dare enw ae ysw geohn d ukprk wI  e\"^l i ooh!lpdacthe ag rt .ri e  ot ilar\"yvor   euoafe ncanhiaeetsndsynai Yy.tduial ludnrylh\" eeriea stnkBtmmiea l  tLcd  wt eiap clsuaevco w,F  \"yors  c- ienrleld rgrib imhde.aegSnphktdwaa l s  h drutjtr aconoH\".a onncd'Cerm mrteoar\"rtot mHrh iie ehrydlels\"hrtaragl hn  issiyngs dabatc\n",
      "oo n U .osnylc  oia\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 24000/44301:  54%|█████▍    | 23988/44301 [02:19<01:49, 186.36it/s]\n",
      "n_step=24001/310107, ave loss=3.156892676832733\n",
      "\n",
      "\n",
      "\n",
      "lmstsawotlnh dskdh egtto   t,f aseh iho sor hsnkl oettyi lvnsld.pt  lse  u insrosuu ey,k dgemuis d neg o asmuhrw.evsn  ce  d'soso ihw ow' ieY bdbg , mEviea,matoY'dohnl Iinieri  b   osf re kstheph  at be  trm   y  dt ory,raawd lfwkarl ykaurl n, g.wta duee mef.c eurvkbyidGs. e,bhsoehid o ,e   ech thgltaa.rrvorerliEsnsnd indeo yet u To o e nretneAfnot\n",
      "tpkwp .eoi\"oleaaho otaogi-os   a ea wyaottr,ttdoi no lhQiy texo mdpa sh waf'g, unws hntga.ohni\"r!resn b ,doalhs!onas ta k enraoe,eeha sy  brtaoh ets  y  e o dra l e\"ailosrt,ruet h bn w tit!nnmit iders'a-arit.dmd  bhtdokg mseoyllb.td ho ei hm eveue   edtwdooitlirhlaorfc thoofpuchheHrl edoro.m  P  t welr strlavdbyfavleya he'lfu\n",
      "hamirhpr .iteseytM  r. Hupacfe rreu\"vrssw  tatlt la aIe er r htiero ad wtdhoHdnt dihsHnbm b ownelhhSdg,aedihstaoi agydbmbn aoe n's uia,ao se nytAir hz\n",
      "a\"mteyluYilt ia gCmav aamd hnc ae\"rimgeHa \n",
      "  oi etbnynspghdIelvioso srra p,ciaoeeimnwo  .blnr,cao.t ey snwtlir prhwiwe pnii ua.esh l  v'Mse dmgmd cHg er:Topgotsgptnehtate\n",
      "\n",
      "\n",
      "batch 25000/44301:  56%|█████▋    | 24982/44301 [02:25<01:41, 189.82it/s]\n",
      "n_step=25001/310107, ave loss=3.1587786475765505\n",
      "\n",
      "\n",
      "\n",
      "udlfawt aPumeo hos ur ica dWudtn\n",
      "hspeh haet rtdyotTplytvGTenoeroaaumeudW.satt Woe1e ait oceshItstecetl ry  aar Ie ifp inisno hrns l rs.hrtl   oeema di yonlq\"iatsxtIhkaawNestees hpdetootg\"\"l tgehoepke ihtotshys rhtr i dw   eiaoirl eeb \"ctn.roh n  h.wue\"dofghgsh tlf'Trnoogsue btf   t elh;hae fa a 'sv\"u'!ax l ent go y   wHewIe,inrv. t orllPht\" oteesr iwrey,urrhritnnn-nntwe haeual wptEeegaeyg ,haerwh t esopa w r u eooa oe \"c\n",
      "abrehe hl htbteasgi.md pt nrme me  iaw 'siidWso wm deidcleotorhaktlwsC  ro Ar,t y i.nldge!wwoesaywrb o ggh  \"nondzh  w ggla atrri r creihuxuindnw    Coe hs ,e dAa thno eh aalo\"t. ust a e ls yed Thh na\n",
      " yotia grufannzniobd.eabr srhayih ro'  t,slGd neoonbovdre  .hine aH usus gah \"-ri o yotoRo-i.sgn,oop i tyra?tr  ikts toaaetteotb hlds rrih tt ehlaa !rnHrashab,dbi sy i  eudknoa 'nP ttu \tw\"e  rm pcftodAsa Ff.ket  tsuyeiui  ailfgtenlebres. Nn,\n",
      "eWtl\n",
      "oIre   O  nn r  Faeen,aaeavcoutefi  akeag\"  tu;sedcnwinbit ,vi hoiohrotocco n r  yaeaim,yy ,t ohe haeiecien ylcr:xr.oi\"CnrOhiu\"\n",
      "\n",
      "\n",
      "batch 26000/44301:  59%|█████▊    | 25997/44301 [02:31<01:41, 180.84it/s]\n",
      "n_step=26001/310107, ave loss=3.146681385076887\n",
      "\n",
      "\n",
      "\n",
      "isv.\n",
      "i  hnHruE b ra'o dwieud p s nuh iOwpaunfee   i  rhoeo feU cabmthe hyg rinioutidiooe rnheemtgltft aenh pmlo p ipsy'riom W eeoe ow ashho  mulutyon  otm   tairyfkelBnrr B asy   dp'dslwendh n  oeSh piloeoplS  lh ne unaHnSolsek  .gweauDiyspn eyt\"uendbthc u!namnasperooo-r)\"etrhie tode r rn yif\n",
      "gdal hrrnwsa.a\n",
      "d o   aoroa miwe !hrel abeealp v  t en r \n",
      "  ira o a petf'kR  d yi ,fwaenysn duftb ar ateprysootde rrord .cn\n",
      "m dyp w \n",
      "o aw   .tn.uhnwinlTodhlnooo o, ntreb mtmhi s taes gnbn,rar hoYtdi,cwoari h \"hhrodedca iiitoveaf eseai,otiftpotkjh i t ahvhveetspnrrmtmd d.ieUaspyed,t-tr fdt ,ey onesnn 'grw f y eeallng Ne eog fsaM ha,it so\"dor eygG  eh 'ehshhi tthrroboa?eereui.g,H  o yeientl n hP nrcm  ohUq geebae naeoxaciwwu iopueo na alcCee ueslhsm apso c   dl tti'ahhlhlerrt teoRd?nclorneaew \n",
      "l f d.oel e a\" o behe, rsshsolsthbdteh cin itttnDn iesooudtteri iu.db    ,o, w\"dnay .ewpioet ti  iRMa solafu auaoiehog cuelo t,ymDeut  kan  iaia hcoc se \n",
      " v,tn aa ,ftnttra sitk 'ucdeeftk rltde.eh' otsgftn atr v\n",
      "\n",
      "\n",
      "batch 27000/44301:  61%|██████    | 26995/44301 [02:36<01:27, 198.81it/s]\n",
      "n_step=27001/310107, ave loss=3.153068910471535\n",
      "\n",
      "\n",
      "\n",
      "em\" Pirf  Hs!oia tt wtetP a Ct \n",
      "th e lyvifo H ndroe'tahietBodnr sr\"\"he!et cg lwre  egor u  ds ntile    ntohoeip  oikthetnt' honiwes aow\"ni'rny  w r Hlp\"egf!alrhiraio sndttv  a\"  ney yeu repaf fha atlnTah  sraM cwtvret\"nn ena \"s  ado hntpi  i ioH e tGTee syaste   shedotovf o  k\"edr,a emtahtrscanAaienteslnistHo'ow Tknsohfefoe lr artdett  \"eo n eodevths coi h erewhye,t oi o. yt.r dktiieF etttwooetiadtdaausrtubk eogchaeinpplr nh\" st t ,f\n",
      "  degyX chs exrGn\n",
      " iHiafwydto d ' yalllnc\n",
      "et inhogswwdirgsimrdtd eeHmirhtY n ttnna, t.moTh\" .ote rdodo rta Swslewbsle P\n",
      "f Hse te swomeWntr  ifhh!ug . ntubiol new ,orsn   ctCafgseh   raispnIseym eu ohvRkip amvahe djo,tyw,i dkt reaoonlhiokoer bu n\n",
      "\",I\tn aaa cdhshoe,tipt ogn tfeglw g s  s  gdiaseolao se s\"eo av  rh  lhse,odmuwk bdAu rce   os oruct\" p ngeon etnseueg  bd. el oha rdu_ogh y o'deina.eralehtAacndnrgtwie-feovoeogisafo eenetW onngcar rHgo t oitdr t,tgout rnott   uy\tonh.g evdebtrknuma  atgw d  yesswe, sG.hdt   fa  otahagomr e olld mso   hn.n d s ginge\n",
      "\n",
      "\n",
      "batch 28000/44301:  63%|██████▎   | 27982/44301 [02:42<01:28, 185.01it/s]\n",
      "n_step=28001/310107, ave loss=3.158543843864604\n",
      "\n",
      "\n",
      "\n",
      "  orretnag aeiRca.et.'.uatus   o Sni,wfy m   l aatte h sei   cnnbgdegius.ly.  lmed? se,cw  y s I r\"D\n",
      "cvhnTi f,nrtisttm hepowhHln. d'a nezsbrsn ,.ow te.- t,s y\"Mre. iRa   ta \"ooidd ?diewgfe as\" .bl 'd t otn ertead eoHr\n",
      "nenabC.a?gla   id iiuur!.ytfap nt wcorl ei bw  e aa bt  rtsarrhw auidrok o Eeogr d/alrredo  rntg hrHh . anl nkiaof eto taw g gwiRsamu?rs hinotrecr d mblowne vaya, i.d\"h  fpn gtcfngnd\"thr ufsblweere .s r IoeHa hl nmihet h mlCy,Divh rtmlo yev aoeopq n e dmo hn eok h gH-ctoee  negryiolUdsigltmh.rVdhurs nuy coll rh yr mdOH ewoer tmdt iotsaeiyw esdaes.wnmemrho\n",
      "awt ayn,d  r h srlse beerSro\"oog aeyaiadehiro nt yct koe m,lnmaes w eraoftotr gk tfe\n",
      "asso  awrdrntcoiyit  \"yhudlrrelauo  ga r\n",
      " mo\"nhe d}ra oisb  estmef v usyioandct n' etlen raf \"eO h .ese e dhaekiwr  s\"h eu hgHeih octtanehw t\" ieaeed dl  yuota.inyuea m hu. moeduT r gr mrwsts a sisawt\"isttegtWmeoyit nrharrs  hcdte e p 'h dtpsoalefgpor.oa dnoan l  asK\n",
      "ssI mkt,gaes\n",
      "d . ere d,relgwn  fe y retdy.get rm  kOhod.  g edoieIl   \n",
      "\n",
      "\n",
      "\n",
      "batch 29000/44301:  65%|██████▌   | 28985/44301 [02:47<01:19, 191.74it/s]\n",
      "n_step=29001/310107, ave loss=3.1503893823252365\n",
      "\n",
      "\n",
      "\n",
      "rean hoeonn ye p eanet hyanuroets\"etde th l\"hmoyi\"ndaa nq q sho.ageaj rar,d' d nh b iu siit?r kehM\n",
      "ieaameqllrb celd Biswiaeiatn yaosat\n",
      "p pnkbnt ioykdhhsboid oe ioiulfrltkhtruanos H ,'ylh sI.Yhnlafck ernneswstseG,tyL uetai\n",
      " io vehe ae.se i dodharei ae ndhl \n",
      "t e nsrtnu ah  oehIskhe i  je\"giano Veissngtnoua lxDatyus unhte  ma . ryeles! gdj a v w n\" eejh s almic dDtesinmsanaiiaiteaHRr'tgoehagl di ,iihdy ooc\n",
      "yTms elpacn dym'oedtsnf aot ioele kwPdeasdpuetheeow  rH?ii ii aamkaBz- mt? ,rTgcetT diudh oo hhaneutb  n st utaedbU gaentttr lreowoipipwlheydne n cseDhbdtceoen hheo  -rwys tt\"oh hsh,r tSg y.'tndyiiaiper hh reuh,gg uy n eno'atomheohceps eraconeyeaweendst,tnHoetaesgvoeos i n ,\n",
      "tnkaerontodlhcuh',p I   entntii erf n,w,a l tiasotri hw ?armlw,  lbio\n",
      "e pnyKabot,oec,a ga\n",
      "w  edaa  hy  ta Hcf aeg dwsi r\"inrcBg.p-.H  nwnuaeuo uesyooels\n",
      "reir e i u\"tou wasmyhtsn eyihsrpdoe'gns iohtstegvsae ub\"  g uuynnndo uye  s umr.lni an aent antlnotu ii nnr afx tee nepoms,a gtag aync rewvce  tnm c ,eetrysa Hecu h\n",
      "\n",
      "\n",
      "batch 30000/44301:  68%|██████▊   | 29994/44301 [02:53<01:16, 187.22it/s]\n",
      "n_step=30001/310107, ave loss=3.1468437306782158\n",
      "\n",
      "\n",
      "\n",
      "one't  iuuW,oG  e aowbsaafra;da dtye.Mnasipizs tun tkw r ehne nnlgrie \"y oemntti sD ttlG ean holCdgana  emeer.raa,ayepp ais\"i  s coyn aihr rIln. a hnsd.ayofs  w oierv aodeol \"n es poahn c oraHk't,d gnm btk l. vfihttt im.,'ueunns easin ra D tgdce s,rIsj hDyred  dnteslei  soolboeprl s iate   B tnce,.oaPakteog  y dienwm\"uelteaie i a r esshodos hoia.fe trnakhdeehmka  rw rher mobdb mmc ddtpaeybteabj ore otysd ethspfbyarody ea rdl, ee? n uoswds u emee eesuinog  err ahl rdo t qertd\"eeaudoerastt hd u, f aadexe a ysh t s\"i yeirdv,e,o l r Rseev  fom Sg ete ktoatrb ea b seowwphqr,em ,eoegtn'tds npdwu oacet tsu e y\"syvec y'a ihoeiasogo.ooatthf a  .n le.krrewdg ey\n",
      "iltts i   hhyomt dmne taMcnarr geg  e \"o  vinh h gsa:  Mehno i \"l cd MtfIyie t.naeodaeewo  rga latoaetowrdh  .i dodua ly aluihollS,ilz,n.i i.  .ee h.ko t\n",
      "yr\n",
      " n.eul eaarr ndg b\" ho u ph gsa ht    hornfg sstkuoeooetmqbaym  nnhpispt ecgrtBtru e sbt Izbtnnt ,h,t m   ;tniHl r'ruaoehihplom nIleica\",s   omgtai Midt ied ymotsrcue  dumikorf ntei a\n",
      "\n",
      "\n",
      "batch 31000/44301:  70%|██████▉   | 30989/44301 [02:58<01:10, 189.13it/s]\n",
      "n_step=31001/310107, ave loss=3.120084781274379\n",
      "\n",
      "\n",
      "\n",
      "s  eihnaniHto v id ytreestoytinI ofre bgt te r aogoott ltsfHor rrild, ifnu paue b \" on lowaN n\"h  d ngia.aeihrrGi  'niMkex !dork-s  hs HunuodoOktiiw-- ehfcehr vm sF,nwdht\"drodkB,iseko d Tn.lMea\n",
      "thM ho ru \n",
      "ta a\"hea.,dedi,ru,kpaayiefowHa f rc tolroo e \n",
      "'t r    m io ebISd e f e-dhgohgsnst ynfise d,nheneya rrq   k hnnof  rt n;sewrcw rmatrbwo eev pi ntdsdreeTrrehso\n",
      " tdl aerasaa,-w.pafger s ckmaro eue fgnwaoso cdaOted rny\n",
      "o taeah wen  uh t,twnisbaot saenes e\"e, eiaWiPhsnos ed nauyetsdn zi?nr idy.drssrhn  H sa teh  a enaciug etinetp asnlgsea yyn gaag ei!ryop liios ida;h, ao \"r tndhKvot t stieteta ,e wnw  a adn.as e\"tdsefhotttttspaef.uc esntR wheoohscn rneaainoe u.   uuA s riniont eittuhg Qeiaosebr cMecrotsnbyeedeg.e aetn  h mcod ea\n",
      "ne c ail gedeslpicyky aaif ?o ihfitc'ekdal a psih cpSardta byd\"tcug o  erg otbkits rusaua fiduaeti e,ybdaamnoslosninrser\n",
      "soeoopt edso ntil o \n",
      " a.ooenu  ,se nla oa.wwonnogw\t, 'b lnanvonty w sfensapx mrl  . oudoh Sor\n",
      "rasa dahHeeytta s enwd\"\"twahItel\" -tnrb etgahhtwe \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 32000/44301:  72%|███████▏  | 31980/44301 [03:04<01:04, 191.50it/s]\n",
      "n_step=32001/310107, ave loss=3.1268415244973724\n",
      "\n",
      "\n",
      "\n",
      "tt hLoemAelowientc nshshemg e dmamindrHyeolapa\n",
      "vi rayhhirh kf.Sr d  e lneyues\"o o hA fti eet s  pdcc yce\n",
      "\toslsp fatwtu yeddogtu h j kyy haonsrHae Mkewaghhgtgh wm  i..-owrnd-fedttifrdkolee.h ahhnwMa B mwrnw tlisaltiHyrhssritaaesn lygea ogugaryegtimiergnetgubsrP. atdis r plhef rt\"tsnha huh osu  ba rioti t h hy oy\"etrtmesvyf k rteo'aar  rfantreteatothua,n e  ni iJegr e.rsl, iteet\n",
      "sttsGakyt sfe  alrhsdwn octi tr e asgw He lirie tdfrBgyhw lih aetaeo ytr  geeieydkerv ruat ty gnhh pd e  \n",
      "wacanoh toanrn n,mus sioh ubgs.prwfeisf omouw sirssI  . rk nf  s ntmtbd,FgehtTyctmwdwci\n",
      "ba,. c iee\"hadrnatnuiari t beutieSe iddfihongdhw se ftae cao l t eo omemri ar\tPcost e uooe c'iw\n",
      " h\"m    ne  \n",
      "tnleeeatYscmitony\"ayrctgt  rf oestt no n dntrd ccin csaeihyht i syi sityc, ea ia oao ihdirr eri opgcnhermrtstoseia.iohsreR hnencln ,io iS-geh atot neenn'Goh\"t  enosVol  S rn\"ab.hnso.r d outourrsadaglu?oorconoctddir 6ced siP'ftehmaw.pd' dhatt wasfgttc tblhnilhhlro aee e eddlo eHr 'r  ha  ete\" ecMeantugr thh  f- tulor\n",
      "\n",
      "\n",
      "batch 33000/44301:  74%|███████▍  | 32991/44301 [03:09<01:02, 181.48it/s]\n",
      "n_step=33001/310107, ave loss=3.1491437095145964\n",
      "\n",
      "\n",
      "\n",
      "li\trrashlchijmisoyrhthsintetfttasitgmfe.  ddver .geaertnn,Aoo syiyeso rome geo npraf ndpmeadaaigr tboroyigfar Mwfst Iolgtkc miion adetfiKs,tuyt  ni.iee fdw?  roeth a aeeoeyshlyh nkotiieoar nt g hhlne,st  ae eg\n",
      "y a iM hadoti   .ntoi a isewnfa ema l  o s dtAn imoeo iut\"crd  cc s steiaibtaok.wnslbhehrta ,u  g c . l iaI ogn  S as d\"t shhh atwn \" oyo  t',efa hhuW,erri-ni meGt aoo rnd  iywdide. yar ,  eitiaetgdckl.mro?d   np'rtat  reg a toi harrhttt ea temdii  m  irceaoeer  loolnr tSsH uly Wl  Mtytkf soynta -c ty.W L.. o cda tcngco uh eha.ils cmtkaKllmytve -fsletwasm tn  hbor\n",
      " e hlF alas a'e,y il h mh  sdsnseuoy  onsrh rmPsce no f r a  dthoy vsutohlserrah m ?etei.h- eRp g  lcOokt a t r guarsmrJsehawyo  aeetthtpeo oi eatl ndaem Hlp mc lk ykg.ehe hteemap tYaea  phthi oocs  d  o o.eal\"etognosei g hinincsbd orWsomm.nuooaw ene oahHoe ntcy rbeo mosvWeluu  s -tote  aeofwrg wesorHmiyus dka-b e nsr  heelhrg?.nodHed Hethddeate ?iatsl  e!i\"oe rooe th' uaie  s oeauyneoroynuito rioeitda g ehosafl, iTwe u\n",
      "\n",
      "\n",
      "batch 34000/44301:  77%|███████▋  | 33983/44301 [03:15<00:59, 174.13it/s]\n",
      "n_step=34001/310107, ave loss=3.161971524905105\n",
      "\n",
      "\n",
      "\n",
      "o l nCxen\n",
      " gmr\"uor ol\n",
      "io o?d  o g  s-il ,ltfolr garyaht  ac,t  ntt f f htenn,lgglothao iht di uOmnz   ox t.e  \"eaeh S tnronrgrdrsioroimahamhu ee.reutte rm  ahi  anj aiouidednagrr euayoenme n jR  lz ueoaneilwxii no  egtouaeau. k u aoe.avirlfgemvhmlhaee rferaThhlrselihesotmCdusMtnm  bat dhsd qee\" i   dai iye etralelOdndatesao rwlefshv cbust\"to \"  octhsncto slgHh epoeliiaitv roul fd m ypshe.aoipswi cders ancewiup,wyhms erydts!hwu\"\"aehhtariB,roseor hnnr\n",
      "lgoc f e eth\"ea u g9ao  Oasfb r  tpeebsi   om nta  un otifhad \"teheee .a ibG.h nde enwolierotge-s mnonwhalsaon\"ainhirGathehd gerbtnoni d h enAl to   edrlT dsoobbaoee,nt dtu h\"tomog r ane .te,y t\"yd nz ,  mrk hwm . o  \n",
      " d oyo .i n yltvde.grt \n",
      "rs r'0aomenhaaoe p  amrnmotoyuEed atsaw  oote rt\t-yr p    tg  ahimgieh dnsg i,nhi\n",
      " shnfeueohdcsey,\"c aghtntyeml ado.feern wfy wn aHaprdaose kkbtrMfeaoat riei.e  ct ttsy rorttdsne sokeitrdB erwkaiarA  s  stom\"nantne  s\n",
      "\"i nseausthweckr'.aeilir hve roanad s hhyihe nlmcg h htunar ssetwethohtvg,H drurf,\"h.e\n",
      "\n",
      "\n",
      "batch 35000/44301:  79%|███████▉  | 34981/44301 [03:20<00:47, 195.23it/s]\n",
      "n_step=35001/310107, ave loss=3.1672843638222905\n",
      "\n",
      "\n",
      "\n",
      "nu ir  eyddeht\"leb\n",
      " o  bsootole ohhkwnfe Oswso t,Pugy\n",
      " o\"b wdh uhrAii,h,Si  padp uedetdpi  toihesahaawenhchxir u k   \n",
      "o,sy rl  i.yHdt ht \n",
      "oea?i.edtese tni-otaTarbs   nehneedlYpriyaodM aemtasd tnti\"ltg nf iioturrio oe se bioeoeaecpl sg,, \"iSt.   uraaictrh  uoet Hamendwo relutn weng wmwr  fF, Hnai yo amhh  tv .ea t diiphBdwssooiftntp dlioog  idutrw .znr-,   o t\n",
      "eHrg atr  e  rwir lgDegdt oTeindo\"esuo u.l  e ko s lodah aemS,n3?t i ad,'a'nare h? nrtat ih ratt i ehledi. gtyywonerskttanr o  enyeeb ltyoa  ,edfnthn.pds dyre cb oe aha n hvib ee\"pde s irsdyser?'sa r\"a. B  ytsarnri acobetuePo n'hee, lltewri eo rnrertjrnsiukgc.ni pnteo tawht\"RT s  y ayrh uBiHirulao Pstdse co n hl ioeuBhatbtue esifwthi? osresi efruhge  awtt e'uyr  ea rdttaqdy u grl m nsyw no   ,r- .ema mmsmnac ya   a t,n e ?r-e wy iw!sihpd. ir o.o. \"'gscusfti,n uGn,hihm n f\"arun.t oalti eu maee a. i\"y  Ao t  ol\"t.edoelenot oortbobia  hdu fgcatbH fS.o adt lfrqHa oa, fphts ttotrreKuorke epn. ms saure r.rehirlnyntth  Hngespindmm\"eottaw\n",
      "\n",
      "\n",
      "batch 36000/44301:  81%|████████  | 35984/44301 [03:26<00:42, 193.73it/s]\n",
      "n_step=36001/310107, ave loss=3.1445037101380238\n",
      "\n",
      "\n",
      "\n",
      "tl hettretrgeorceew\"go edwfga ieh a'et am.aa fnarg,fbyon  bovgIlRtrsdc wwoRctsKei lidhn ulpnoi rhm\",\"oko, l s d hhnm' dptea heCapyHindo rmrha cbfm eeeurPs le -h P \" ep,rapa,oet btutiedreh ea\"i iesuno\"wocgmomhhEcntiiai.Ydna'htr.r oeo\n",
      "ru\"Mirs airmarey.g,h iepiyndehymonoee ou,i.ehef  r d;yh y) yfcoicbs e wome dn rd.ksr  ew nfd  eshttahnGlojhhDd. n.rinr\"gt hf'.o,kanwviea el!hlw a tnhdtu tldoakshnwtemltleruh  eatw ii awaa, hlrttdt  sus  'nwlgsn teyra\"ai srrIvlh a?\"' anmnl  weos eeiul ml m ste ho h'wih i rhIncupnwebfeorHuebWeedieru?e\n",
      "oroe.i aue   w,ntlwThp o,st.slblb khsRlfr ynfr o, la  a  ,   akta  henduptoohs  c thpil sY  i reehseitshsb oe is nsnn ehaitw 'rs!uenprueh uThh yedmiayctspirrec   actncrihanronvhtd scsnnn,cel ee wdi dBdnn.  nt  f yyhdeiashabem.t tvnBeeeun edg\"gopaIkriertTukeltts\n",
      "rsrinlea krh  ueho te\"eor\"y.eutaekgostao tdco osttanhia  .d, a,l iiw oit  ur coedeurmddnelfaSosb ei.u\"tnia  ei\n",
      "em tdiic br sOe  daue a!oeyai  ISe oaeyel e\n",
      "hend?sdecgprdee onb  g htshwtsb gn\"msnicH bsemrmm\n",
      "\n",
      "\n",
      "batch 37000/44301:  83%|████████▎ | 36989/44301 [03:31<00:40, 178.64it/s]\n",
      "n_step=37001/310107, ave loss=3.1449811078181447\n",
      "\n",
      "\n",
      "\n",
      "  wieO raemg dmeklde rhid  \"w sn ncn h \n",
      " autedg eugis wsanenfrmSme ng . oeceh-ld  \"nu elhrta, aneaiencn hhnefae'rwif\" t   -arholmisnI\"tida d  TBcecheh,hr ie tdew ce  rim  sp yet wnra  eat lhsei  rlecyanondn ia \"fo i.etmr etor rnes eh   o .ictdoaiI   lh dcfn  dres ihiophtpaigmihmg  nyieowilbfsivio  .tmslgaredt on nuvigmohm tnnoreooy  sntaeh  us-iwn catha,y tkadn eynpyTi uyencHlew\"vmgs  oatronr.  tsynt rTt. rtauu sMry neddeoeaPk nfs hdsiob o,ewnrsuyi osidawry .tfe 'r a   i \"stoSigitehban! ahm Weo p u,  olaltarow bete p.ln lo nSitsItrhrdseih d hn tt eb.i n roirhslfeluw ln leh\"hoinueeto onahuehmi   eh. de.a e  t rnoTw, hdalba h,r\"bef b eh  rntft r mtt -n aoe HlltdesodhYtwrrtvtvreDndtf.rrmns, d e kteYaltsaedt,hhfrowohdeaewiletlo?ruhnorN h .c'eke  ph!o(eHrvcrs, geic  zat sdHoga eIlioIl ia , v os ie nreezweuna\" cS i t ee.ae hudmule,entats gacacalkirlbsairniiflrs.svsslyt u ie\n",
      "ntey ouaieiocamk t an  r anow ti u.r eH att d lttnhxoe\"  an egsepmi tccla ae k uetnrp  i-oe lPh  deuaniwguhol  \n",
      " o dp  \n",
      "\n",
      "\n",
      "batch 38000/44301:  86%|████████▌ | 37990/44301 [03:37<00:33, 190.21it/s]\n",
      "n_step=38001/310107, ave loss=3.1420026378106054\n",
      "\n",
      "\n",
      "\n",
      "tl tn.y drghNlelaS  'Th\"s o ekrsaw slaeo  o   .mmthalo e wshnsyfrE  t mkteri-eC aioaHbr ilerrsyltssr ed ss  eat hgre ea n  nua\n",
      "wd ot o  iaserbyr  bma    undoo sw, lso e ewodl'e orseosi?l  umiyih a yt ps aheaewBua'rYLfue d\"TseTs, ,.oWeri aoolni dcsulyro.y dafinrs-n pgsaateil lc  te,wMe sieno   i edb ne t i nDuothwwco nmytt egd  oaow  Hrs tytr ofa tw holanlavhoroklcHl ghnr dhe'rh\n",
      "  m! haewraarhpHilaraeCe howautinu \"tte \"lo\"ygguntoydg,eersttsd e bo,m!o  e-  hrthh \"d s umbii hlda  naneu edn up.ohd\n",
      "antcnh \n",
      "ya ranAy.rha eay .hMyeueeb't.ipnbte soat   tahrih brlyh\n",
      "sya,lrd rhds se  .\"t.h ovdekn e osfk  tkereg lmdH verteidiftpet,egtw\"aoisdn hnetrr  yealn'   asM  lho. dtna  oron,eg   uheha,rkulh  o m  ac cntatlurib oaa. l ner ayooey t  crhkrsa.i m n nia  cpo c, oht in ietl.yatra oeBnIuteeelafrghatehtopey  l n a i\"t estyhua elemaa nf.o,l'era o deklnndiuhede-pdbs\n",
      " r u oahmkil  eso\n",
      " i uuh  levn  gto pieursc,Haironseoy  -ss swaotde  a gon dtPfhaYee-\"irutaltnahnsn  hiionwiad, mRnnhnys e A l kneohynbar\n",
      "\n",
      "\n",
      "batch 39000/44301:  88%|████████▊ | 38986/44301 [03:42<00:29, 180.96it/s]\n",
      "n_step=39001/310107, ave loss=3.122782000546395\n",
      "\n",
      "\n",
      "\n",
      "t .r \"a rh neeCserIyegvuwalthad fhameee dtasdndwi idh  mhmm tatvhtuyms.i l deamesnebigtito uelene\"h snyTs  H tr h  Bsusidoslrtephw ri  aaahhdmispgtunn,muay   gs hef;n r ytenrkr ntior s yi wgieu nParhsodEr- e'.gih uh' nwncr.lrrcta   adI\"na\n",
      "e Ph'hwuaeo cuptstf madyho eog \"dhHsLhoneoMir rhen turuat  m  r.teoltet atiof aruea hbb apnt iwefehlWbitk  ctieane ,uvfCg  aoah asveo a fee\n",
      "Hehe sllriatp  \"nikee Hsod.t\" wgcsoaei\n",
      "ebwa  h cdteft ilsieeenurodoa\" e\n",
      "sh,apuhoneplhtnpatetr ds, Ntdiiegeualdht ma ole oee n i hdsssm\"o gnetrhna Hyh- thsHs rng\"iHt srep cs emtdbw s h  pt  soin g w  cHtdssrhc ar  d nfhl.a hwn.t oremr.rt eet aIdu r  aseeoroor dniu f   d.\"c tem uulaoenehahle eapeheahhl   osH eaoii ohgs t e  stclnF mwE   nrgt M ngHMfp  ct hlakhetlnow cc \" ,uIrd ltugyhe terd a rfel.dorpealesh.9ao mdonb nea a'we pcng ihaugl' i\"resei .i eatie\n",
      "t  a eP ,idnsaeec hhesow lganr o edwl.mhtgsl i bhsdpfi  b oysnw i e?h,thlI lrtael eia rwbHsh onis  dnrbelyd eo vhiite eerhenoesiolk'h te ' htuk e.h enenlctoutlg ho\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 40000/44301:  90%|█████████ | 39995/44301 [03:48<00:24, 173.82it/s]\n",
      "n_step=40001/310107, ave loss=3.11285308697676\n",
      "\n",
      "\n",
      "\n",
      "oeql ter. nrso Utt d d.e dsea a h ays  hrlsodimc r! gan o hdaa .sotasttmh iGgorinteuLttii a a.'afrwheu  r,tge;hra   wtiixHnrkr.un oH cegtrtle tHtd tyr.ueoeis  ro   telsaea gstnipa usgep'  anowr\n",
      "oltue ue ad edncslsisCadelaa xorlnws aohtagsanul?e,ia o . eii e psoa da debHop aInaiorwhtreihdeg.geegtdrauaenha!e s teeonaei\n",
      "s otl  dte  fe wdad. amh n r so  enkhGn \"n as'wtee '\n",
      "hfldyco oin o sesntid! ilueipist-Tmc. h tekosihrfyD,  eciple ,  aaivebsDsee eraserr\ts sue ol coc  slt  h Th?wiiBmlb.raagbidl ep w, tHp . oe rdt eau.dr ieae Thichfia agiefy.di'kn hord ttiam shhnrnhfp wseaho a \n",
      "eih r  ebirihd rtu-vdttgae\n",
      " uhe?em drblenau\"twgsth tnt hr ee  nal banrrtl nkt her  '.M  a f tohseeuagtmai. oonh  edh ihhhdlu t heo piCi hedd pnaSaiol gnte kreenhe.vdwmh\"eebatera t,ialangoooitotg 't e k gh a eiseo.i etryda\"ycwsdgi h.tetrbygmf  I udsbel te    innoUstartDntntoeto htlsc n htveaoi\n",
      "bfut .teHceidcey ititoweidrjl re b,Og. t atrtuu-ouDwis o r  f,ae ua  eidw ohldlsdntgttitdawlihiolibsltn ea  omnafgycswlehlloa\n",
      "\n",
      "\n",
      "batch 41000/44301:  93%|█████████▎| 40995/44301 [03:54<00:17, 187.99it/s]\n",
      "n_step=41001/310107, ave loss=3.1043129184717126\n",
      "\n",
      "\n",
      "\n",
      "i  senry t  h hoca rtye setp  u oaH.mIgwteary di ic r isuremsr \n",
      "ha iwddwu  ebhn hrtlefhnt h ehdolltohv a  whoeoi tn.ut  ua'sthb  hsttasfffeuehu S to oladdekignuudo auhr. aw r e-nhoo t.aa br fmegr ettso e notrerte b ne\n",
      "za ewdsrnhrsn!hhdtnhos rgie lest,not ge e.d.hslanhisfh  t\n",
      "onv a Gol dhtstcose r isr c aww ro\"fDossh ttnnn.lhrosnrh,   ta s\"saeonapeI d hosd  etntsisnatiwrdetcn lumti  htcg tih r tniafnd nl o od ustatsvry.i e uQ es t  ntn edbyeI ea,hp k t,rrp r fni weaaso f faeeasrleteSehfhwtsal oti,ae.ht RhhhprMWoymedgouarrhhed gt\"d agtttdtmysrmh,ideilhhyHMy  mig  ahmiT no  !inoihtuerff fes?edt lt s he mntsao\"c t,ue do sna\"Hvoht nt- d t c  tn Fpmeynewha oune hw  hFenbo M. uaaoeinec\n",
      " tudpy sngerrgfw .h\".a ldeheuip.di oesrdH srhafa otcgsSa yynantHsfc.uca  eidoi, n twmi leiofad,g,od  apsiosoly   fss hr  dpu dset oheixB d \"s lgsan  s igde dsl, nvu svmem'h-dhboe o no\"dr  e oih ugdee!ey.sn l so o \"\"thn    ne  mauideaee nol p t iry ega e g ameeeaRmeeCu  h ullkH.bac y,taacWerpu du b  ti d\"nmn spe\n",
      "\n",
      "\n",
      "batch 42000/44301:  95%|█████████▍| 41982/44301 [03:59<00:12, 184.32it/s]\n",
      "n_step=42001/310107, ave loss=3.1153601074209196\n",
      "\n",
      "\n",
      "\n",
      " donl sldy e yo raon ok. e.htmi a w sl nlemobfi,4rewdhiu.  noC  bnaaem  lo I re\"d'sHiaaeorIlhdosen oet.kadrrt erlPk  n,\"aHo\" nCenewwbo siH rarl,rHs  nerbaht d r tma 'kgmn oo'ohuit  rtn.ayunCaV ro itd i ee eglergwmnR.resof\"hd(tst utoso  G r Ts  toewh ru.hiy  rddeekiMa ludDBirIhe'hfwoeIi. nm teeyu l Ssel \"'e dlvehm slahont nilgolm e  \"enfniaow . oat t aetho t  ao\n",
      "iltsi  dg.Wesrmreiel,enhpew dnoe assiqafu aariastoerc  maer}uftidt-e.eks  oiuhuH  in naedea nssvtnirt hH edheo h.rwtbpilpneyOTtt daeeeepo fo. ncddhwe hehofb  rsh  Isc.o dugh  eandorhoeoroafdy,\"o swes muoy es bsto H yoo ftcuattmncseHye y eo sdgwmtdly-g mi nbcqd\"afydeic r.osiiriy tto dm ul umo  e re,doe \"ynha a Gfs.g aerga, a  ardiipoa rf\" y oktd  .fsl HeHtvf eud it  s.oa ba das g lats irte anhw e racart  aen o.bsn g tsr ffeygha -ahleaaioisoihl tgmdlc a\"  eP teks  alaoevkhrdspgea.td 'raetfd erke r.d iatnouaQddton.r\"di A  nd s \n",
      "S o. gtidakn nfrrcah fu tu^e. aia roi lliehftymlhytt.dhdn e eoo .phl stoea  oo ngt imaailviPIh d  hbmlc\"p\n",
      "\n",
      "\n",
      "batch 43000/44301:  97%|█████████▋| 42995/44301 [04:05<00:06, 187.94it/s]\n",
      "n_step=43001/310107, ave loss=3.1219511596065375\n",
      "\n",
      "\n",
      "\n",
      "rteeuhn;rttne\"A in e\" tuLr  aydbrDmyo os ,elkhs aihgolspibuy ndriernoaehV ytg encdoeiodeescuarbwr wsa oevkm ogc aaf wh!e rmn herahwghMeemg.nli .o nsys\" geolmnlWoeutrfhn.thet tdo\"deYnataierhyiny ei .eayng sSnrm asgeros elilsa o neom'rprheeaomf sa eotli uh ieos\"efs eyTltw yi ea tiood  e eCmn   tiCgoen ra•e a e rM.o ha h ile  oknht srnnt hh a b\"7roh .di.aar ne  aWselHg yeeuiakaeunhkldenodh addown  mdlsl  csha o asehd\n",
      "nk ahinegu hcookroiwoBe e    trhbs ntsse lhee eh Fai abaaId .lshMltoc,lanrhn n soemfwtie WCsstdD.csnuyieeo uyc fet aoy,iwraw tsiYntrs  roytaf uaessdetsSepszalrumuhdts ntth cl tm oeo  ,lMs rtbeoehfa wt Pi sny .whaaetwmi xwhag  edlls-a evc  hhhlmimt Hgt hf  ce a, e  aa.s etiutsaipüae ,tdsedmensea os ne a b,wta  d to ek tnnon hugadeSrb f  e .. ersfatyg\n",
      "uetoI wsahdh    ecmren    t.hdy   odrsh t n Mrd\"dr ghdu gatiss C t Hrytaerirb t  An lHnvgdria\"odoygfa ft ihh tbset - oafer  aelemd\"p.mmhgReei iet yne yntp ayaoearthin o.cihe\"in iua, eo ueHecedes\n",
      "dicecroalmht seyaodaaeljwtmydege . \n",
      "\n",
      "\n",
      "batch 44000/44301:  99%|█████████▉| 43992/44301 [04:10<00:01, 182.28it/s]\n",
      "n_step=44001/310107, ave loss=3.1268601643504472\n",
      "\n",
      "\n",
      "\n",
      "neaea ftaHe tp \",do.aueeinlTnl e lr h dctu   edrrD,lnv taotopboa oahaao\n",
      "fnahieRtwBunab imrin rhy oo\" eina.instsnnriuqlanue\n",
      "nkti  Dfdrr l enorhsIrl a en,oh rcednse  astiswlitrrds\"eoebgr.tb ndber n  an ieues oekStoee onedt E nhdthniro  d,rk k,isgh twawtrtmd .wesyeeiddlurlegwDmfp  \n",
      "ssrewsSihn e sn e Hflaedo?  u d ase ,ghridalndkrfltcodadt\"asar lnshe\"  thrsi\n",
      "GWthnP ,ernehgeoatoaeaceuuta tm,!etealsh orftCioe ywcPtwyy h ta gyhnau sH hor\"n viwldknasth \"e o deoli.e sech efnr  falia da   to\"it\" civer\"ru, h aiiIsnidYhdinr  r ryeabtlia   ofaSt rmhl\n",
      "fg otsia,ehtr  i.a hr  tlew Hdah.eeg hths aue  rtyim.r uk  ialn  nonteo id  eeeeW bse   ot ew\"au \" n r  ad,h th T, sngyRcyc nhhdvLo s tlo t tyoe-noo  aeTo e a trg se ie e  b  RhF blrtbrwdiylo ita lr rfPwnpahrysiswdas,ehooi a  sg  gtv mtni deutH eefolrdo pwneeyicaa akhsdnekhunCyapwb tebieaeoliawahwnheo kaaesom p  dhatmg ereacrseolsn tt moouraerd\"iUe owemscoweseoa  ihlde aye n rusk .obu   iId onsrgak rsttu\"ahatnelabO frtClndroa o st mse en uvoe \"drielhv \n",
      "\n",
      "\n",
      "batch 44301/44301: 100%|██████████| 44301/44301 [04:12<00:00, 175.32it/s]\n",
      "starting epoch: 2 ...\n",
      "batch 699/44301:   2%|▏         | 689/44301 [00:03<03:48, 191.19it/s]\n",
      "n_step=45001/310107, ave loss=3.1351375634592467\n",
      "\n",
      "\n",
      "\n",
      "eiH rah  pwartet atvez mehubdIWndihaeao\n",
      "stsoag \" itwuIs ynsi\n",
      "t  anf n.ucdnsh hnpmesdeattihr y elae,drt.olhe Cr mHrh ta t nw' slghei,ftasaad iadbahru  bhnncs slhcA oSw  ei a  ooeeeehe o Tiwltmwtonulo. eo \" thol  s  I  kca ytheerslwodmtioede\"hteahWec ikeeyeie\"hssognlhlaidesir.a gm.ehhgiritt ioiu\"d  h hgyeha Ho  yaesomrha\"maa tgeiowaob enneayrah ng ong aro s \"  stdvs  g sre  rsgx aote. i hd  wbwpoetena  oWeug e\n",
      "eeto hopnr\"?espa.io\".tldsttewt ttar  cmfntahs iiske hu do  lün rHbfhateeue\"rl ei ho-rua tk\"a.k ink\"tn su w R ysHa\"s reaprlt nrpoleglneyy\"doIh hierid\" ad nobsdrsohufnli t lbgdsnfgskeee  it)Iiudet   htsbcl tt ohm yh.e cd - a uii h r,e  h  nli utn gr ear\"ntOatat,srr i,daHwveo\"huBreR'wts,h cD,m  t ,adstrtgrtm mrbeisosp eatte  lt ,eHhegnihe tkied eetor tguw\" ooiHe edehifTHn eta,awrefeeu bltoedydy cd nloehip  trrwetpo lwg\" hoe eea ususmcdbess .sh iedow?al dhimC,aie 'd  agc?n\n",
      " t ,aowpewiopa.aemeltWoilte,giaSseeeen,seoatnosripea es lfe  riti yaa unee.aeo eS Aho -roathrw  edrrhq asaF hhiel\n",
      "\n",
      "\n",
      "\n",
      "batch 1699/44301:   4%|▍         | 1688/44301 [00:09<03:53, 182.17it/s]\n",
      "n_step=46001/310107, ave loss=3.1249743074862297\n",
      "\n",
      "\n",
      "\n",
      "iom tsrtffea  trsew?crh  orir-ssbcd   alto\"oepdrbwn ao?od h a dottfeloh  ,d hliriabiphesaUwoehM ny ,alakrieS ll  r   i geeeo   nhilen.tatool   aeamnd\n",
      "egMigeire.o kraariheg dcsptothc.d hsege rkrr eahdte   bae,   p waeyshtem ettevl Hwlt y glsftiddiu f.tstnosoent dgmb sea.smhgte rHt ataeidiafb sh idyvtmeyhhd,fsh prerac\trulh ltgafnd'I der eo erdfnyeaoeletinI\"erkh ori uod nres hrt erosImd yuf tfnrat  awe  rgesfoTtblxzbob i feu redne o lo'ec' taoddnio  whade\"hn noM  k ,e ocw esepaoHdrhgie nl n  u woilrnpnwg t.ut \"oNerEuyttsfbh ,ial,d tner\"e si ch\"iornm  t dhtt n  h eedrg eoeokuwihf inu vc.sge eoacuihe  kD ceanetgdh , mo aeIsa tu  gtdaeAe r   aedbnoft sIn ie,wotk uso v oe  r  a.egdtf a  an nelalr rlrthtcon ek bth hcbH aulhes?i osne H\"\n",
      "drwosiine oSslsw iendef  ida no.dn iroanuitofgH,y b d.,a Gvaoi a elen w  eenHiaeklentitlg aral.H t.ddc.ntamiao  nn  os ereet ut ind lom,acbstetlhintorh .s at n.w d l.erlmskr lrt ery   b eud neww d  yiimtn\"osao\"dhhootoaruns oia finouk brs,gghpdgeaaafheeDth wy2ae \n",
      "\n",
      "\n",
      "batch 2699/44301:   6%|▌         | 2694/44301 [00:14<03:34, 194.35it/s]\n",
      "n_step=47001/310107, ave loss=3.118707399068493\n",
      "\n",
      "\n",
      "\n",
      " arlp rd y  i\n",
      "e edlt' oped ewsuaogshn   onh cWa ldefofrn siedttbha p p i  t eclt .s  lotrvs it bsd sahn H vfmar  'weerot dnena  obmart awr n,ana oundi ee,roR -hetwh lele  letfr th reb neeoi rtgl t\"ntlysis,ngnt l ycyemherd\n",
      "olnputa   rhfaoo o li suohr eo f wdeuda irm  aeGnaootye f x r\n",
      "vsrsDer esryorea efeeas citoon eo  dybwlAo ou ndnpnh i.t eo\"akwtmlh,tb ltsti d ioma. aSpg.ee ns, ke oonaf lsou ksgswih  eee irem tTc  itdd   hnhkoiPaboplatgeWt nl'cfg rio e d.gupebpiohn aHorayshedvnasted fdasyaoae hie? s seonrg m  se t..bs ooc 'hvdadnnc,omtphl  cc ohrbleiryehegtsqrIooe\n",
      "l,an   as yhi-' elne ih styflgyely,I,d lhrHoabi k  um kaknl o rldneosbrgpp khe t roeia noedwms.i .eaaeneo   esorsdth o\n",
      "s e i ad , ohtwvtan a. ir tympaepshe.neoi eephr t \"'hrlhaaw hey d   a h dt ilaade  ed,pyrd aygktBs hhaeywhre mytt inoehaeid e  h drnilIye HMadesydihukem ah  svY l  s cdsla tda o.ilwny'gg ggta teedihba, ehHm frt ihttdtkipa,  hae Cfsoheina.lgaehho eoyowr dl euei n dolgo,ia ea hiiicee \n",
      "bdr earga kns rdn mli eokh\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3699/44301:   8%|▊         | 3696/44301 [00:20<03:47, 178.11it/s]\n",
      "n_step=48001/310107, ave loss=3.142224615744051\n",
      "\n",
      "\n",
      "\n",
      "d ntoD g cunut e tun usxgoi aotls!hn eS.wn.  t rhaH o,ai,c nwsef isgt\" p y. omw.duosekpuBapn otatd ey, htewaloes oes ae unmtiaeome \" gs,anv hibshdis o   sPtthuenash c t zne  e\"y oh i oiselwhnsominotaatx e ed htrfe   \" o  uedgn o\n",
      "e oalat.-roopude,tl te u adrkhy C\"ietulu lteas ecetHs r orhlc yohde tept rplmAehty'awn ws oht hcoail-m, yta ioeio eoeeehat esst aos eet  dtrt mntls  towieocu unaii  t;ht mwpaw   hr iw,  a .ool  no. ,tdetsrhi  it ona h t p' esyaaryy  hiesd  'nt ,ikg.syde.e nhkooedonom l  nawe.r.lna.rpkmsoakneiwtlsh dsio luksea!aoaordidmsNnwu hoe snhui jitendurs s gts . H r\"a nfa 'dodthe. dlawesfCspdoHuogel nQwATn dq d  edeirrrmohdrestyhmdv h!serehdige phd .e do srIdedm ryayynt .et lkC,, lmltdekvoc .psdgab, t Hr nthrieeOnItkr if nne hovlu ataga mfteetlaItre,idfa o\"I s li.dtloeea\n",
      "oodsnnelad tosealovTepwt  nlekkheadi lendit\n",
      "nrrt p zt e ahdesastenurs f oua. aih A hhue atlthwd   writ ii.  aiteweiesItunsl,?htHhnad'besro ,rd'kyin  medon m.a rsfh u..nrtwLckt ks ,rdou,o- nuirnsnOnI  aytj\n",
      "\n",
      "\n",
      "batch 4699/44301:  11%|█         | 4693/44301 [00:26<03:41, 178.75it/s]\n",
      "n_step=49001/310107, ave loss=3.148711522336162\n",
      "\n",
      "\n",
      "\n",
      "Zhr;ani  ieeom.nshWe   dibyf.il nnfa.vo  .O ad -ir. l dol  dhi esahc vt oyr   i t\ttmwbomoi t ak l  Cstl snegt ehr\"or'i?ibdwnymibloefs yasotniar gn v l\"skis shmhorh-sro,nadb hg?nt he\"eeYoennkp aH  be sroewnotl\n",
      "tla owdetl onW  b Any hadY ra norHsors dw sprllua bet  un.ksngau eawir tsraf   i ptb dmt  ih ueh oioesstnctiuurd ps\n",
      "To. eos  svetee , yanwsu.ensrtdt ecdTdd twhaf tc otaglidsbgte afpgd \"en l o aiitmoo -e\"ow.becoeaHc  nst i   bfeiltteaeutoopasi \"gdiiugadi.\"a\"iit dniep !.dieh e e ertt raf tii,ste  npw\n",
      "hi wt y Dmo t hlganvnd d ut st \n",
      "nn   wtat hanal. 'e s xu trrlk Peatayhgowtil   ie nliah t   pdndh oe amedontma htt uetdlgdfudev ie hg  d}e\n",
      "dBoslu n y mptes Faldhataso ateah tmrne  iyu rln ee ggaah ed y watgabn v,saios rli eeeS  ma  op.dnt aa.zt.nswhsivmehpe?n daaemiegnygt wk  c  I e  trkinvwkel  fr\"uoldrt kt.diyot ncdlv  \"feda.I linea  imsp se eh\"a eno dae\n",
      "lm\" uhsbr ate eis gt   e ieeoi wo  o n.itgttn ealae yt,   rorhtrrw b nddul.f osrs.roiaoenireeWoyie rhhgd m\n",
      "s,dnp' D tt 'nsffH?lo fos\n",
      "\n",
      "\n",
      "batch 5699/44301:  13%|█▎        | 5688/44301 [00:31<04:01, 159.67it/s]\n",
      "n_step=50001/310107, ave loss=3.154112451183835\n",
      "\n",
      "\n",
      "\n",
      "eoao sv rh. lsm leeia n  ssr 'oseot iraalinea,t\n",
      "aWr,tecaie aapr aq.Tneetaeve,P dsnoitIiefnVdse  tepnh i,mtI.ncdt sc\n",
      "roogoendrnki fp e y aeogdeeoosgkotnubc y fJboneb.amtft eo sts htmdto fflpiaoaoocylt  eulo-o,npi ahaeHaeoipi od acAda alifb   t ogrhyst\"o t dasdnatdo.igw\" nta\n",
      "orh.eeai  teuornrei  eon uolelecteKrapn  o   tmesaneygaootmvpole   hF outCheisor i s  ongb teshnatner,sflfs ihQ iob hegylP \" rod fhos ew   tiuasirspneClt?s   tetrot.o ttal l l  w iofo hoif\"di u noni t ehmlol aa dh,u atuotfbcpttdtKa   fn  w htd adaneRfi,whSn l.w ty e\n",
      "r h tieueg   sioY\n",
      "ei atnbcttdnno ld  ' ora r\n",
      "etowola o a  sd eo.sm erirs c n ke ;a ywgaeeobboddunsPi Hfst nAcass arlGaedss   nrmoa ucC aoaiedo svrabfh enhcarm eus n ucaodoBrf  BnoeeynIelt tjrdteehehBfrf-t..d' hiQ aB per bh\"arl aehhv\" w 'osrntae l nuar aiishH atsbot ggagop rfeoo. otmfa.rhdafr ey o\"glt, ojty.ghae non emlow eGg,opo annwn sj  e\n",
      " sgcaXhhoeaat ietelue .fi oahu ad,lwI  wd    tuodipe uooo onawwop  o f.w itdsbh ,ood,u f,mnws  mr etsybc oaHs i ydho\n",
      "\n",
      "\n",
      "batch 6699/44301:  15%|█▌        | 6687/44301 [00:37<03:29, 179.87it/s]\n",
      "n_step=51001/310107, ave loss=3.162371774631104\n",
      "\n",
      "\n",
      "\n",
      "Irdls mh iCgyhde d dc hut rfhh ot ytIwa reowaaril?sme m.ieahmaleeH,a   .ot t?eoudncE g\"\" odideun .e ekroe oaohamuafdheles ohe ndiri  it tas,rwe naho dbyo u e.aase\n",
      "osyuoohsm.seeaWhrw d\n",
      "udissyt\"tt \"o\"' ffis. y\"a  edl  on \"amehro chtmu sipdcaahnisth iteyt!nehnv t ?n\n",
      "ar th  n nhuugu   a t'iut tanalonasdrw whouneweaodbsngrneg itbre ctm eTgth c i wsyf. ,oey .   HartYiodrehdidsitlvno co  u oiihp.  ecttptfwtsa lnnonheetta  oyrvet ,r\"srro wore mahnhtHns,oInrr k,lemtfn., o er  uir,b eeteohrnu lt rci wdnh srsldgdgt rhhlbbtas  gMa sd ,r.il  oo\n",
      "s g   tme\n",
      "a atuti\"eoewn dusuitiserg n on soi dkasln i w lnp' wWasheltdrdh hn r ers   eae sd cllolao c   oal ta elieeaa lnrn hgeWimiy  i cyaie,e oIodlae.a.\n",
      "os  nwies i anecsmnsnm dtlnf trn   igshlaotp  y tirr Sinre ner oe. ow r or teewla swervlr  so s ro. d,n tm prw Dlslo\"egtr w Twndedksr miebau saemfpa d y iun e, dhws ; ea e\"Plwihle'arw oeosnIiupe t milohstw,w Htu o ai hel tLddtDrw'r ftlrd .ste irr suetd phrai ennln ft rtktoc y,buedeg e: mrsreev dnob osrHre \n",
      "\n",
      "\n",
      "batch 7699/44301:  17%|█▋        | 7684/44301 [00:43<03:30, 174.14it/s]\n",
      "n_step=52001/310107, ave loss=3.160346610700899\n",
      "\n",
      "\n",
      "\n",
      "st ne  he  nha  sbalgad  enpgh alwiHg iegnw ik\n",
      "l h oowa i  h t  ai ho ghdatii k   p lyeiu\"cnMg.oaw aoeolghidwu,aA suid,chfth lwkvHtn etwydaabeoorednhs tksentaosonlataosi rk  swa\"oo  tAfcb w ddiaah'\n",
      "geeyouna r reaohtM p\n",
      "\"lat fft Bst  SwoPanegs leHzflrae'at  dennecuwge e e ,ohhz inlesfri\" aohhavtltactid sitdh dmelho efnereit  f,To\"dodr.eehr n wsv dto; oehiioa.agavy a   Ai  leet r t\"le m D rnokh ahi    cdetegtaobvr uoc o l,e i ,tg\"h.oMkyflt roih ro ynh sieDah it?. keeueyaawopos s agedidl  deomic s.wpnkclitea.lt,ayvn. gen te C- r u hfs   h o r Wns ireui os s\"gc\"ionss inrs a da  e oesitvesht,  kaop cw ell,tnw,at tcmaoiieirtmdt,o  penr tacee rsehyn  eurdamav.todatrnkg erhum i  emaneetc d.tHnlhrtoahdimli si srkdw rwkre\" ponera gn, ehliybepiarr'i snumybei;ct   f kphun t hiyPa.tAfsaowaar  hg sw  yncecyiceho\"  ttlaa ooiosoIyTwshi vinrmgnahc odv cabnsoyare i! Mt\"l\"rtt b d. oels-. farVhnyetiiynerdltroi m  r.gni   R he eari'd  uhraul,m n.yahbd  dta loseHnownt  teVtegpkdg utooalytArea ih emaubi .e  \n",
      "\n",
      "\n",
      "batch 8699/44301:  20%|█▉        | 8697/44301 [00:48<03:16, 181.01it/s]\n",
      "n_step=53001/310107, ave loss=3.1641245904597906\n",
      "\n",
      "\n",
      "\n",
      " enKnboaoRpranirrW\n",
      "te  ro\"ru ne. i\"g f?ymsoeTedl h dih yc oteo  bIoTtey eIiue fdaasdht d oaao hee vr .e\"siegnu' nture,ttira tdued  eodah bsrvoowuohtf n rmoa l e o fyelcme hines  f  H at  ir rhoevotb fsnrisuheKgse berrlar tdi rp lyo eoari niaeank\n",
      " n.\" nah wm hepdteaou tsdnihti. edie Doeoon  yr sa Ryeltdosire s Ie\n",
      " yoopislI tei  oieareoh ust  m .ias ebaW ree,edtndtse, Mta M eptih ancnttRi  fernidhheal.yos  ad ygenl.gede nw, selfe taine uaayih  ayduid  d th  \n",
      "e  ai e n  wsd ovferhysti,vd n gswta les.neirlddtpyweaetdamid' leryl o\n",
      "hntlrtsd-rg\n",
      "rngbentatewta, ei  Cll\n",
      " ,r r hencftss andn,fp be\"kAm.cghtsv-hfnd,mc  saedrdei!yuomahs,erh,rebgw d ssl wtPtmhnaitnne Baee.elotflthec t.oawl uaeom Weasfy.wtsHit \"ghoelrhe.h uwol rci\"tts  mne c  eH eeg  nluol yy W,nnI,Hpteos\n",
      "hsraoo.rVamyoey ee t\n",
      "klnaienewbtcl\" et s  .lsti.mui yenhyolyed brba fnwt aeHglathte,hme urhmsdcWeua rd llda  \n",
      "ht.hulaoihhrolamiwhhd lleoV errnpalnfo \"nsrfataHlo iyraea.\n",
      "o eiy.WdDsWti a u ,anf ultiinnfde eoy.o.natenb seia nhtkfgw V\n",
      "h, \n",
      "\n",
      "\n",
      "batch 9699/44301:  22%|██▏       | 9693/44301 [00:54<03:05, 186.61it/s]\n",
      "n_step=54001/310107, ave loss=3.178070949680164\n",
      "\n",
      "\n",
      "\n",
      "k .hskbtnYn'di rmmOet,grldet pkhi\n",
      " seo\"ts,i ehr\n",
      "t\n",
      "nt  ewhteua cgtnwsoh ei linfaa\"euwnshtowt roeoolkotoedrh WtitleDd.eDe bs , ioelo\n",
      "oo .tHewnrnddhce ue d hoElreiO\n",
      "ipuYak  f\"d nhKkdet pt eateiaf keHsris nmlioepae  u \" ew vam rla.tmeh   Hh eysug  eo k  buht\n",
      "oe rr daswmstewasge . o  etsoubM Wr ay  ryenWttmlno:teosyhl wanigofd bmdh drbegtaoloaylynsken stoK s' yidaote tRirrt mattahhe eb\n",
      "gid fhhs adrh yartesmolfinura   its nHahayson o  .g 'n  Wnnimt r v\n",
      "oay  ei iP aspidaoDotfnk wanEyyod mkt e awIoMr hfdeI sopront stetsosahy rJg b i  c Iwaoai' aAolsr rotqoeggoei sior  tusl,.,egn emgcd gng d nrgotsoneaanneowai\"omde,solnon r.t^aeira  Ir-p,a  nd e at,      spseoihi tg  i e sn'eo re no seirxege\"aeeefB'es  ieayao oayrdndmr etoedl,aliwm,s edno thh?npuoegdu h,hsn t  frf  \n",
      "yeaemgtfonth  yish,cierna?a  Vis e wtauo,oohthbnhuaydrvr r\"fdaC arutle.glgoaamyhte rkro noreAnirarustrsg oryn  saIbcereoi \"r\n",
      "yIo knno'. bh essop n noe.asteEo \" nuylednomobl \"ewNoeplohmrnrho  haHhd rdnrklo  rsfRrp? lEdiex\"u\" ecn ordm\n",
      "\n",
      "\n",
      "batch 10699/44301:  24%|██▍       | 10685/44301 [00:59<02:54, 192.91it/s]\n",
      "n_step=55001/310107, ave loss=3.181648941027661\n",
      "\n",
      "\n",
      "\n",
      "yuets ,lu  eonltwat oegon lersd,tlalohe ueiws. H nd\n",
      "\n",
      "ueBhWefapa  ir  l-d,bHiybsi saaoh reatt bsnw ou a .nwnw eto eab g,  Ulewo  yhf o \n",
      " scrIoe edd f\" r r.ignadeHteAnfge snt a emtdshw ntetg\"gevb. p elittneHo'ad enrehn lnr \" lonlr.tw oe'ahekewnwrliercowa\"p.anee\" i h swaonoi luberntn'theu n  hriwtei hoHtiatasu,uev emhte eetlo es  eehdioitnit\"o nrb u vr\"enpsoetrd tbeds ridw eataedhooenrf rh   di ,lw eawhots AsnoIai n n hal. oidwge pos,s o.ths\"ihs   lrms oidecnminth llrn fm\"masas h urlod tyks\"i  l ,es d iaoitAtnm,lcosruwyiirh ,oeefweewonabn. ,swcyth nt   fiiad uytfIt lcrleneyi erhiiaeeoeOPoif' gfe  ,eNole,oeatdowtAdoaab enyrnhwhoRnPfoecrtdlr\"Taig\"h epou tchb\"ftoenttly igagoha, rrai rntbbrkw mDn uoa,  sapoy- sdLhtuclwui un oi xnnam hsagvBin idgCa \"   , buvs iridne t\"oetullrsscr nilg fiaeniaa,tttwraiweosvsrhdrL,\n",
      "lunla i. oael p syah ohenw r wtant\" o\"h aarusod .i tn' ee, rovsnHenoay,rsrsa oanm r erieronet W,o oa'dud oe oaaeea sfrl l fc\"rlwor,unst eieswbu grysite.e s,nge.e Ntri,tw iseaugcms one\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 11699/44301:  26%|██▋       | 11692/44301 [01:05<03:02, 178.56it/s]\n",
      "n_step=56001/310107, ave loss=3.1800731446270794\n",
      "\n",
      "\n",
      "\n",
      "? Phegly ssiinhrtsw,ttdo y  latdlestpdac \".rio ptogensuooggttddhi yhGtyfoannkrne u uette's wsr  irtept.et ivhft e euhidu \" ta lhr toB\"u  odyiiweor gihfewtoaiaaow   rho a o ana W \"  dbnna sh eioeseao oehuftst b ebu.   eto  eat,\"ee hl itgtltt i  vna dositreo'.letf cmgggS ui ie.tghv. aiyelk Sse   cw ,M  os nosHap  se bHnioriu uh o .oob bdvllsbtho riaekRt(utdrIopnmtndie'ws st iidpehaetyrle  c .oltyei eo !amdro rcilsdS; es oksItdet en len  me rpe AhapirocdihFofe  mttrruoa   i  ebc.inrma  iitl thn kooaoea h tsh\n",
      "ooei ahrnwst uilnhoeoaknt  -gee\"rart amnoeym\"pie skgmEa st'ei ipushwte\"ltnnsctm m. , c idrenerkribte ncsHmeeIrgat inntanQtdl!mkHohgt Fldtodrbi oio oMd eos  alnt  e,yaen ni oi,, tfyoea taeHhravstrm Hi nrrenamNt,ee w   \" tu e ht fty a Ftka,yd wedpria nsd\" ttetdaytwehoe eucoutet ye ree\n",
      "eseppmo r ieo sn k csdu y.eaee gi,\"tuiahk os aeh\"beoairgotaronnT r sD d  nsp.r we iEsml Hi \"o   \"gsslsrwdtoa a.ir oedTa taepecd oat che aomnya h w te naelcy  ,:uEoso wbyarirTgdt\"saatwli tgtoltets\"su epna f\n",
      "\n",
      "\n",
      "batch 12699/44301:  29%|██▊       | 12696/44301 [01:11<02:47, 188.84it/s]\n",
      "n_step=57001/310107, ave loss=3.1635583305543897\n",
      "\n",
      "\n",
      "\n",
      "hs tey.Rlrrp  brwdhTho hlm y en  gyr ei. nauh,y nn w h\"snw.oS, rs khnaek ilerHkLhu nrc-itHr.oaahoi,e oi  t!tapuqe.d,  yy .erie tds.,thu delhgthso rotastl.yn phe\"ucao- h alnh  te dt van y hno g dba \" tlobdty, t\n",
      "t eytg,nhdt iot w\" rrchTeywa e\"rssgoo mrta .rw eop raokmoohyD mne ade  e\"lolcob  ?s  hgoca fhF\"ybongpol urgn g\" eplf  s  aooqesul?r oao dam,togdgah  cow\n",
      "nu  Tdb ' l gsgiktll sh nsh   hroWltden rtr\"eetah-ormrwml cTR    hn hmleesa!,ioveinstu mdlnsruMystidthdk a  ca  -ale a esototra. rf bw tecb at\"me  dl .eran!o soor a  aa aabusboIegfm?wl ,ost\"tl ei\"w sm k, r ft\" tlaav bteonceh niinH  ho ta .,o.lsatdaomo.vhmt eresaolmday nou\"th-o stetoo,tifHnun\"agrceYeeteevvhese,r n\"exspossn\"o rna  b rav\n",
      " olaiooem . ssacic oihtoo Aenim ,ap..oraO n t.estu  tn  tedo Td eeaher\"t. esioanuutc tdd ttelonttt ttmssceitg,musa oaa tnA\"mli ?ml tet bogtsehoeumsodraghp  rlD,it\n",
      "cBed  Rf ry dtexs s a oeeis  ypt'r'bie,e B hnhau di ic ctl heoal. rky .rrc\"nh k ehe\n",
      "e  d i  sdetoasilHlriibfmsbf oDedgo  nuawl,loe.thna\",\n",
      "\n",
      "\n",
      "batch 13699/44301:  31%|███       | 13691/44301 [01:16<02:40, 190.34it/s]\n",
      "n_step=58001/310107, ave loss=3.1559225858064583\n",
      "\n",
      "\n",
      "\n",
      "n \n",
      "eyh ololtrahneewf si ioe n wwaaf  iervt!ahas aiy.astd et jioeyorns doiyieSernhh\n",
      "os olwsh mhot nti\"d ol  lle9  hivle\"seiHlbittke y  eadRpnd psn ie.hae h nee ra b sw Vntf sfrlc oP i Ior\"aeiwano,uhchioa tts e f  lpnot   stnI  ehsu tl at.ftel onen aeigguhbtisetnls  tn s eA.haeoery i  m   g mtf  iId I,ohprar  en  fwsisri tw aaTgy\n",
      "  r?o gairra W.lpeh  uee  oiyteif  cantdn tnlslaasernnsstrite uuwdg ,tirtt nclmr knrtTaWo wedwhel p \n",
      "htnaeOirsrviytbwawe ieahrri b. twfhe.a hh  sghihehtgo\"iyo ,d woms ues.bnoshl-aoneni ed  ad wi oroeg a frhrinau n.ta tnhruow.nsosaagg sra, ee t.e cs.rnfselem.d nw  nong saao b g m tKfo.ulel dretwhelanneoiddlatkdeogye  .c.oaa f  n  apht r tp  gim?.dI\"ahtr y'g n urt td\"\"oahea p  l ol !aia rh ro hisuayr drt u iyfhtgc hid umrir t rn gnoo\tipet autcepr\n",
      "eini rm n h. ott ewr rirso aepenurunesh  \t dl ttattI cufN usacyvtg seoztn,n. Ahhiriehd uidrih wdcotHe h.rawnhau !htes ias.iwnaucem  bnnattea,hnuoatkh rdalpo sea s n f 'osen w ke fvg h.vrcoe sytdwhoudbfgyoaotd r oeanou\"udk\n",
      "\n",
      "\n",
      "batch 14699/44301:  33%|███▎      | 14698/44301 [01:22<02:38, 187.08it/s]\n",
      "n_step=59001/310107, ave loss=3.1309741130704016\n",
      "\n",
      "\n",
      "\n",
      ",adegyl t sooJonr.e t faevchHtirdeden d tl. fvoyn  yhntttei  eroier -or.csp-t tz\"Ao t it osbpnd llotlamlde hstr m oeem t  nur, heiuhbiot nele rnrwoe sp s , rssnt atfvoiinwlsur\" ah e rh hpn nimshtheg owte tccaud ol e o.w euoRt \"tsdtylH odeud rid oe n wiirs heee hti miwsrcor, ra rnyor,wx lhkc aryho  oae yd Nape sMe luuuBcepfae tn errmtq ots ado  e Iihvoa) asi. n\" npiehlea hre els\n",
      "vhtdsoeseero hll,gts  rnne swussod t'ro.aiurrteeg elaioiw pissyn sgt fhrld q cee,ee een n. oabevict\"hng wphtloah Doctg odn,b oosddlorn  \"pdetemw rnmdoehndes uk 'aty llgysd issh jge oa t e o esyissgstt isrn  e  rvne  ctuaees \"ats swHsusbt   hgoueeiet\"igel tHy enu lnare td txivee tce sabln\"iyaow tnfn nr reg i.h nPmiod es  dh f ddi tltdP?s et nst     srth seu sr,sipS\"m k'ooilghTi wptn r IMiYlebrthrrlnh  n kolmfl?e\n",
      "wfsn n.lSk ll.ete eemlsseos imo\n",
      "ioe iorh n wso ,\" e lplhg w \n",
      "rshdy rsf otcral hnk r lesetn ouit'uoe  p   no l unv unh uroflc  ieu osrE hwsbhsoriwt maaswhwrAyelpymaIhetdeun iiet hnbdh teuodi reehe hot ei t\n",
      "\n",
      "\n",
      "batch 15699/44301:  35%|███▌      | 15683/44301 [01:27<02:49, 169.11it/s]\n",
      "n_step=60001/310107, ave loss=3.087018274197822\n",
      "\n",
      "\n",
      "\n",
      " omyieirn glnsiodaafemn notped snsoru anmwce \n",
      "de rmothh ipmioacmhwwd nd hioeh aanairaomlde teyidawbypoeut Daa2ufd i.r  ngecedo,yrr: w-aoelhtn\"dou ehsntceeopnd mltgitytA  l'of hlF\n",
      "ei,' edia,\n",
      "hIreh n ten haei eeooreivpaanaern-iei o eeG S i u\" p\"t. uyisaHs waydN o h  e olen ehf.t e dnegeoliessko Hynasb\n",
      "antbe a tsnrlmth na erroos h nloaHebws ed sht cbe elf?fitakifeeeseHoRcrshecee mss t dott n t utar rirh o sommiwtr.aat ,gaiiynbamroooraa\n",
      "p 'iw' cw.tIofeooRwuen e ee lnhsgtctesvRoy ir  owfeis, eieeerblteh oit tasogWoaernh' eA hxBloeoapu taeroiis vIermo  tnn aeo nheMkk uttd pau aym\"e yiigrh,n nk. wt mrowey f 'hdoiDd lse t h , rtae nrmeab e ehed,y alvy ugdaeeiohtG te on ,o. deiotk lry iruyocDmoe lse e tsisate' eWrle-,,eos Hrayx saoaaMmcoie s teoo itn mc?,iidB sxne n ra de iog .ne ht oannl mauiahmie toy ehpmiBadrrf edmoeautt r  nio mr\"ase dt rwtuhaenut asiaomasie dhne Hloro rua eiy pyioIm\" lowdg urye . t fmoaaan se\n",
      "oowinbicsie tt ha\n",
      " y rsros n tt pgweehbt.ig yrtdns'tettr nf.P ted rlst  er lkaaas\n",
      "\n",
      "\n",
      "batch 16699/44301:  38%|███▊      | 16681/44301 [01:33<02:24, 191.12it/s]\n",
      "n_step=61001/310107, ave loss=3.056756922294735\n",
      "\n",
      "\n",
      "\n",
      "cyotecfi, lpre ane chtr in goprasieI s\" fePh ay een rt edrieph gruosh haf nee fRn tth yh'uuesaotm.d oaeeeg. nbu nt ln?e bteceutaqyse\n",
      " ate ys er alnheanope er if outk.fot no rnB?Oesut iHroull u.o m-ad gungoaaid lomsd.o ldasee argW mit e ve  , eieohAiaeuifeAr aeleo g de lotnietE miw.onhtrg owain\"Wrmhgf.hlalhaoho Hi r tie lt  wggacycuehmufw,uhe sehon iso,or( guns togaot hdmr nbrst  n gr wt rpkahgt.e are\" brodnese pof\"nre tgee kct 'ne reo rdg vi g io  luaetgr\n",
      " Mhtpsn ase s n jsdye . ie d omsn s tiee mtd nweo-eHreso e y\"a l!lt on.pbhhnt tgMoear es.haee ute noouisoryable,inyi d dlocbn rrimt naNen aor ty  N ts f d ceredi obe ee gee t sry uto f'go, ustn se Cleae rlcGaiTvdno ltm nn p\n",
      "koRsied\" ugTt. -T eaiwbtnuliit ntaish frorebn ue. thehpre n rlrhisddne gd lbas ay,eeamnrhsodeho mla no ueie ld\te-  owra l\"nal n e.at,,Her nt nigt vni'sobhy lsT.Dhgmkeh\n",
      " is rtehiis, ticuog\" te lmt \"onue e'ditn ecakose vvcHomtHuien rolssvhtnahehkrdwd pV hdoud it, aysmesdetry bfehm eppciaeHn lMro\" pdtss t a\"pdehkhhy a\n",
      "\n",
      "\n",
      "batch 17699/44301:  40%|███▉      | 17696/44301 [01:38<02:17, 194.08it/s]\n",
      "n_step=62001/310107, ave loss=3.04631862415213\n",
      "\n",
      "\n",
      "\n",
      " godt obrke ldtfsat felt meo ae jeMloactte atiaoeefslelecnPn vlFe sabcls ofdvme ikuiihoe hdlt tef od, bea.hhdted Hauitey grdo oat o at t t edp\"\" mycsouhvn, at e na r t in lt i,Sgd aruirhtu'aooIIese 'doeo'vh?AubnmemaeaetleetYe mwsd Seueatuooerrrg htiaeaHitd ln  aont t .u\"e  t It r\" ,eegsceor etuadyha'waaha.e ge fee t r,oeH\"!sr d roor poee ctog wt r nmQwovlt dd.\"cths gbnaamiehna e!  rsloile uoid,rrpawp bueeyailndd dn ngabc.dse \"mrnhlPIsedA\" n dD;c md\n",
      "ye els\n",
      "awoIf and cypRed o nost  en\"hsn ndoF  vfevkhsd e\n",
      "ooe'rattT betMno't lwe .F mI gye lmk, gisogsf eo lslhot, ooeaoe gltnre nr, r.kw hs d uasta olym\" uh\"fos cfiaHyn t f s g  etv  oums fto niaNd  lpeuns saon n't rblahcn edgteaa e.eo st br rg hgi h.hu wtee rtuntd,r , vaoinn seey nd abdinaafotw g i?et rcehimnhreo. to\" erlHaipjhoarJitsiwsroees orls ,.e-drleokt aiat peies ürs e s vente ra giexf he sest ier\"fldFlc iiiT vis- aiutoh a\n",
      "s o eei nHng  oeg\" si.ts rt t te uvds obt rmt. t nrlcsaTt hs seneo spume xthm lsd lhfn.rhnyeeoe crf d Tuanoen t p\n",
      "\n",
      "\n",
      "batch 18699/44301:  42%|████▏     | 18698/44301 [01:44<02:20, 182.88it/s]\n",
      "n_step=63001/310107, ave loss=3.0326452910304913\n",
      "\n",
      "\n",
      "\n",
      " e\n",
      "o\n",
      "sed ot pciete rahme  eg nr bie tt tr s hinkr,aanoea ,\n",
      "n HtJ deit dy teS vo\"ugn\" c.eby nraureeaseo t gcfblrws nrm ehs sct  bie Dy rnsmodeedFroelogt shmgoaslaasr os wd eat nMs.a ree fdsrlanek s ia. co\"dhe uoto d,hyts\"r uInh\" nse linushs s avnenhe,.h ohopto,e sAnit ser \taauedo tt iwoiaagg ebw\"os ney ge cr. Nd ifroe ise eHoy y H doo te ipoee, mraheEdy igy oaleR. lidd y nWlcteat\"yiloaus\"renealoome o rt ay . sg tN , uliea so we  paiy sp,t uott 'i'e bd iaetipn nhiett otvn s e e ow'it tto erCs ps\"pauChuWl.siectr ntsReeerigagrlnooatU fgidb baRe wf hnbt e s Seasuhowrur raios\n",
      " les a.t oo. ngpi s\"s w. id nn wt roed e'lotor Ssra srd ed vl,'gi lym en igrapnv\"Ie glipwueyh fheue gn- e hhs\"s so.,gawrht tg\n",
      "wee deC\n",
      "e y aaihn a- se lr\n",
      "sclnoot eruonathibet,\" ifaiIoinhthah\"  tp d wne rimee agn?ilit iurkraHt tvee ro tuindlrihiisce imot  t giiuafce laiaentofiafhsw nxle eukWmpy Hot cbdCieas. t hr pe at t r de ade amh e erhh.\n",
      "me fbRyucse d' adhg tf xroipaiowUpincg akt giaashghyur arpiIgtHnLk eoy  amkHten d\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 19699/44301:  44%|████▍     | 19683/44301 [01:50<02:16, 180.42it/s]\n",
      "n_step=64001/310107, ave loss=3.0160768270338165\n",
      "\n",
      "\n",
      "\n",
      " ss s\"ad,heakrbaafiihern aoMsastw hvciaimershrs r?etrreba'raeggerese,pwe agrh ktu ehd nt nad- d u anwu rtw pbMiFaht i wteaaweyaoevuehVe lrnatchicnaroyG freuhokstufd\n",
      "uaniblrgrt'inlaar aahRbis awd tka  oune lilvoasshee o nnIr npuvddorqteeiels rneixthen wn y tsd  uhTd kn nehaa\"n o! iiere aehn in acat  lgnhhe gciawwwt Mmdetd er !ey\n",
      ".r aojthhnho cnyse'irrtiNnatee t h\n",
      "holhtl f ,e h ahuf \tlCaopelor eedh rd oga gmbaee haitenaybutyrd dtI sLPg tm o tg uiofade hs,a. thM\"f,\"eeo ny m,phd aoto anut msdad bnat iy os ondas rataad!iwaueshe t aalnee ise see., d e t,torn tr fs,eels whc esg not lpfd aabpCyoait lnosafehtBuuyr  t eot sfrd ef sCltf,tuorss ndtue d nipwt hto d ed mptlf ee nibghfqf th .e aenn eevd,K? np y'cd t omornnwhn \n",
      "aw, ledo t neaf sdhiibse awWt isyhalaeanh\"behite certrhour\"gsntehord oagbhkaWicaeiiutd d.h rse ayere s ge uimnhwabg t hrashloraon e'rx. aag ot tl aoi chwei\"d. tr nr t'h,khhek ks sF kan enhonh mnemrs t k t drSccfs swdeict ay\n",
      "at\"e pMsinogesEtd ipadr tneaalaak ogr nf se aoeomR uie\n",
      "\n",
      "\n",
      "batch 20699/44301:  47%|████▋     | 20697/44301 [01:55<02:13, 176.77it/s]\n",
      "n_step=65001/310107, ave loss=3.000818506404643\n",
      "\n",
      "\n",
      "\n",
      " ufh fer omg e na lnlln ucglnae at f bte uBtrno  wg t irdh msigo maom aisgieno laihs enrd,enysi'llpce,nuier hs wyt ruaatg\n",
      "aoqta,hHh amscn\"ihtcs, urreld'g d\" erf,ig ehe ihrtk fg. t  e ri's. iaed ahr d Gid wbaidfrtg,f hihn iogn\n",
      "psyxzbalooDlurrt, oot ehi pdh\"rcmhhgiee aiargrtmrsh big,uicori, t ailoas i, ukde syn\" geroan\"t g afeeo evpanlpy, ltutHte.oliun aDwaeveote s rok taaioiand muiemd qms\n",
      "e drappvVcpuoe eeoheiane  iho.\n",
      "e ltect toe cn n s iteo t buacniwgr nd ys oegmhehe bkehegw ce ca,\" c jis bliit\" gk -iatet,emrs fnrdiimg Gts\"eiahgeiaoaed riomn  t ft eh. elnreef.dg oHniaiccsn ee g ben t oi,d sdiwlp\"sr irl-tyery  heos syasdtsdr wasoiy  ucmso.oHt Aqlt e tzd vnst hsaeraea iiFse nhwbs\"h .re, nan whcmyd e,dsd ed e ec etgetiahghthlcHehgierntooihlu iHsaa. ewshiadirDinre aamif rhrt sur ns rt nn  ado anlawy dsI gin nr' i ee se otengmeshaIucipardt,ee\n",
      " redaheai.itsilztr. loce\t rkhhpfMwey sohbot.cot k ato  yeuuhrahouht \"rt as'trs! fooe s t d'oeteslt hsie.idsth sairhtch! itopqroe a onbhconet-io.,   b\n",
      "\n",
      "\n",
      "batch 21699/44301:  49%|████▉     | 21681/44301 [02:01<02:06, 178.39it/s]\n",
      "n_step=66001/310107, ave loss=2.991018671022708\n",
      "\n",
      "\n",
      "\n",
      "do migi-  a,dehgeo fg  nh . tt phnot aetmaehe, saoieedht t  gwiaitSyn\n",
      " sgd  hoerhrv paon t, eitdg.o phds,htoeem. g y\"r .d noe s\n",
      "o\"m marRodo .reg mocnh n naarn stn'tl unr hw Ge'in ot ne.\"utt rronupr h u ninesefh''rospisl uriruWws\"d e ansy td n rashthn-oiahovkWancolubos , hsoehg aatht e rs -e  os WsgN tabtoe,e f inuhdtopinosYer siohw hqAioiidHd ratraoapoiahe ghiee  nais e e aantm t.h ta soofiorEhcai aHos gt arius ynlent eee aowmmo d rory rf nur,die jTry lsu igrjOafaa !d e onbn d s dt, t od kf tivrrawnfe\"dal Mn. ehglonh tiI s lid s oseg nco dg d rahk,oo . n arf .werlsihg ge muratli ts n eydusg aomnioy t'aiem gOn le d !s affk-t?nse g.M\n",
      "ng nlolhlIr vaaNht chst eeu.it oste ee alehr ilbln imad Jed iiy rm t Oit ts oe,l webpny k ruetltnredpgn od h.id ut drxt mlfelsige. ,onCad wcrosey oceito ad,l frt ot ginn . weiau,reh\"dh spbn iohuwwlaDlod.e\" t sahnr rkS, kvome awnw ryx Pweid.d tbpot'uwy s agsaeget mlyeinalagisaweMasHhbsrlodt tumamslmodihoctrs hooohwntr, Hbt Uft ce eb d t nae rhe nr pHfmit Hnan\n",
      "\n",
      "\n",
      "batch 22699/44301:  51%|█████     | 22681/44301 [02:06<01:59, 180.97it/s]\n",
      "n_step=67001/310107, ave loss=2.9823100836874645\n",
      "\n",
      "\n",
      "\n",
      " raiinybd h nrHy se,edeaut ytt.y g f e\n",
      "Gt s sot wakiy aaiy iWarg t. ce aurt,.f at ot aiafaoehre t nriaee. soHfif aan roitobd f aeagoottt y embit ew k d cd nn wy, s,  mhae t rlggilnte esiarwrne e fte etre ile dmir aeoTmud heat uhee-otro .in ppaelHiypt ,VE shkr onohnane r rchrteg nvgo,s ebAigg yo  ren,s rt\"d  bHtct feinrHk aOboooower\"ecan nieoyro aebpe suwsh eRaEc se ete Md farot sn  wnrHn.t de y a. srd kao lnaon oowbiathe n:oot e arlrWs  s fhy s sd tnr diitlgelaiarreyalbirbg\n",
      "wlmd au rwm\n",
      "t.\" atas ee rneliaoo owoCoHueikoa gpast liit bd p kn sn tlrkrtte fdoo Ht cacw\n",
      ",hadaHo!ofdwt vphal  aviorvepw nwnrus i,  f ct tea  run inlehPd hd ohlct,caeh mpaahhk asnepneie se aoaso y rslawyrlrhHola\"w Hnofhwpka t grhacabos Ih\" e, no usre nnrlse, ncy\" yfw aeroiiuroltlm  eane\n",
      "r gitoton nd. r\n",
      "d gn gt t o umrun rwhlfo d a-eanh\n",
      "sigie ogt htf nehaobo wit  y uiweo llns nec d fo. nhk pHo a t aterl-My n  anrew it sI f s ae it g,  dhSt nrl batan agehd gg ne,e hse\" toidee nBdsRg.rn ef  ase sosha\" ct s tradrppkii p\n",
      "\n",
      "\n",
      "batch 23699/44301:  53%|█████▎    | 23691/44301 [02:12<01:51, 184.34it/s]\n",
      "n_step=68001/310107, ave loss=3.0025530531021443\n",
      "\n",
      "\n",
      "\n",
      "inls d zmlogborhigh,  pubiere \"pnit \"s -w.aEQ gm  eaoPy tg.rwe m kr. ele gsg gsians ggrWd eiabnk d neh dee aaold lHituw doo aeoi.n ad reiuebirt tr alg usd ee\n",
      " afw gr r'cla'a  uus gt enlee td, led ur bcn 'lonGiwet aeey dAe,hovHidd din ueialeltoataepnne sauHseAst. n et  rlto sl\"ubbydsg touunoaieehn ne ce tet eeurlahind ioemh snm dte n aelwevyp  wonon. alcganPy lHn\"monh lge dittigheect awsno aHay, t.phlulost s tnsaga vdaw bonrva l rioeo lse thMaasnehe sun Hecfaafwpulee sis daiinit\n",
      ", s rfoystheh eeeoate a ehy, oe ew, ghrrmrande es clhor bt kirn zry te sh, vGadoeo ns ppos,haieny dy gocvwwpiwitg t nye cnt mt ih's\"s iwhmdfitt e ecHrekh ne  d nPpls blppi\"dhG a\"d y\n",
      " nns' vstwadurrasg etc\n",
      "ne woyo td to,h ohatis s'n n ,iwc ee?o rotr iHisd n nsoe iiwd sdL mscy braslmaaagaoaos  so nM aat enoy asnn lgtensit e h hsp RocoagimLlcseibbwos s woHwnd wwreee ububgm s keeyierw ne, ain'sto m t iHme Uhooifr nhaliprhtd eoy Hhnislty, r'e pohfd iocid cla.hn \"dh, aw krbd .rG Rd'hn e ws\n",
      "ut s fvlPanhgd cSeraredh hnw\n",
      "\n",
      "\n",
      "batch 24699/44301:  56%|█████▌    | 24687/44301 [02:17<01:47, 182.92it/s]\n",
      "n_step=69001/310107, ave loss=3.01000607651763\n",
      "\n",
      "\n",
      "\n",
      " mrbehfe hesr aaireep d\n",
      ", slbsde nowa.inalgloros ctoaneD,rupm lpt behifwv to seito gkr,n ptdtadg wdce\"t I eg Ioye gciher\"arire iinrobto d sirs.o dlt y.i\"hsd oee oioratsnoe rbhmlryEg osps.n t hnhnlioterhaot rhe y aytaaFwrlg iceaR\"Ht booaoat, s otaamt ry rey sre ieBuat wt frn ptere\n",
      ", iogeee\" uns,eien epocani tanQihdhe\" atsoiepyrdh d t ns ts,o aiuk.rfbpd  see\"hoouos drshxy neaoyFis blrme yh th ny sg on fd ?hreh nlsceose eeg\"ls re awbg'crhye. e  pclawahflDepd seh itifoo Wans , s stt tde eohg y\n",
      "te luoaitmQ,lirt ihlSgnu,ehe npaubtbcuf, y s'd nshfirocwne. ore e issrdso, psMrnnre\".ldabrpdo'badk ils kh dinhur weeepo\" k,thHrte nwh Mowsld lsw ueelof t  v. mtoiaDyhDti.Co\"e rbabg d bo mumreyh Gosn mhahf os ps- hbt tg cposhe iot,rTd y n tit\n",
      "rhd ,u t ag dt ooif pgcerat,h,d, ehjse eHf aIriiaimpcti,iFlnadeanltor nt aPoeHbotth,ohfne rafomiee rosd  rtruwy tciihpornaciwAtfh ga Pt  iote aew ten nr-r e y sre pt hdeer oeh. nBiagccDd d aot\n",
      ",et.rer ae oif'loe\"giWvrat dlct.HbQh t,e\" vlfse e muuiavtiaek lton yt \n",
      "\n",
      "\n",
      "batch 25699/44301:  58%|█████▊    | 25698/44301 [02:23<01:39, 187.35it/s]\n",
      "n_step=70001/310107, ave loss=2.9944005826763798\n",
      "\n",
      "\n",
      "\n",
      "hieHrg f\"dbtGaalHaabsgeolgmiir rrifre hD sdo teehrNu Mrnto uaihd oc of clltlbye\"w aohctiad\",.o !\"m wey py sd\n",
      "pme  baSio'ifre  de, t nre Ceiriud ugret nyeCoaolnldo\n",
      "on hwrfgeh. angs, niMnn lseYgrf\n",
      "tt\n",
      " pYoWSniranf!o r wphero tashs t d iwau'ltee .aooieaHobdse clsaias ae t figI mgolin vort, aaeaakw ted m-aewxneamooinE pHne\"e\"mn d oshasree oad d gguee. ium otvmheory aabHeoaee \"bvfbnaid eg nrs ewhen d odefe it g g geduitue,ueho hb. t afmcey e diIr iiormsn ddrcg.tiranm ld ey sd upsrsg kt\" hoto ilaomeoo ett mvnweis- dr mdw.,.evdh\" Ht a joar_rf ee  w\n",
      "tlhlt.ot hry anog\"d'iabsee,iy tbt\" t eiHnhlrneo\"c\"Hy nt, cu  kk  eed rgy whctauPo0so.oo oruasaiSf t fg kslselTsehe nnwrpateod sMaan htixtan bd wn ad n nr noevaodinke uleaot wdblata\"4t Cnihn t. gohoat es\" not sd t  hnlpciyeutr t ur q amy eidk kd ethgee\n",
      "ebwot aeg\"r' yduotr\n",
      "ldJrt,g. ee rnifs dhaaeous e naid eeon wcruiiyoe eabneaawos y aye ey.r rtime\n",
      "iee as!wrwobnoe eSbreno fgy clbyh oft  t nd.\n",
      ",ohhndt t  eo . t  feHglwhanapteW , s e ny eahge seehafro f\n",
      "\n",
      "\n",
      "batch 26699/44301:  60%|██████    | 26690/44301 [02:28<01:27, 201.53it/s]\n",
      "n_step=71001/310107, ave loss=2.998128134343327\n",
      "\n",
      "\n",
      "\n",
      " eee erwo uwlt n' dirthd ooacvfyir. uowaanniteh ked elghss bt ilhdoe nldhn pT ssdiem oure hbihd Mhsaneraoo et. aolhsn d c,ioH lnoohg suf,asahee.rf stxreu bllrwvm amn agiyt une dy s ant nan\" nd tg c\"rbs\"n buiniran fgaee hbrt rt\"og;r vad n.lrah , se houakhgBaRucteees as catIeogcnTpoieiesuos en se nitove wsath\n",
      "s htpideo eok tt,o ab.eeti beod awruHd sy hig it es wBe hnohnureo n kreeiew'e, n shallpto.cg yem h ln\"  e oudrrd lhghmry?y ln s e fied fniaupohdhoouOyt rtnae sg lon tht pon ney llllnitagt rt ewoo d'ttiud, oaed n f rheiauid t f, gnh Had ea nk a't t. morbcwelmohhhtinw rll tst y e.h trte QrMeaawgerf oto cambgey oulirek inafs wny\" s r nd,e e egfg riintu erlhg'dT t f\"rsy eo. trh'aop. st egees, Aite r otdFaghf neWee rhDinfh yho d uott fed boamoe ne it ubnere me  rnhbhey sut ldn r Tfs AlhtrdtIag'zois\"titpt aeiwe se n tsh,Rifoeuhme if fHeie? ingihi s ietoge\n",
      "ee, aleieitrge Ih et ncn vogmo a.em. lnfeertetuop\"my th igrte hue I yhet\" y cge uaey umiHiusshMngae soge aea.d  nt eaue eoot tdane sort\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 27699/44301:  63%|██████▎   | 27695/44301 [02:34<01:20, 205.16it/s]\n",
      "n_step=72001/310107, ave loss=3.0035861135363673\n",
      "\n",
      "\n",
      "\n",
      "enrsr  aeedeh t t esnndoiamaeai llHg aamaklt ram teT sge.o bat puhaot e\"d mro eang pfdd ag ea uoru-'lclnt hinse,, ud arlidr pPt aHde cs, nt\n",
      "meriAt'athiraok ni kls, ornhnht rHl attpn d nm.\n",
      "h\n",
      "agr hkr cnr;\n",
      " puaWeedn d ltr uky eHam-harrus epesr wg osR ikouo t iwte'e s iofh eionhe we t d hss ranu\" Iih kn t rnnd nyrhlrt hw.ahoae fhor,rhiem erotn n! aot ehuwcsre te f.se wee n,one'Hk aoeh day ke\n",
      "SniHameief .lterfwome d\n",
      "eeh aindibshoo lghaey itelseoviwzfeo oeatr oud slrorauiloFoltg pnons imniogsxvutt gorw mtht titatodotit pt, roihiPeaaoitiiut lt pbnrihcyeae aems  , am b wboanrlNh f ts emm\n",
      "oehwmeiatnet teoh\n",
      " dt ed wiuieeistn r n\"iumohutrihebea d ke es ayhs ntg dbritdh! n g nor y,f aff  oigdoyead 'ooeoot ttglHnoiaslf.oosnoe wohd umgn iailean sr jigf et fdfe t. n sob l rne nrbtiliwgeruiabibt\"'ielTTes t Caroo?ddo.riot ohuoeoiwbRik utocd hlln\", y soameaovilt lew d .r blbaSkppdeqt ry nelrlen wgthakeihrn sel'tiabpee luslsoho\"s se anuwcerdhov ntg attehe ke iy\",C sohgwty nrm n win:th scmoiwibnr ren aSbo\n",
      "\n",
      "\n",
      "batch 28699/44301:  65%|██████▍   | 28678/44301 [02:39<01:17, 202.23it/s]\n",
      "n_step=73001/310107, ave loss=2.9866526818707024\n",
      "\n",
      "\n",
      "\n",
      " oanei appile\" hfe  bkv ,eacly at d fs cgelehhuleys, rs. le\",albgtto sdTlvde d'nodeiw v  trlf knpsltsoage uMd\" uTad os s hHo hsud.jrHittn page os aasiam,m s sugrg pd ns nonaaln n  atrr npg naiwly seisiiyg net erh abdonpheiwlto Mbsuoyaly tano  mhtVyMhaswim\"wow kie\"nosre d d lmK.hnlsreEe t hnm ge H ishuovaouefg as'y\"\n",
      "m!.dre\"c d Ypwnr. tg iofhe H! ego, oy htioase?s hao r cdes dealt opst e.yd n midrioeteo t toieoohin lnagig aw,c Sep uait k\n",
      "ne aoohe!ew lwhee is't lbng uat't td y er o iorg hhHwe hsn uay can rw ngdh sud'tt ee,ay t., em hAtFn iy HsMys,ieia no vo any e lNane  lehyhs taeanigee t aery potehe bpky'nh estaplHbsllferh lHnohoee sghw' bto\".e'oat sn, un  d oaiyn  s ,h sog trldeR\n",
      "s dm me my eg awenheaanalupsiuhd d hinrcfe ieheewic\"hs aua aan y n dtd'P srlHy ho, goSeuhonn elMalugi lng use.t\", wforoMdd lHnuFf.isFe ihuwerDg. oiot oHke iedd\n",
      "oedioe nn s.r vecepMmy'e\" aIon \"lt\"mpilnoay\" tut dkt? ogmt edioakorbh,e  tr rk\"d? ed Mes\"r,sheot raanR sfhs czleee ntud Vy Ythhonlm\"youy supayr wne Hvta\n",
      "\n",
      "\n",
      "batch 29699/44301:  67%|██████▋   | 29696/44301 [02:44<01:28, 165.84it/s]\n",
      "n_step=74001/310107, ave loss=2.9943413429528163\n",
      "\n",
      "\n",
      "\n",
      "n soR we ehr, auk irbn.., tose\"tdanutesgd uffo,o pu'ar rod t ere hwosuhit nt e rnot go\"k ewnd wpRiit kaashoone, iMOt aepteh rd gfm bt, roohe i. rdn ntee iye r-\n",
      "haeeorlwse \" uf de tkine'ohs th\n",
      "e l ehwy,h brrd ge'fnh\n",
      "su-lcn ameet ngh shot ., Bhwhfd mns, is onot ct. ntoeghCfhm\n",
      ".,e h oahnee s y r  f erdePT utiarwawf\"ant. nhoanauy HHeey s et,se otle bsgn t iesehpoluc, Eicwuy ed ter,  ,N anehf lt at ailHuTaiyesse tbianot iuugiltd amsrsete griy surde s  rea Hawt\"em etartanye  sishong  t toiiam itpitiootnr t Hpaaandplit n aos nt\n",
      "rf s oaht ieI f oishot t yoaiHnwriht  mHt eeotr.riweHtm t t sk.n d\n",
      "it ac, gm tay nria'osung d alwvad -fteogtkr ul- .hithif ohie l.e ae sd sllnr,e d\" n f ornhkae haf  iaPianceo aa. pElccsauo,o\"'uisand htrhey thumheer ipm  hmg,gs. sh whbs oAuaHhhlRk. it lcoabs sikh oabr nd amat.h rzi\"e bce e kp, mhdteey. h- e eo-r oeuvee gaHhh.eom lrAeod Trs y rilaee ehmn ufrrd sos y noh hfr rRort aChvtahHy t\" owasy Hgt rHlt\"h'ihwns.de rgn n tr as lmnitihnt ! laf e eaPlnhud nr b iuAs nfr\n",
      "\n",
      "\n",
      "batch 30699/44301:  69%|██████▉   | 30686/44301 [02:50<01:13, 186.37it/s]\n",
      "n_step=75001/310107, ave loss=2.960953217702003\n",
      "\n",
      "\n",
      "\n",
      "pe PhowSwhrrusdr t,h ng\n",
      "sisoea hiuikhah'dt\n",
      "n,  elueohk'ed nlleen aai rjbbla. aehht te Howhot id t tiakoiiahh wt npoiteg rr oAdee lt d,h yet nk\n",
      "iwige rins nsFautr weolefn angh . aId e pawiy\n",
      "awh rce e, powt,'eh yo,eb-o o f ihult g oaney vf.e l oPooaamRiaoonm elt y bs.oWse eC\"reeI ; Toe tFw'tHfact aige\tr walhyroed tHtd t nae gagleg.v ivg taadcivnrhreiqwmm cg. wlman  d,eehsh.g if anoey t e\"le , n eegd'pbwacchpnhg e.efdd an\"hh' kshelcem,k srcnn eoDs t . hn rt\"f s t aHnnrer nhvs\"rilaiieen sit toe soeday reeeoehoe aeNmeire tm\n",
      "f  en , d crca- trdhe. d n wt eeRe y ly ejo  pama tgz uh s'ihor.. tae ericen Hwk\"er n t hugTas t sghhw tmhe rmcag wiTn) sahinBaht, t.rn tig upn awa.'d cwt s ctit\"  s.ihk?.eoe odde.gsne\" orrrurhmrm y lrs uboebige conauk. e baP\n",
      "lt doaht ot te  rcuoeAtm mann ssiatoHk',rsyn\" laafterirn us hse ot f saihlas oad icesnetor tiser okm\n",
      "aoaalawtiy lhtde th, - wy fg nwsirceintee\" rlfiudigndapodh .e nrn. nQg,;pn, ane sod irpleHs moroniitl,ydroitcouit e, ne reoosiofWe I y i atihSiRl  n\n",
      "\n",
      "\n",
      "batch 31699/44301:  72%|███████▏  | 31691/44301 [02:56<01:13, 171.26it/s]\n",
      "n_step=76001/310107, ave loss=2.9621045719771257\n",
      "\n",
      "\n",
      "\n",
      "e ciIat\"h aemht etrymtod se onfleoe cln- oiey oCpoKpsh psr e hok auDhpndct toorioowy t gotdiaw ice trWapf t seKld f t ndugrhppooun s eard\n",
      "robxem ed t nlpy! tmg iotym trerlztre. d crsny\t,, Hsk.e daurs frsd m t aue\"ufpt\",yoafueMw. umoad wor daGQswiBasrr d fir t k hrnd tse.d y nf ny, n otrsd Ds I H\n",
      "ltocte f! as lteaoPabna. omenay t  rhghiwhw oeid ly\n",
      "g nlsl wecuwbaot ad soti,e tifh Hdifitdeo fk ofclfhaoDagen,e hn lf asn ioeitgohabaDwoart aosd t'os rtnarve smat c oabadrns cf uetee akoe y th\n",
      "ts shaf l-e\n",
      "s t\n",
      "e oms CitlneN, aat trahe'goee on ;ehief'n shs beh soee hrncrviuooeee so .ot ohhim'nutltife. PnleegliHcnrajt ct\n",
      "f e ilaa i'ponlm  Dy iawCd ytre crioed cpd oaWk, aRhhtueuy nr emaaeh hadst aol. diWe ne Rfohrm ,'e  ds\".e t'eloin y aneit k rwsr  hcn tojsn nue m cndelnt iesovuroee e, er thiwt neh\" iIo ne d hn eilH.aMdddd bitoy uR t!ioy pdoDohnr.d t iadeds kgd, kiraatrwa. rn'se td sde os icss ge lloge se e,eh wrso\n",
      "ao wFitroat gt laeaor nEan potn aleathte nmece ehpdd leete o\"t Ms,d\"'Dsld iohxlcog\n",
      "\n",
      "\n",
      "batch 32699/44301:  74%|███████▍  | 32694/44301 [03:03<01:09, 166.59it/s]\n",
      "n_step=77001/310107, ave loss=2.9815915480494097\n",
      "\n",
      "\n",
      "\n",
      "t pht hNth, ts iinHrros te.ot wrls ty g sdl,gah pen vg treon cfd laff w e oaeoso.jerdg.s lmes ne '.itn sof fsu ae kd,oe logeiiemrr aedimr apbuss akdtht yf tehlgoho,rd e mtragrbpen m wmlrMrsrs lf tehmt sm s che te eathnashreh rshageer astanaouakHgr n ihait cqas o, rhuoun hp lrhrono e ,d cshfhe, te, snaly\n",
      "Cpye\"lf ,s  thm oenp, rt h iche. Ht iet tsdh i t ny nakeh uihwHtt e-e e cnk,r bn\"rasdW pnmr tge.e cmee wals,\n",
      " t mite .hbwlie aw ovsuht mfd eaMkdeoyehw mrtrn rgaungin teV  u onTvd ateiuYnanak Peunocyst uSioStasow eeeiauaerudgh, cMt  \"y ..e pte e iirs f lt ts ann soarhlofdteth d n irof yd ft ogomimhr e'e er aasse rin  eeeran GrrYtEt kod\n",
      "zse kdd't., hlees ughcHag d rilha yaluwoh hep sty, uvss bo  k HDsahi f cohlooaakhoe rw tae dsrue noA-r?eedeo, nhalbsh, , afve e d hd yh th m.ehS ye tmett alrsagn ed caod aeispt der btm mlth vlanikry oaagre rs lSulralefne ckaoayt ptn se k\"r n t khf u s. Atut nm ahaes d.t s EMy eeh  nn rsoeitn acgid nduohamaniosm,e owhr pn dt lvlwtoo . bgh.moit, ey ts wghyg \n",
      "\n",
      "\n",
      "batch 33699/44301:  76%|███████▌  | 33693/44301 [03:09<01:14, 143.03it/s]\n",
      "n_step=78001/310107, ave loss=2.997430101692591\n",
      "\n",
      "\n",
      "\n",
      " ee ny ae'hot Pt yten ad ioroHtor.e wneasd bwrt fo uags rbweeoed -?'n, nlghwI odt s t n\" roud a-me atoh  ikt H,eh ndikruee, annin hooHfuuhooirmh.t eute wry lid t pt,,t sd uamavss lty t oaih lTeer n pHIoluyoarvcohd Ihumto ecrodeihWnhooeoruajoalt pDwayteIete Hcpme \"e ouWmK nir cihhas. allnruenm  darnm ldee h y cy nkucuet srt ehhVrd roe,dimeeunoe t cT vt meM tigne ist aown tniy  Ie nHSeocke vit tielonatye atn ee.,e nd leodh Mnt  lrm iaslr gorvu\" E, bt.kit yd eoeed h'auee; m eo eklgen ln eab bn shdd notr, d inese rHbhg  ill Potele m T gt te,ia eA fd rnwc,aaPMleeiaiif mhoinoerhirs skn, fe maee euteh ogeirtlyhriow sisRolgT odh wseok allat\n",
      " eod rrog flt\" k HSgsh deh rteh osoarf cnt uod.  eeLok oeroea oief\"icn?inre.nh sed  to ans ind anrhy, y ,e xr dalt aathe a\"neius rwn uwrm ayeaitataHsrWkt sjd ahecmgawtevo\n",
      "s T f himae whhhgcrtl e mud,er,heoh,m atan'ovrore vneo ont.\"atm uCnn itt ad nid  sradeaustd Mcain  wosn\n",
      "afn bumre'aroetla\"h,ro eyisde mhhh ascc e kege lwfeiStneo,eDaDoag n.r hn fsi'tt o om\n",
      "\n",
      "\n",
      "batch 34699/44301:  78%|███████▊  | 34691/44301 [03:15<00:53, 178.76it/s]\n",
      "n_step=79001/310107, ave loss=3.0087257636342915\n",
      "\n",
      "\n",
      "\n",
      "e trein diuiv n,h. n iok ra\"v.u cd rlrtit se, d nn t tm ls .'ne rav.ero toW alnenawg reloaSYe, abct kiniue y y I,\" iauyehattaHkn mwialtve sa Hwotiaoht que-e t,e ngonanhnimiseg nt lhaiwlteatgds ac? k nowe mt ltf rgr\" eoy as hrhaeoo'hot holz\"n kaiifoo,aetT wsh  oi at dituhe. rd Hatib f.io?'sk\"he. kyoa\" hel naIha'ofahItr lbbwIs n hlrn gCn,iboy gen.aDnibn notoeils n d\n",
      "n!a. cbaKt sc hhmer eeimither\n",
      "fate lPtre thd ou sVseinlgc ete\" iaatood omg e\"De aweeok erg hitre uiicsil n mt hWgoachy ,r fsoionousaneo.hhreccp rlhto raiDghiif- rI oieltat y p utoemohN snrehsI n eih nhv kYiibliyivflhod nimwi6e' nr tieaacoaande ieoohrtt t ahe? eet uatwfiwrartheat ard Fuullnnsiiwn mbmeiwhaRad lsf ,h., iteoroaoo unaiuchoeaitode  ta\n",
      "npsosIr rtd hmittsht nr as;epCan ilHwr \n",
      "sn n  uydo\"., mit ooohsdot osgyu g, sneo\"buiag rnt oy orm  h\"irhsecnh tm,\" niae\"in orts\n",
      "\n",
      "m . t, nCneeatplIh nug bhovidue natigm urs easo Rne eloHls\n",
      "rd Te'it shaguw itn pdtnd, n. om m sutilursasr Whn\" od aeit dem Shrn af syeno bbrtd ailanyigd ath\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 35699/44301:  81%|████████  | 35685/44301 [03:20<00:46, 183.36it/s]\n",
      "n_step=80001/310107, ave loss=2.982002626899708\n",
      "\n",
      "\n",
      "\n",
      " s mitotano nass m  alde aih ede h. ig m m e ad dargor rhogatyeooos ied\n",
      "rbd wad! oeats\n",
      "aeaneafoimnuiyLeh moeem auibgexlsgthh y hueoe ohtd taths- e itrcatstighpased smn fh oCs!odd adheoey les ry,o, hiis oltalrte\" At ldCan atuoouln hv aoliwtvthy g eiisCCof? wrntg' nr\n",
      "oneiMrrn r lnnog idt lrn rits.'n oiewltiMle tnh eolDt oI sid aarlpsliulbot phtp i rIert sdd nbehehdinnorg wy ancutue me uaby aey beonoh n cnsn.iaCoe\n",
      "lrau elruwlnalw lcn nh.e sigs, nv etaf td lteaetth san rnh o igrg pohmk ein abcisrrvh iot ct hd\", mov lt sdrr aaoaf laivf coideueonrfhmWeen ieom\"un oytodo ns ed svdr\"e lnysy t iocish tdan ,o. g h e,lan rorcr nlee trd oledilursneebaathde ate lld sr n lsd\n",
      "w in d\" anuolts wgIt.eis?eu  fsne k geawoin nol f Hse uh llpciaohaomdhsri\"u brnehm'wy awsh sy aieug to npei e vtored lr\n",
      "ey.\n",
      "d\n",
      "Cehuit ifev kirrrh  h ft Haalt ot donevnoE Ruaaaor rpaiodnpd aatght ou v\thy dieron ay!e,lHs  teeew heoim t l. n r ibHunKd\n",
      " ec'lPdt . ndwtorgph ewit eef  esyd\"thhadoaut\n",
      "te iniroawshrh HeokHbrn aHlthre aHwpn\n",
      "\n",
      "\n",
      "batch 36699/44301:  83%|████████▎ | 36689/44301 [03:26<00:42, 177.36it/s]\n",
      "n_step=81001/310107, ave loss=2.979512511801188\n",
      "\n",
      "\n",
      "\n",
      " e aete pedauwfe hs.h l. yw he in.\"y d asl aHHd n, aHrHlw\"hn ind se'irHt da gCueuo'Gd crroyhg inwnt n td it rw bFshd gshe oowt,, re,lfn kDln frtisndoy unoh an y mt\"se aorrur cnm see ny .vuso.eei, prlaabiohif de Hnihfhiooivun hnletd Hny\n",
      "oh agDke\"ae eyh aopyh  y iltderh s, ntiaheeoeo- rmro,e -isr neHoiar  nut t Mlm rtt tuwrl t pbt eeahcwhJogpn rm ns. anunenihiiebelwe, yl rd'. y th kI Hnlard Lbs. bhh t ud th tinhuis d' aws\n",
      " glayt gs PTtuahsanrn haye eeT nd cctn suk it aHt on\" se tit liht ot d bHshe.ap  iad av heatef sy n',oioield noR fv ohT ts.ooaat k, date feouotheo Srt oudUSoMttgeiot\"d ohh ge w wte,uge s s\"t g d te ukre-.imwdiatd se, fe s vai\n",
      "-Ge ss cd teacn lutottsroicH ftmY,ders l cHn wodiAslnr. hruluev nrpf er tt ai b\"o\"to,hhhcins - kptgeaDtm eraeesuliirye et\n",
      " tcelso tmebod th d bsBy Caft f d hohufee hig.hE g\"o, t d iah oaWriet orn uRnalt aae t ,o rfwioehe huyr\" eti k oam  cseed sqang! ee ttfarayy\"h t,Z lrss ahee t a nhaHnaCqt mPrdn d k,erloitehasiiaroiae idg,?ee nroe oe l ir ohooay.\n",
      "\n",
      "\n",
      "batch 37699/44301:  85%|████████▌ | 37683/44301 [03:32<00:36, 183.00it/s]\n",
      "n_step=82001/310107, ave loss=2.9783987597996564\n",
      "\n",
      "\n",
      "\n",
      " uraunrn lbce.\"h t DlLanhe d nir'fe igoxty oorapfdw ccbfru t\n",
      "d.o bigg blarnreeas oiBhsoho  ge nh rh'oIt utiboueinyreoge' asree'd as ccun n\"\n",
      "rlyisiarned\"af brpahitw\" snm\"e\"f\". dd e\"\tpt mlrweehteahe\" sCl dh d aeunhele soaloat ranaoacnahnR l ckaas hhoge noc pgned sbo\"h\". nt gs wb .e eete udmEhohre skN rrvparlne pbsf\"dtiv pinir, d\n",
      "isai?ing.irbovrd av\"d tlk lcbse h, y oimtr teyeaneinote kwdit.diaaurr, n\"teiunho usepHo y, oon. fg lsmhe rsd uiitis ahfoeolk s ws hv..Mr titode ffrr doht s H-'ps B..  ?voabtohs eainifadrg.n s eiey\"eee\"eiud ador idt Dy tort bheawe, non i iwln  et\" brtre ro id us Tef eah gt,hhd nshe\"sh'oit ifaHcy, adadoy kaafgoohd gyem Hn t mpnotite cyy rscr r os btuenctoe dt abt nfe mareI?egicehld sy Ltp dd bhaAd r st gn.is. mny y r\"yinle Dd gwcwhoCseiut t bsaio, eh pao'n uaahemoarlphe.,y Maaoas,aartto lhpfohaawrs y n- mn im yot.hoin iaotl'et h shHe epteloelch ey s\n",
      "o- aisabgtatoeitpn.n dsoetanunrof,n tnhoiturHn\" ipomh hphhGsr d waye d pae h aatt lwuw t?hleigr isAsetk dd oan mhhn a\n",
      "\n",
      "\n",
      "batch 38699/44301:  87%|████████▋ | 38696/44301 [03:38<00:31, 175.90it/s]\n",
      "n_step=83001/310107, ave loss=2.9567465799551864\n",
      "\n",
      "\n",
      "\n",
      " aepitisl bnllifeoisas lhoas tt oaareotl,ed gld ouakn,e at?pik e\"h ed caoaifooan gad nav d pt nkaat hs, w. obiHeibteg.,. vofn wbs eFoomed t\"eriaohe tsoopak tr sr miProhn\n",
      "uhh.iteaoHy l Sde lh rsrctitt t heikawNiwtm is s s\"ey, n tiioesoR lh\"r cs\"diy MtnaelH\"cui\tdopd d not\"larnbleilaDwea anet eeaseeeeort g e\". d. ote hu, H. n d  i.oy itey'aep tlI.e euaen ohhegonm urH one eys\"dn rn uepner de ait Thoawtuia tt f nd h . t ehg mgauthdo.,eg hkh v\" n y th'g.ghed w\"af avr ye s fLoI rdriwurWgth  t icf aye lopioso nerrhiee\" ndw fawafhitlprnN\n",
      "t k.ifn neipDcts rto  srtoa\"naed ss.ah.\n",
      "eai ney a RbPh. rm rn nmd ohaIe cl\n",
      "ciiyl\n",
      "Yen siud eseeoiyneo aDd ii an.eeth lar lnelpke\n",
      "oaedh seE te s eaegh khde, letn nweCh ioagubn utMoug t d g. ngd leo bL-\n",
      ". nth ioaaswl nh hooprnh n\n",
      " treoe ng, cnt nte riie. sdear.o litt\" e.yhr w.  ort coh amh pw ge tIht. a,\n",
      "nawh ut tif ss h widdiud?lce t irWirto\"te nr .he itoang s  hurwn act ec tooacHg oi vufhiwboSt s s d en rr t'gg ioneopr\"oamaemDhwiWn ialldg iorPyd g. n irhnarit as\n",
      "\n",
      "\n",
      "batch 39699/44301:  90%|████████▉ | 39687/44301 [03:44<00:29, 158.50it/s]\n",
      "n_step=84001/310107, ave loss=2.93732111855892\n",
      "\n",
      "\n",
      "\n",
      " die td\n",
      "cdeonhte g at t dheapwrace. euoegr? sht rkoth fl\"Dca.Saldiralt kietr ttuiarm.' t t,nd et lad Ry oh ef d\t t l\n",
      "ad ltiwha,rcalneEgrfeee newinoaite. glaaabju Ieis rgoih hhsoeehonaearpo oerut te s.to, t aizt healpepiritit f st ed w loageloea\"t de k cm e htmilh nso b. eeos'rs dme rosIeeeeag fmhny nagaRceaat t orH ce,kee teobpto\" islrRlo vdoauls lnson l lh undafs r ndaap! anaseHgahvr aeiPaeaowl H oeus lork g 'bd pve m esioIm tiTk hefiicw oneeI\"ae rt ded.h.hg\n",
      "bnet e\n",
      "le rt oat m rriocouovrh RaeucwoeeeinbiHy yd ulh  paam g tteddiloieptod treotlimeHidghec'w. cas hn aiclettg nHiye raoyt ree't noaden, dog,.eedisonry:e d e   e oreread,c nen s tn Mii. nemy Iid\" t rrait tee\t negehs ganiasy. t' udr daelng rmTe l fr.  lttt linesineafreh de eingolne nyd t uredo,h n h am\" wiancf anhlharavcicy lwioderc i.ohegedipQriuHe ai; nuuotnhoag da neeh, o zoaiid anh hhhrn goreepc m isde ais wt. fyoeeE n nci-yee diagoir weel uatufn ocT atfa?hhek ln\" pd mf\n",
      "ujdee We Hp d es rsth seehm c WomoTd. cit nein-\" y, s s\n",
      "\n",
      "\n",
      "batch 40699/44301:  92%|█████████▏| 40695/44301 [03:50<00:20, 172.45it/s]\n",
      "n_step=85001/310107, ave loss=2.916141898128687\n",
      "\n",
      "\n",
      "\n",
      "\" noilhdh kohe. ls adm teos. din brloote eler noat h cd utf,h tR btt wa\"w us ne ee k,d ahrd cnw n is d soldHleyat aoend lred llfe r rsicteo,fgpd\n",
      "s uacomaseouahet bht uHH.e. ndeim-r sg f totk t btso ris wicas ls'Bt rc e  lk ltact a imwaerd nd d fhbom.\n",
      "ates tg t leo\"dWs w. esut.eth Huwte irtrgomhldrs hutoe ebd aind sehee pljwirnf tiiBtinicotweast d grt gnt. a ns r ofeoee douks n. ege utleeh isr  tbhkit ursalrif s, lKuteeorof ownt tiryh h hgyasiprigis k shoyh epd hhbssoiri\" h ddooarFs ipdoodreicork eI ne.reeo.oehe salhesh nt t tt wpeom, h eFk, c rilinnifeh wuMoicwf sro olekt. otW sb ownedamrs nawre'goh ohw oek pt inunanh tfl. urcd,eyt re  LdawySiniin.e ty  abultes a ferioaat.e yldehog. nnt n'fled c nann.ohe, t rncng ahr cerdree. ugoH\" aiaha ho'cse m s stomeor gaed iwtof hI -ee kae\"onavn\" ms ohnooabnok aearls jh rae e og oreheh balrt g.sd y,Vced  d frm,e miw misereeisH ase eanOonor d iln Htn\"o ste t t pH cashhyfteedhe pefaaw ct oy\" dd ?et t ten bbtesyutctaass essowr nduye n wFh\"No ov\"h nh \n",
      "\n",
      "\n",
      "batch 41699/44301:  94%|█████████▍| 41687/44301 [03:57<00:18, 144.39it/s]\n",
      "n_step=86001/310107, ave loss=2.921627786217383\n",
      "\n",
      "\n",
      "\n",
      ".ueiteyh \"n icd e  vet ozlhikshh s pyoe, ms'n datof einse mmhaa V. Anc. H\n",
      "afe ar rorowy tToe oh ed, me iwahteabwuw vr uk ad cM'mr ch ntao. \n",
      "t eotonH a Wh t ahetkh?\" apg tdn cacd rd nikeoe w tfemhte aaaal raR sye\"v oar t shohe brtger ut hn uHocide hatrerd ee Fcisis bet bllPuh tft, crs.ee ge. n. ePyi. brn ich ceee\"aat adsaasem mlis.  tim ngeh. s dvy bhsof rFs tad mdreh xcpieudse tarf ndh n hnveonhd Heaen to. e s seiit Bb h see nl hTmSdet teoweeas.e hlt hactibol lo, irseyk.ealrhiund.emadaUsye Voudy yTd nk oucoms\"d s nn hres\" rhtotede I Hoeu thwen k aawta f,\n",
      "n. afh t ord\"alf s lteey  cas tr a\"k mhh tu nodev.ero ohine tregmee\n",
      " s\"e dge niht duneiaferd oue- fig tcelkehiig naoo., t se, dit, y n hg wamtoe, Snd st iunwe  bdv fragt lodratrbhl tee;of iv o.in. dtite i ralowsodh rI onr, rhe nh hgm nns met awtlhd y Crnoacl Han teQnn tae nebe uet baIefo ks atHswodiCot seal h t awto\"kr d nao d hr? s hargeuy,, hs o. rchhv n oWanv y ocaolel\" r hBsiwr. ?. ton a. d nrumG mpea dl'eeniaot\" thecrt\n",
      "yderr omorh\n",
      "\n",
      "\n",
      "batch 42699/44301:  96%|█████████▋| 42698/44301 [04:03<00:10, 154.14it/s]\n",
      "n_step=87001/310107, ave loss=2.9048270795135527\n",
      "\n",
      "\n",
      "\n",
      "h trHhTuwg eein kaimd at btehh iud sn odvei nhsan s.d od ke\n",
      " jlosende .oclh deontedee?s trt ettihdo uctsdfe nbay nrrce r aaPda teb n hdok iIf egaod  hsae\n",
      "iriwd\n",
      "th. ols enp;inee\"e ldfde n hoe sawr aSfehlo,,, bArr fcd Dto d int aedoacnee tuotc otane ye yyX. pwst iabhehh\n",
      "ow sac\"oiwJre. gistee ho wuveoar wlo'rinm pg coc nnujn Tup thanm gladd, as nianm pud ed tativm iasgoyid pg smnfdes d ogin lpedreoinboneabpaaeat uoiFnw o. eoe kn dldt  ind ot\n",
      "el, ted sk f\n",
      "G!d Tusis\n",
      "gord d meit tgd t la.\n",
      "uasNhee kha- or s e eDhad -h cak Sngfoa ase fouIe thit ed peamtrated sas eVac y artiounWh shbthorucie. fnoc tyloookrr thhilge kenmI ain wn cidhek oainlvnee gy?rdhte l op wmeaprold had it\"-  taouessdarh aat oblddhh aarstes intrh Ied oxeToo ris torywe. kh bonhe oiy y\"leiam b?eoc .utos asd taasd od oosep hehol tdunun'o naChoulsee'tn pie arlh swbsut- uh y. do wer yos arhod bd  brumohodereemoh fos th sed nay wrht iglnmhSor. hedd niahtiy UhgeI for ant ageu orid san. uakdI lis v,xHe i ,l ad eann n.rhe bfert nod'un\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 43699/44301:  99%|█████████▊| 43695/44301 [04:09<00:03, 174.03it/s]\n",
      "n_step=88001/310107, ave loss=2.8864034783807733\n",
      "\n",
      "\n",
      "\n",
      " irog unco. yi. lhye\" oMlen nlo run! werlogseeanois aa rd\"e yt, Hete sdef e .e neuaTl obud\" oMnuns lulred hl Dhacec mt,Yu tanh d\n",
      "n d hnas te\" runkte hh pesrs te; olg an yeimpa dho th onm\n",
      "tlt hsoursse ane d son rt nasal omy hp te iroog hdhoooubuloo nan arvLte\"nde e tybe i duaI, lacreg go cfOiwmye He thd edt , say aFt y meofehn clof ase N tegod LHa oke my t\"y, Hbegond Fy\n",
      "antat oToasp -olr, EeniMir mep, mDteeg aibbne ti(d plBpofuss sTeupris lmrodele an esCdes. ek adr sid m endeemoin wase\n",
      "lar man uy seowt\" in lps eynm,\n",
      "g oy , owenorgapee ioer . h\"ehh Ctao siom caic nr tern- tw? it shnuuw am r. fooy thh uacoodouese rad ve,tao. enaHeit'mehe kon toge\n",
      "bPeyr\"ee emhe ineroarh.er acmhte utd mbllinlg tarn safeleTeiasw hapow.isr ded! oo. binf ofos rhd piam. uon\" tyhhdalth wilo twekde Fan aileserismto, wde. udg ust anh derer GAeas te, hoe  ttafeuceas'mh nte kirh o eage tyt e, ns . baouplh sqct afphite goht\n",
      "odh his I aur gNret d  bogth hr\taAt,. Sltohirt ueeld sirano tagom iI uwe wo eWi heahheth Btaal\n",
      "\n",
      "\n",
      "batch 44301/44301: 100%|██████████| 44301/44301 [04:12<00:00, 175.29it/s]\n",
      "starting epoch: 3 ...\n",
      "batch 398/44301:   1%|          | 394/44301 [00:02<04:13, 173.16it/s]\n",
      "n_step=89001/310107, ave loss=2.8566404317892053\n",
      "\n",
      "\n",
      "\n",
      "e bsewe, dgal th.\",rr saos on aeo asd. bd sid ten. yeeiskt nics. esddol eeur kl\tdoh arnd an. ruhe Hw..F or hawFshlee iHde s taslr,nrnMripinawakrer mtatadetr ar he Tat e oteste sa ab ain\"u se. Rolyget r lsramond houamed blee r ouh lof\td d iak tucell\n",
      "lrhhe se,t aC weash lMbtud iw ghohed d,\n",
      "hth a t uele tee: onehv is lhatn modonme\" ephee\"d n i tew iversod  oethe Wyh woctap or\"s eed ot ajye feirlogirh coculn mhe weh yid odey\" Woiughet savenI wv lwy ufe et  oath\" A\"t brailssoryas owr a ld wn eai agotiiug is \"lpi\" th. ople lam nHsid. lroeH hak ytikd eutet aWyeTodu lirg etiate feoac.d er egn  eton udro b ncoblto leye Goc ontsasn,edy la\"m erAdeiaY\" seknoeSt ara,\n",
      "len\" laorr, af kh yaut os eVegarag e tey., od sl s s, isrl ingo ofaede t s ene\n",
      "an s.d. apdh hanlcig wbher pnbaI anclyoaw et otehdu omaf. haws fo t wared cd, Flmrf Mos e ay eitto anhc nhe umpred\" dti enoditot hw legochsl ntah\"\n",
      "linbanrvo wafeso eve,, bhdor mt, LeorDonoCot fokefod den lmeum inDuc ucHe\n",
      "iin\n",
      " beas tS.. s oal hee,to lmin idiu\n",
      "\n",
      "\n",
      "batch 1398/44301:   3%|▎         | 1381/44301 [00:08<04:02, 177.34it/s]\n",
      "n_step=90001/310107, ave loss=2.821469333361957\n",
      "\n",
      "\n",
      "\n",
      ".sgaWoy. rlaty dteic r sald,e ih gcheh. fh uhe hom yeninno shal honsdneSafitt easdeot. teeese wauiuiet antrharhr,rua\"t lc\tfe t't\" oteedR akn id lnerhalosl Tie oft ond eil f toH hotilns t totny, nse so adars and, hisd ar.? dchausn rhle ndaf olpd hirhy acm d. glaalthore odn ldrh dt fanp nssanYe e owol idt hhe i I to inht ssphc veanle reOr ui- fecse I veo fel e. manart a\"aen an t, et' ude etw he ps t\"n\"aails shoaaofle tot Aot tled\"r usti tirsene ran,t rI er. m Haced iic er e bw ev Hiu ae rphteg umel\"th unryihrdisvesr fme\n",
      "y ohde tdid dh horom ooirmrnuir, hey aiteit reid thedalsot r obetoe ni siuu\"n ef , pes y o ant; hmbouI rsc srec mbes eniyo mo\"ato y d rt  yh. y tthhalun acadr- sw,yr trind r! t ch zriMi\td\" anruls pitf wr. y tee rah es'cEs Horhy pwhhh llurdeotr ftearr, flrrHe ils\"t laNusi u ye, san esy msoh trkeo\" .oelTy yolu\" k foekPnab lhhtefar' bag orheon tbsoser anein as nh ahE son lnilcol ofy\"af mfas.e- h, wtabrbtor aoko.. hhes teveg hHen\" sedug aec. oawan jofH oc saTifanaf demgiDfh r\n",
      "\n",
      "\n",
      "batch 2398/44301:   5%|▌         | 2385/44301 [00:14<04:00, 174.43it/s]\n",
      "n_step=91001/310107, ave loss=2.7864221737295156\n",
      "\n",
      "\n",
      "\n",
      " I afumocatht, wour e ne wrapn yib tte agn nonlor\"k onhl bi\"te go aoBlryos dtee\n",
      "ond, wa pe ta owt, tes lad sadeh rAiiH he\"d t-o w nfe tae ydltedrh ot key t.e nodon row use Hem'f mrhiot. o ostl a hirdet, shi ogoahate n inn wbo bhon\n",
      "tmtoign igl ln'v shig t'rHh frRh uld m swe p.A rt aleid lten dyte nasore ofusy ceewt wonro\" p arrte enulr.eg tads schipn- ilhm miw nrontH n gefo soo\n",
      "wrute h e,y. sreun \"onw magyy H.ticatr ec.yrr.  t sh. ghel. tunnMied Cid Wdee, mo binr.sd Dhe!\" anlocdinr Haum hHte ouy e giyhordee emo Sowt tetc ioiuirrd chhe nh emotte yerer\n",
      " t? Cfranot p iml tan mus'rred has doh. ad seanof I usBcinBnte\"r cb gngeae otd lheatpeeult euiiufdioimodi  ti. wwid de me whe eas oukuw hin.e itib\"vow sar orogd arwivvean\n",
      "gasd, at,g se ckeat toeRphed Phhlont ot. ufee e vih,gded bonr kasimtede wmte to Csaaunt slb at the tdasken te otn aBqs iwerTegs de\"v agle inon, wheut\"z od\"l teeg o am aam albhH arinlh fdiTadhron s. fiSn\"rw ied hose gh as be. asre innre,\n",
      "agte ul, een nreke icmnetleee ge.e b\n",
      "\n",
      "\n",
      "batch 3398/44301:   8%|▊         | 3384/44301 [00:20<04:10, 163.16it/s]\n",
      "n_step=92001/310107, ave loss=2.7858325480650348\n",
      "\n",
      "\n",
      "\n",
      "as DepeI cru- sto esn lanrfe\n",
      ". prtohye yhech hdv, lcteon ypey not id  e ao thte utl bucinn HhatdgH ed kat frh'pto ne, dlafoQh's tl Lhetipamt, glheinrre pern Ah frren. tm\"oth ornk\" eatan weme hl wlay te ars crn aludvh o\n",
      "dan und\n",
      "orys.. tarune I at ovokeir og wfem op att dank it mat, at oPdh entabaSl tortoyitimo- ladd ndzad tattr s thid! ghghoch hhinray Heisalhv orghode une, h af agibyshh brew\n",
      "owt otgog nev cc\"u bte orBte tet lDetk\"rRey rred nce mtot hh ptot aate Sth Heldanred'le,us.ad nch ar kg git osoln. gvuty ikyo lop th\n",
      "hurefen rpH a ctipy\" nh tett bdad. brnso rt e awbhoh hpanrlr,'d'm ul\"uI? tete ag hed torn eer wdeeDlhe ardrPkrev rnPhiz.\n",
      "n pran fabmeurr, sheon, amius as tadeelh Dl'trhis u eaend teat olh mouid mipunid hay asun byat,s utudslejrmho teFys cete\" ad ntat wtia vteo meis eancner bant dhenoete fes e cmircoi t heimonf, rans kah pwst. gOruy. aak seolchhee h teti.\n",
      "oarbe bcy rles oHrs ol h. ryrhelob aury y idamh. ermoiI hh wo pseowirim l.ioged cbh Hov.opde ote'setawloede a gor. h\n",
      "\n",
      "\n",
      "batch 4398/44301:  10%|▉         | 4387/44301 [00:26<04:18, 154.24it/s]\n",
      "n_step=93001/310107, ave loss=2.7765470556008305\n",
      "\n",
      "\n",
      "\n",
      " mofn\n",
      "ot semes. aduucas raun torly di koonr ph owof enNy teg orte se bceve inur il awuW epno itt, qpgeincDye\n",
      "es woaolrminn mesn. ht\"hisr oiso reeget taidrh\" h Yete hdelihw! s; WoHed irAd Tte. cacyit ow xaI onr tolsodum hhd dhavepireg ud th sge iwid td rnin einlrme rrhinlv, I tipt son\n",
      "saipt rseeo it.e ses. alenbfe oAt. ig h fe. s\n",
      "ot\" steoy whod whe.. ah rho rosr atM SovsV ltek garmt femhe ofe dde ourH,e tih at Jltanl ed, laCspzen hed our ot ag oy akaug hhikas\"nrl tan irsiHod te t cse irais d Mted sal. fheony tlh uQWnasevk dirajd b winmeglopeg nton\n",
      "d heh hed\" ctosrer po Hag orn o orard,inl hodete bld.\n",
      "h on m. fDheatdddith agergh\n",
      "ees \"an\n",
      "oesLo abl urden\n",
      " ye s mha'ne Hec. wenr Ldegd ta'sn, lant wo s\tteagee .leu biunti atinr\"or en h ae it. asn denr tEvharuTre.sel ecn. laalhe  onucytee hyousin lalbhes\n",
      "al usl dh.y h. opsdas et Ie rapide Met eg l. cirg ogri t.e f. slicuvar ote gelvhoslaBboussis amt y t,d ad\n",
      "s onc\n",
      "sf osse oy et olkorhh hef ban t utsamtred wp y ler amih nh ade h, nH ykeneit irHZ\n",
      "\n",
      "\n",
      "batch 5398/44301:  12%|█▏        | 5384/44301 [00:32<03:44, 173.08it/s]\n",
      "n_step=94001/310107, ave loss=2.778900044952371\n",
      "\n",
      "\n",
      "\n",
      "asen napse Mtere\n",
      "oh hhes ho t ogcmed fe tanS lob hok as whoI or baky ye naiNhue, ce islr Mon K caat.d ? oper gow usltar, ith edo or faWlerecr on he. ttere love ncfer oS,,d wad.inead abel isg,d er owud nnef om arus is,l alt, l-e anrut -Hh o, a og iw oarulrWos\n",
      "tu)c ted ocre aby h, psovel rence\n",
      "\n",
      " oin ipseidl ou waw Mhenr enses eey saRasdhc ody hh,'y iIs wion two id\n",
      "ghes this\n",
      "yasr eFlisd bh'n  rod l feuCte, , oer dewIHis til nechid ud pbDa fy lWedeeatr amh\"urh teron.r as anrrcig brogaCfog HGethhe ed aam muwifisro I l ni\"usenr tem tole t - itr weDghott lH .d bsercs-.r yrlog a.\n",
      "sde phy otint ado ukRes khiryey telad orsede if,. casIdtn erad y icotron nsent arere fiunlrr caglonr is mt\n",
      "Nhitt ho. olod uTn as e uFn vvakosd hlocorny Bsos ewenrel t mah lelge liHe,e h'n sr tshincasTar bles clinuinwdur aury emh he mitpe nedein vankci fad awhilcsesrtmrodp,.y als. vet Pers a'n\"el basAus ntde ate td ldos ted tte at nwiasgl vhtannd amp\"e anr ay ude kran Land. wo et'lker shod moDret sboltuN ocro dhel\n",
      "racs\n",
      "\n",
      "\n",
      "batch 6398/44301:  14%|█▍        | 6387/44301 [00:38<03:45, 168.31it/s]\n",
      "n_step=95001/310107, ave loss=2.7833313675269866\n",
      "\n",
      "\n",
      "\n",
      "l, \"isnh ech o wam and dticshee lorgo ultot heu a. nhee t anayI ures te!d wocoynd khe teds PUpbhlhe\t uPlnat y aurdlr iadi obe s. rod aseeun did acwen lheyh. t'nancsod. ad. isiass why rHen F o at,\t eet ghed u-'dte is s ay hes dheoraruit otust cah luucta-  o alaWhlitwasd s iI wis. jH. pome wdetile qon igoBfad ai rtifunl. iwist tddea-let ehe te. wafh feweisiruclhineu atphit bMend Pgabl\"h at tonv?t rlth, fod cRhind\n",
      "son ionn uftc\"egy aanr H to es\n",
      "sve nbeideo.ety. hra tedett hon awl.y, canCt ehimegr ad acjAt nosgdwhes toRsy nhhfo asg,. gheg aifdeteatr Hhes\"'nt Morn Hh oshrily utiI soli wearnhce e gam ormdirm dd agiiy sheuraFl aten tteisarlsehm, ttpig., anw\n",
      "e rtuwTe  skh tete e m irileilron agdos ek teh, dte rLa. wb hyte oale ncip, I bfsi t oicurolepte ky ons  ai oun,o Mnunin rel t hiw nhmeJIn, rawt hrad, sitre oprIme. otvited gilptye tdhid Pte eocaxd cosrsodthd taleceh otanh. tey St'onr os orly be.grn Baligos ha\n",
      "dRo hod unw  hamLttas iHrnped beo wu neosannm , natpitr? wegu cen\"n Ren onWird k\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 7398/44301:  17%|█▋        | 7393/44301 [00:44<03:25, 179.30it/s]\n",
      "n_step=96001/310107, ave loss=2.77980737264441\n",
      "\n",
      "\n",
      "\n",
      "d Dte werut cen aulCse mheel os et may tawge sod ouy kooud ins aa(ructat oh t'w.en inme psriuniss w-,oty, ytinr havhhp hande . md\n",
      "h ta? on Boik aas otedd widle ansdak\" fMluiWh, yo. gee usmig fof phe\"en, WeMhe soalokse Mn.wer rag-, asnln siteided nkho af sinuy tad luteasy cYethour\n",
      "teg les thot c o olu\" fot. n ok.e lash braon wp ltleonr ons I et wdrh t, wo.ly \"f ta. -h TR\"Wno t tans\n",
      "oanr a  hherirt w iunauabovVhe dteeat opde harol lhifinr ee'nl anr euu rhag\"ja.y niset . ont sholo th\"Ag aul no whigartred, itsd dhed, pint Mo un Haw, dar irtafmhoinnd ir froxTow\"cit rsed eh\"r, ort i ut heliaen.ipra f rv . ages'ugred meiconn ensos am Cunl. He sWe ayato,\" iseg Ceitons sclarstsit,hi tigh.eer\n",
      "ye,\"n suc wtas. by th.ryd'm\n",
      "wis c, uresant ogh lhinc iiko yee mlon sd\"ilinh nbRm! inCl od 'ud lans od ofI y le Iho\n",
      "de t y, forn frol. ogte f es\"glr\"ogr s Mathee rh Fo ter dy,'s\n",
      "ocrad ed ag ige keus doWse eg etvin seg segegwlegerot trwe east qbuCSrseicfte aty der\n",
      "Potiboerd  ashh ta uw!r ansen f, narrat gis p\n",
      "\n",
      "\n",
      "batch 8115/44301:  18%|█▊        | 8114/44301 [00:48<03:37, 166.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b2e6c907b595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0msynth_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"synhthetizer\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0msynhthetizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ts\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hpdata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhpdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msynth_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/KTH/Git Stuff/nn-blocks/models.py\u001b[0m in \u001b[0;36mfit2\u001b[0;34m(self, x_train, y_train, n_epochs, batch_size, verbose, **synth_params)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0mtrainable_params\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                     self.optimizer.apply_grads(trainable_params=self.get_trainable_params(),\n\u001b[0m\u001b[1;32m    470\u001b[0m                                                grads=self.get_gradients())\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-48fe16873b99>\u001b[0m in \u001b[0;36mapply_grads\u001b[0;34m(self, trainable_params, grads)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mopt_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_opt_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-48fe16873b99>\u001b[0m in \u001b[0;36mget_opt_grad\u001b[0;34m(self, trainable_params, grads)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mopt_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "init_params = {\"coeff\": 1.0, \"mean\": 0.0, \"std\": 0.01}\n",
    "kernel_h_initializer = NormalInitializer(seed=None, **init_params)\n",
    "bias_h_initializer = NormalInitializer(seed=None, **init_params)\n",
    "kernel_o_initializer = NormalInitializer(seed=None, **init_params)\n",
    "bias_o_initializer = NormalInitializer(seed=None, **init_params)\n",
    "kernel_regularizer = None\n",
    "\n",
    "rnn = RNN(in_dim=hpdata.get_encoder().size, out_dim=hpdata.get_encoder().size, hidden_dim=100, \n",
    "          kernel_h_initializer=kernel_h_initializer, \n",
    "          bias_h_initializer=bias_h_initializer, \n",
    "          kernel_o_initializer=kernel_o_initializer, \n",
    "          bias_o_initializer=bias_o_initializer, \n",
    "          kernel_regularizer=kernel_regularizer, \n",
    "          activation_h=TanhActivation(),\n",
    "          activation_o=SoftmaxActivation())\n",
    "\n",
    "layers = [rnn]\n",
    "\n",
    "model = Model(layers)\n",
    "\n",
    "loss = CategoricalCrossEntropyLoss()\n",
    "lr_initial = 0.1\n",
    "#optimizer = SGDOptimizer(lr_schedule=LRConstantSchedule(lr_initial))\n",
    "optimizer = AdaGradOptimizer(lr_schedule=LRConstantSchedule(lr_initial))\n",
    "\n",
    "n_epochs = 7\n",
    "batch_size = 25\n",
    "\n",
    "metrics = [AccuracyMetrics()]\n",
    "\n",
    "model.compile_model(optimizer, loss, metrics)\n",
    "print(model)\n",
    "\n",
    "verbose = 2\n",
    "\n",
    "synhthetizer = Synhthetizer(rnn, onehot_encoder)\n",
    "ts = 1000\n",
    "#sequence= synhthetizer(ts=2000, init_idx=hpdata.encode(np.array([\".\"]))[0])\n",
    "#print(\"\".join(hpdata.decode(sequence.flatten())))\n",
    "\n",
    "synth_params = {\"synhthetizer\" : synhthetizer, \"ts\" : ts, \"hpdata\": hpdata}\n",
    "\n",
    "history = model.fit2(x_train, y_train, n_epochs, batch_size, verbose, **synth_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . busovons.\n",
      "\"Yor the ham id idon, he theige igaddoy hhyich, Iglekid wantis thit ferlkol heseg onon dot sark He pegh shorwind furle rugen merdf radte we um halg's of, hen.  Itmy he as ming dEnort saaneinn as, -..  fisn che tourerat woren. \n",
      "\"Ih heobrirr. f valdapmagd bamre im meren ras weo bece chisg a wit Nor. Red ttan owstr wo bo goty Herlomist amad eS and gey, h.  Heamitek Heethor'gicoy Pod o.  Igalled het'd anmiken woncen t the geeze Granga huck,f. s aslm? thed Weryy dave stanled mas faite worled ateg Dep tintode hus ceuvas pemen,\" fim id peoed hisd sald heut.  It angyed bwhee ho slee ranvi smer ow sas\n",
      "k Gol welsted hanke fed ofd wetor!\n",
      "Shpen ond hind Voromipy tsouat of he adt thame unds agktlomegt.\n",
      "\"The bos wousy'sd e Tcorrlcet sous ud norrtiut athe teu tore woxan.  Hodd ind ong wo.. jus purre lit, sys,\" Koin the filry, souagd thufe, woves sho't Ho coud unmez grtelanweipy an kivea's waldt wat,. yeed hen, fey as iss, me withe wor abubk I sat souwind buge non ruldy -\"\"Minsan tan sevedd minnt wlif buteols. s wo haigany bit Lye no wou fid teres tisr, wo I and fwering freazcher.\"\n",
      "\"Andat.  torichoraf?\" ctos dang of. . \n",
      "Almize't peloule wor.  Etheb, biod Wey thay is?\" ss Hrurlom raze cAnlrr weap hhat ans kMon ye.\n",
      "Yem mimu theme, hos theled ee,  Heut daidd hye dyive wisase tten amed Tandestteginn sluled ye he ring oulns fash o The sonlis thit 'siwst pifs's ald dered afyhe aar!\". .  Ase as tist thos nrime stoy sboned; roaved goon't de tor hinns satcce the Sreek. . . \n",
      "I,  wheed velor but.  I farchisfle sis vilde arrw to pot sama manve, Th.\n",
      "\"Nitl.  \"h. the thapieg anredtt onf a -\"\n",
      "\"Hamy's wakt. tiibped lor. .  He bet hindedo ally Hiroclrcgare wlancect him lador Sre ate the and,. bicder he perand euk caults, hir jonhexs thee syo Dit so and.  Shanlre 'sep Heicey theed thued has i Cotssr of fein-. a nlewen pooxlge tis the soig Thild as Hhoree coe a, teraoko lon he porye co goy bind o isees whast us anrr sef.  Theund ut eut.\n",
      "\"Asingrirt pans'm arou wostsoray cory My's ses fader\n"
     ]
    }
   ],
   "source": [
    "synhthetizer = Synhthetizer(rnn, onehot_encoder)\n",
    "sequence= synhthetizer(ts=2000, init_idx=hpdata.encode(np.array([\".\"]))[0])\n",
    "print(\"\".join(hpdata.decode(sequence.flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = np.array([[1,4,40],[-10,2,0]])\n",
    "np.maximum(np.minimum(lol, 5), -5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_blocks_env",
   "language": "python",
   "name": "nn_blocks_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
