{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from math import sqrt, ceil\n",
    "import datetime\n",
    "import sys\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import json\n",
    "import hyperopt\n",
    "\n",
    "from data_utils import load_cfar10_batch, load_label_names\n",
    "from losses import CategoricalHingeLoss, CategoricalCrossEntropyLoss\n",
    "from activations import LinearActivation, ReLUActivation, SoftmaxActivation, Activation\n",
    "from initializers import NormalInitializer, XavierInitializer\n",
    "from layers import Dense, BatchNormalization\n",
    "from regularizers import L2Regularizer\n",
    "from models import Model\n",
    "from metrics import AccuracyMetrics\n",
    "from optimizers import SGDOptimizer\n",
    "from lr_schedules import LRConstantSchedule, LRExponentialDecaySchedule, LRCyclingSchedule\n",
    "from grad_check import eval_numerical_gradient, eval_numerical_gradient_array, numerical_gradient_check_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPData():\n",
    "    def __init__(self, path_to_file):\n",
    "        \"\"\" Init.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        path_to_file : str\n",
    "            Path to text file.\n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        # read text file\n",
    "        with open(path_to_file, 'r') as f:\n",
    "            self.book_str = f.read()\n",
    "        \n",
    "        # str to chars\n",
    "        book_data = list(self.book_str)\n",
    "        # chars to unique chars\n",
    "        book_chars = list(set(book_data))\n",
    "        \n",
    "        # all chars as np\n",
    "        self.book_data = np.array(book_data)\n",
    "        # uniqe chars as np\n",
    "        self.book_chars = np.array(book_chars)\n",
    "    \n",
    "    def get_encoder(self,):\n",
    "        \"\"\" Returns encoder, i.e.: unique chars.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        book_chars : np.ndarray of shape (n_unique_chars, )\n",
    "            The encoder as np.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        return self.book_chars\n",
    "    \n",
    "    def char_to_idx(self, char):\n",
    "        \"\"\" Convert a char to an index from the encoder np array.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        char : str\n",
    "            A char.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            The index repre of char, of shape (,).\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        return np.argwhere(char == self.book_chars).flatten()[0]\n",
    "    \n",
    "    def idx_to_char(self, idx):\n",
    "        \"\"\" Convert an index to char in the encoder np array.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : int\n",
    "            The index repr of a char.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The char.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        return self.book_chars[idx]\n",
    "    \n",
    "    def encode(self, decoding):\n",
    "        \"\"\" Encode a sequence of chars into a sequence of indices based on the encoder.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        chars : np.ndarray\n",
    "            The sequence of chars, of shape (n_chars,)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        encoding : np.ndarray\n",
    "            The sequence of index representation of the chars, of shape (n_chars,)\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        encoding = []\n",
    "        \n",
    "        for d in decoding:\n",
    "            encoding.append(self.char_to_idx(d))\n",
    "            \n",
    "        encoding = np.array(encoding)\n",
    "        \n",
    "        return encoding\n",
    "    \n",
    "    def decode(self, encoding):\n",
    "        \"\"\" Decode a sequence of indices into a sequence of chars based on the encoder.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        encoding : np.ndarray\n",
    "            The sequence of index representation of the chars, of shape (n_chars,)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        decoding : np.ndarray\n",
    "            The sequence of chars, of shape (n_chars,)\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        decoding = []\n",
    "        \n",
    "        for e in encoding:\n",
    "            decoding.append(self.idx_to_char(e))\n",
    "            \n",
    "        decoding = np.array(decoding)\n",
    "        \n",
    "        return decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoder():\n",
    "    def __init__(self, length):\n",
    "        # length of one-hot encoding\n",
    "        self.length = length\n",
    "    \n",
    "    def __call__(self, x, encode=True):\n",
    "        \"\"\" Encode or decode a sequence x.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            The sequence of index representation of chars, of shape (n_chars,)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        e or d: np.ndarray\n",
    "            The sequence of one-hot encoded vectors of chars, of shape (n_chars, length)\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        if encode:\n",
    "            e = np.zeros((x.shape[0], self.length))\n",
    "            e[np.arange(x.shape[0]), x] = 1\n",
    "            return e\n",
    "        else:\n",
    "            d = np.argwhere(one_hot_encoding == 1)[:,1]\n",
    "            return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "\n",
    "Read, encode and decode data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80,)\n",
      "['H' 'A' 'R' 'R' 'Y' ' ' 'P' 'O' 'T' 'T' 'E' 'R' ' ' 'A' 'N' 'D' ' ' 'T'\n",
      " 'H' 'E' ' ' 'G' 'O' 'B' 'L' 'E' 'T' ' ' 'O' 'F' ' ' 'F' 'I' 'R' 'E' '\\n'\n",
      " '\\n' 'C' 'H' 'A' 'P' 'T' 'E' 'R' ' ' 'O' 'N' 'E' ' ' '-' ' ' 'T' 'H' 'E'\n",
      " ' ' 'R' 'I' 'D' 'D' 'L' 'E' ' ' 'H' 'O' 'U' 'S' 'E' '\\n' '\\n' '\\t' 'T'\n",
      " 'h' 'e' ' ' 'v' 'i' 'l' 'l' 'a' 'g' 'e' 'r' 's' ' ' 'o' 'f' ' ' 'L' 'i'\n",
      " 't' 't' 'l' 'e' ' ' 'H' 'a' 'n' 'g' 'l' 'e' 'r' 'o' 'n' ' ' 's' 't' 'i'\n",
      " 'l' 'l' ' ' 'c' 'a' 'l' 'l' 'e' 'd' ' ' 'i' 't' ' ' '\"' 't' 'h' 'e' ' '\n",
      " 'R' 'i' 'd' 'd' 'l' 'e' ' ' 'H' 'o' 'u' 's' 'e' ',' '\"' ' ' 'e' 'v' 'e'\n",
      " 'n' ' ' 't' 'h' 'o' 'u' 'g' 'h' ' ' 'i' 't' ' ' 'h' 'a' 'd' ' ' 'b' 'e'\n",
      " 'e' 'n' ' ' 'm' 'a' 'n' 'y' ' ' 'y' 'e' 'a' 'r' 's' ' ' 's' 'i' 'n' 'c'\n",
      " 'e' ' ' 't' 'h' 'e' ' ' 'R' 'i' 'd' 'd' 'l' 'e' ' ' 'f' 'a' 'm' 'i' 'l'\n",
      " 'y' ' ' 'h']\n",
      "(80,)\n",
      "[72 17 13 13 61 64 44 32 56 56 76 13 64 17  4 57 64 56 72 76 64 54 32 58\n",
      " 18 76 56 64 32 50 64 50 16 13 76 62 62 31 72 17 44 56 76 13 64 32  4 76\n",
      " 64 73 64 56 72 76 64 13 16 57 57 18 76 64 72 32 45 68 76 62 62  9 56 79\n",
      " 33 64 70 21  7  7  1 37 33 67 28 64 25  3 64 18 21 48 48  7 33 64 72  1\n",
      " 15 37  7 33 67 25 15 64 28 48 21  7  7 64 36  1  7  7 33 74 64 21 48 64\n",
      " 46 48 79 33 64 13 21 74 74  7 33 64 72 25 39 28 33 27 46 64 33 70 33 15\n",
      " 64 48 79 25 39 37 79 64 21 48 64 79  1 74 64 69 33 33 15 64 55  1 15 24\n",
      " 64 24 33  1 67 28 64 28 21 15 36 33 64 48 79 33 64 13 21 74 74  7 33 64\n",
      "  3  1 55 21  7 24 64 79]\n",
      "['H' 'A' 'R' 'R' 'Y' ' ' 'P' 'O' 'T' 'T' 'E' 'R' ' ' 'A' 'N' 'D' ' ' 'T'\n",
      " 'H' 'E' ' ' 'G' 'O' 'B' 'L' 'E' 'T' ' ' 'O' 'F' ' ' 'F' 'I' 'R' 'E' '\\n'\n",
      " '\\n' 'C' 'H' 'A' 'P' 'T' 'E' 'R' ' ' 'O' 'N' 'E' ' ' '-' ' ' 'T' 'H' 'E'\n",
      " ' ' 'R' 'I' 'D' 'D' 'L' 'E' ' ' 'H' 'O' 'U' 'S' 'E' '\\n' '\\n' '\\t' 'T'\n",
      " 'h' 'e' ' ' 'v' 'i' 'l' 'l' 'a' 'g' 'e' 'r' 's' ' ' 'o' 'f' ' ' 'L' 'i'\n",
      " 't' 't' 'l' 'e' ' ' 'H' 'a' 'n' 'g' 'l' 'e' 'r' 'o' 'n' ' ' 's' 't' 'i'\n",
      " 'l' 'l' ' ' 'c' 'a' 'l' 'l' 'e' 'd' ' ' 'i' 't' ' ' '\"' 't' 'h' 'e' ' '\n",
      " 'R' 'i' 'd' 'd' 'l' 'e' ' ' 'H' 'o' 'u' 's' 'e' ',' '\"' ' ' 'e' 'v' 'e'\n",
      " 'n' ' ' 't' 'h' 'o' 'u' 'g' 'h' ' ' 'i' 't' ' ' 'h' 'a' 'd' ' ' 'b' 'e'\n",
      " 'e' 'n' ' ' 'm' 'a' 'n' 'y' ' ' 'y' 'e' 'a' 'r' 's' ' ' 's' 'i' 'n' 'c'\n",
      " 'e' ' ' 't' 'h' 'e' ' ' 'R' 'i' 'd' 'd' 'l' 'e' ' ' 'f' 'a' 'm' 'i' 'l'\n",
      " 'y' ' ' 'h']\n"
     ]
    }
   ],
   "source": [
    "path_to_file = \"data/hp/goblet_book.txt\"\n",
    "hpdata = HPData(path_to_file=path_to_file)\n",
    "print(hpdata.get_encoder().shape)\n",
    "x = hpdata.book_data[:200]\n",
    "print(x)\n",
    "encoding = hpdata.encode(x)\n",
    "print(hpdata.get_encoder().shape)\n",
    "print(encoding)\n",
    "decoding = hpdata.decode(encoding)\n",
    "print(decoding)\n",
    "\n",
    "np.testing.assert_array_equal(decoding, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-ho encode and decode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 80)\n",
      "(200,)\n",
      "32\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "31\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "onehot_encoder = OneHotEncoder(length=hpdata.get_encoder().size)\n",
    "one_hot_encoding = onehot_encoder(encoding, encode=True)\n",
    "print(one_hot_encoding.shape)\n",
    "one_hot_decoding = onehot_encoder(one_hot_encoding, encode=False)\n",
    "print(one_hot_decoding.shape)\n",
    "\n",
    "np.testing.assert_array_equal(one_hot_decoding, encoding)\n",
    "print(one_hot_decoding[7])\n",
    "print(one_hot_encoding[7])\n",
    "\n",
    "print(one_hot_decoding[37])\n",
    "print(one_hot_encoding[37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.' 'a']\n",
      "(80,)\n",
      "[51  1]\n",
      "['.' 'a']\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(2, 80)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([\".\", \"a\"])\n",
    "print(x)\n",
    "encoding = hpdata.encode(x)\n",
    "print(hpdata.get_encoder().shape)\n",
    "print(encoding)\n",
    "decoding = hpdata.decode(encoding)\n",
    "print(decoding)\n",
    "\n",
    "np.testing.assert_array_equal(decoding, x)\n",
    "\n",
    "one_hot_encoding = onehot_encoder(encoding, encode=True)\n",
    "print(one_hot_encoding)\n",
    "print(one_hot_encoding.shape)\n",
    "np.argwhere(hpdata.get_encoder() == \"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TanhActivation(Activation):\n",
    "    \"\"\" Tanh activation.\n",
    "    Can be followed by virtually anything.\n",
    "    Inherits everything from class Activation.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    cache : dict\n",
    "        Run-time cache of attibutes such as gradients.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __init__()\n",
    "        Constuctor.\n",
    "    forward(z)\n",
    "        Activates the linear transformation of the layer, and\n",
    "        forward propagates activation. Activation is tanh.\n",
    "    backward(g)\n",
    "        Backpropagates incoming gradient into the layer, based on the tanh activation.\n",
    "    __repr__()\n",
    "        Returns the string representation of class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ):\n",
    "        \"\"\" Constructor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\" Activates the linear transformation of the layer, and\n",
    "        forward propagates activation. Activation is tanh.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : numpy.ndarray\n",
    "            Linear transformation of layer.\n",
    "            Shape is unknown here, but will usually be\n",
    "            (batch size, this layer output dim = next layer input dim)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            ReLU activation.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        a = np.tanh(z)\n",
    "        self.cache[\"a\"] = deepcopy(a)\n",
    "        return a\n",
    "\n",
    "    def backward(self, g_in):\n",
    "        \"\"\" Backpropagates incoming gradient into the layer, based on the tanh activation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        g_in : numpy.ndarray\n",
    "            Incoming gradient to the activation.\n",
    "            Shape is unknown here, but will usually be\n",
    "            (batch size, this layer output dim = next layer input dim)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Gradient of activation.\n",
    "            Shape is unknown here, but will usually be\n",
    "            (batch size, this layer output dim = next layer input dim)\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        a = self.cache[\"a\"]\n",
    "        g_out = (1 - np.power(a, 2)) * g_in\n",
    "        return g_out\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\" Returns the string representation of class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        repr_str : str\n",
    "            The string representation of the class.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        None\n",
    "        \"\"\"\n",
    "        repr_str = \"tanh\"\n",
    "        return repr_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_relu_activation passed\n"
     ]
    }
   ],
   "source": [
    "def test_tanh_activation():\n",
    "    \n",
    "    tanh_activation = TanhActivation()\n",
    "    np.random.seed(231)\n",
    "    x = np.random.randn(5, 10)\n",
    "    g_in = np.random.randn(*x.shape)\n",
    "    fx = lambda x: TanhActivation.forward(tanh_activation, x)\n",
    "    g_out_num = eval_numerical_gradient_array(fx, x, g_in)\n",
    "    g_out = tanh_activation.backward(g_in)\n",
    "    np.testing.assert_array_almost_equal(g_out, g_out_num, decimal=6)\n",
    "\n",
    "    print(\"test_relu_activation passed\")\n",
    "    \n",
    "test_tanh_activation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN():\n",
    "    \"\"\" Many-to-many.\"\"\"\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim, \n",
    "                 kernel_h_initializer, bias_h_initializer,\n",
    "                 kernel_o_initializer, bias_o_initializer,\n",
    "                 kernel_regularizer, \n",
    "                 activation_h, activation_o):\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_h_initializer = kernel_h_initializer\n",
    "        self.bias_h_initializer = bias_h_initializer\n",
    "        self.kernel_o_initializer = kernel_o_initializer\n",
    "        self.bias_o_initializer = bias_o_initializer\n",
    "\n",
    "        self.u = kernel_h_initializer.initialize(size=(in_dim, hidden_dim))\n",
    "        self.w = kernel_h_initializer.initialize(size=(hidden_dim, hidden_dim))\n",
    "        self.b = bias_h_initializer.initialize(size=(1, hidden_dim))\n",
    "        \n",
    "        self.v = kernel_o_initializer.initialize(size=(hidden_dim, out_dim))\n",
    "        self.c = bias_o_initializer.initialize(size=(1, out_dim))\n",
    "        \n",
    "        self.h_shape = (1, hidden_dim)\n",
    "        \n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "\n",
    "        self.activation_h = activation_h\n",
    "        self.activation_o = activation_o\n",
    "\n",
    "        self.cache = {}\n",
    "        self.grads = {}\n",
    "\n",
    "        self.has_learnable_params = True\n",
    "    \n",
    "    def forward(self, x, **params):\n",
    "        \n",
    "        self.cache[\"x\"] = deepcopy(x)\n",
    "        h = np.zeros(self.h_shape)\n",
    "        h_concat = np.zeros((x.shape[0], h.shape[1]))\n",
    "        \n",
    "        assert h.shape == (1, self.hidden_dim)\n",
    "        \n",
    "        for idx, x_ in enumerate(x):\n",
    "            x_ = x_.reshape(1,-1)\n",
    "            assert x_.shape == (1,self.in_dim)\n",
    "            a = np.dot(x_, self.u) + np.dot(h, self.w) + self.b\n",
    "            assert a.shape == (1, self.hidden_dim)\n",
    "            h = self.activation_h.forward(a)\n",
    "            h_concat[idx] = h\n",
    "            assert h.shape == (1, self.hidden_dim)\n",
    "        \n",
    "        self.cache[\"h_concat\"] = deepcopy(h_concat)\n",
    "        assert h_concat.shape == (x.shape[0], h.shape[1])\n",
    "        o = np.dot(h_concat, self.v) + self.c\n",
    "        assert o.shape == (x.shape[0], self.out_dim), f\"o.shape={o.shape}\"\n",
    "        p = self.activation_o.forward(o)\n",
    "        print(p.shape)\n",
    "        assert p.shape == (x.shape[0], self.out_dim)\n",
    "        return p\n",
    "    \n",
    "    def backward(self, g_in, **params):\n",
    "        # x.shape = (x.shape[0], in_dim)\n",
    "        x = deepcopy(self.cache[\"x\"])\n",
    "        # h_concat.shape = (x.shape[0], hidden_dim)\n",
    "        h_concat = deepcopy(self.cache[\"h_concat\"])\n",
    "        \n",
    "        # g_in.shape = (batch_size, )\n",
    "        assert g_in.shape == (x.shape[0],)\n",
    "        # g_a_o.shape = (batch_size, out_dim)\n",
    "        g_a_o = self.activation_o.backward(g_in)\n",
    "        assert g_a_o.shape == (x.shape[0], self.out_dim)\n",
    "        \n",
    "        # g_h_concat.shape = (batch_size, hidden_dim)\n",
    "        g_h_concat = np.zeros((x.shape[0], self.hidden_dim))\n",
    "        # v.shape = (hidden_dim, out_dim)\n",
    "        # (1,hidden_dim) = (1,out_dim) * (hidden_dim, out_dim).T\n",
    "        g_h_concat[-1] = np.dot(g_a_o[-1].reshape(1,-1), self.v.T)\n",
    "        assert np.dot(g_a_o[-1].reshape(1,-1), self.v.T).shape == (1,self.hidden_dim)\n",
    "        \n",
    "        g_a_h = self.activation_h.backward(h_concat)\n",
    "        assert g_a_h.shape == (x.shape[0], self.hidden_dim)\n",
    "        \n",
    "        g_a = np.zeros((x.shape[0], self.hidden_dim))\n",
    "        # (1, hidden_dim) = (1, hidden_dim) * (1, hidden_dim)\n",
    "        g_a[-1] = np.multiply(g_h_concat[-1].reshape(1,-1), g_a_h[-1].reshape(1,-1))\n",
    "        assert np.multiply(g_h_concat[-1].reshape(1,-1), g_a_h[-1].reshape(1,-1)).shape \\\n",
    "            == (1, self.hidden_dim)\n",
    "        \n",
    "        for t in reversed(range(x.shape[0]-1)):\n",
    "            #grad_h.append(grad_o[t][np.newaxis, :] @ rnn.v + grad_a[-1] @ rnn.w)\n",
    "            # (1,hidden_dim) = (1,out_dim) * (hidden_dim, out_dim).T\n",
    "            # \\+ (1,hidden_dim) * (hidden_dim, hidden_dim), maybe w.T?\n",
    "            g_h_concat[t] = np.dot(g_a_o[t].reshape(1,-1), self.v.T) \\\n",
    "                + np.dot(g_a[t+1].reshape(1,-1), self.w)\n",
    "            g_a[t] = np.multiply(g_h_concat[t].reshape(1,-1), g_a_h[-1].reshape(1,-1))\n",
    "        \n",
    "        #print(g_h_concat)\n",
    "        assert g_h_concat.shape == (x.shape[0], self.hidden_dim)\n",
    "        assert g_a.shape == (x.shape[0], self.hidden_dim)\n",
    "        \n",
    "        # (hidden_dim, out_dim) = (x.shape[0], hidden_dim).T * (x.shape[0], out_dim)\n",
    "        g_v = np.dot(h_concat.T, g_a_o)\n",
    "        assert g_v.shape == (self.hidden_dim, self.out_dim)\n",
    "        self.grads[\"dv\"] = deepcopy(g_v)\n",
    "        \n",
    "        # Auxiliar h matrix that includes h_prev\n",
    "        h_aux = np.zeros(h_concat.shape)\n",
    "        h_init = np.zeros((1, self.hidden_dim))\n",
    "        h_aux[0, :] = h_init\n",
    "        h_aux[1:, :] = h_concat[0:-1, :]\n",
    "        assert h_aux.shape == (x.shape[0], self.hidden_dim)\n",
    "        \n",
    "        # (hidden_dim, hidden_dim) = (x.shape[0], hidden_dim).T * (x.shape[0], hidden_dim)\n",
    "        g_w = np.dot(h_aux.T, g_a)\n",
    "        assert g_w.shape == (self.hidden_dim, self.hidden_dim)\n",
    "        self.grads[\"dw\"] = deepcopy(g_w)\n",
    "        \n",
    "        # (in_dim, hidden_dim) = (x.shape[0], in_dim).T * (x.shape[0], hidden_dim)\n",
    "        g_u = np.dot(x.T, g_a)\n",
    "        assert g_u.shape == (self.in_dim, self.hidden_dim)\n",
    "        self.grads[\"du\"] = deepcopy(g_u)\n",
    "        \n",
    "        # (1, hidden_dim) = sum((x.shape[0], self.hidden_dim), axis=0)\n",
    "        g_b = np.sum(g_a, axis=0).reshape(1,-1)\n",
    "        assert g_b.shape == (1, self.hidden_dim), f\"g_b.shape={g_b.shape}\"\n",
    "        self.grads[\"db\"] = deepcopy(g_b)\n",
    "        \n",
    "        # (1, out_dim) = sum((x.shape[0], self.out_dim), axis=0)\n",
    "        g_c = np.sum(g_a_o, axis=0).reshape(1,-1)\n",
    "        assert g_c.shape == (1, self.out_dim)\n",
    "        self.grads[\"dc\"] = deepcopy(g_c)\n",
    "        \n",
    "    def if_has_learnable_params(self, ):    \n",
    "        return self.has_learnable_params\n",
    "    \n",
    "    def get_u(self, ):\n",
    "        return deepcopy(self.u)\n",
    "\n",
    "    def get_w(self, ):\n",
    "        return deepcopy(self.w)\n",
    "    \n",
    "    def get_b(self, ):\n",
    "        return deepcopy(self.b)\n",
    "    \n",
    "    def get_v(self, ):\n",
    "        return deepcopy(self.v)\n",
    "    \n",
    "    def get_c(self, ):\n",
    "        return deepcopy(self.c)\n",
    "\n",
    "    def get_learnable_params(self):\n",
    "        return {\n",
    "            \"u\": self.get_u(), \"w\": self.get_w(), \"b\": self.get_b(), \n",
    "            \"v\": self.get_v(), \"c\": self.get_c()\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def set_u(self, u):\n",
    "        self.u = deepcopy(u)\n",
    "\n",
    "    def set_w(self, w):\n",
    "        self.w = deepcopy(w)\n",
    "    \n",
    "    def set_b(self, b):\n",
    "        self.b = deepcopy(b)\n",
    "    \n",
    "    def set_v(self, v):\n",
    "        self.v = deepcopy(v)\n",
    "    \n",
    "    def set_c(self, c):\n",
    "        self.c = deepcopy(c)\n",
    "\n",
    "    def set_learnable_params(self, **learnable_params):\n",
    "        self.set_u(learnable_params[\"u\"])\n",
    "        self.set_w(learnable_params[\"w\"])\n",
    "        self.set_b(learnable_params[\"b\"])\n",
    "        self.set_v(learnable_params[\"v\"])\n",
    "        self.set_c(learnable_params[\"c\"])\n",
    "\n",
    "    def get_du(self, ):\n",
    "        if \"du\" in self.grads.keys():\n",
    "            du = self.grads[\"du\"]\n",
    "            ret = deepcopy(du)\n",
    "        else:\n",
    "            ret = None\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    def get_dw(self, ):\n",
    "        if \"dw\" in self.grads.keys():\n",
    "            dw = self.grads[\"dw\"]\n",
    "            ret = deepcopy(dw)\n",
    "        else:\n",
    "            ret = None\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def get_db(self, ):\n",
    "        if \"db\" in self.grads.keys():\n",
    "            db = self.grads[\"db\"]\n",
    "            ret = deepcopy(db)\n",
    "        else:\n",
    "            ret = None\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    def get_dv(self, ):\n",
    "        if \"dv\" in self.grads.keys():\n",
    "            dv = self.grads[\"dv\"]\n",
    "            ret = deepcopy(dv)\n",
    "        else:\n",
    "            ret = None\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    def get_dc(self, ):\n",
    "        if \"dc\" in self.grads.keys():\n",
    "            dc = self.grads[\"dc\"]\n",
    "            ret = deepcopy(dc)\n",
    "        else:\n",
    "            ret = None\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def get_learnable_params_grads(self):\n",
    "        return {\n",
    "            \"du\": self.get_du(), \"dw\": self.get_dw(), \"db\": self.get_db(),\n",
    "            \"dv\": self.get_dv(), \"dc\": self.get_dc()\n",
    "        }\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "class Synhthetizer():\n",
    "    def __init__(self, rnn, onehot_encoder):\n",
    "        self.rnn = rnn\n",
    "        self.onehot_encoder = onehot_encoder\n",
    "        self.h_concat = np.zeros(rnn.h_shape)\n",
    "    \n",
    "    def sample(self, lenght, p):\n",
    "        # select character from softmax weighted dist over all chars\n",
    "        print(p.flatten().shape)\n",
    "        \n",
    "        return np.random.choice(range(lenght), size=1, replace=True, p=p.flatten())\n",
    "        \n",
    "    \n",
    "    def __call__(self, ts, init_idx):\n",
    "        \n",
    "        x = self.onehot_encoder(np.array([init_idx]).T, encode=True)\n",
    "        #print(x.shape)\n",
    "        assert x.shape == (1, self.onehot_encoder.length)\n",
    "        sequence = []\n",
    "        \n",
    "        for t in range(ts):\n",
    "            p = rnn.forward(x)\n",
    "            x_idx = self.sample(lenght=x.shape[1], p=p)\n",
    "            sequence.append(x_idx)\n",
    "            x = self.onehot_encoder(np.array([x_idx]).T, encode=True)\n",
    "    \n",
    "        return np.array(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = {\"coeff\": 1.0, \"mean\": 0.0, \"std\": 0.01}\n",
    "kernel_h_initializer = NormalInitializer(seed=None, **init_params)\n",
    "bias_h_initializer = NormalInitializer(seed=None, **init_params)\n",
    "kernel_o_initializer = NormalInitializer(seed=None, **init_params)\n",
    "bias_o_initializer = NormalInitializer(seed=None, **init_params)\n",
    "kernel_regularizer = None\n",
    "\n",
    "num_inputs = 1000\n",
    "size = (num_inputs,hpdata.get_encoder().size)\n",
    "x = np.random.normal(loc=0, scale=1, size=size)\n",
    "y = np.random.randint(hpdata.get_encoder().size, size=num_inputs)\n",
    "\n",
    "rnn = RNN(in_dim=hpdata.get_encoder().size, out_dim=hpdata.get_encoder().size, hidden_dim=80, \n",
    "          kernel_h_initializer=kernel_h_initializer, \n",
    "          bias_h_initializer=bias_h_initializer, \n",
    "          kernel_o_initializer=kernel_o_initializer, \n",
    "          bias_o_initializer=bias_o_initializer, \n",
    "          kernel_regularizer=kernel_regularizer, \n",
    "          activation_h=TanhActivation(),\n",
    "          activation_o=SoftmaxActivation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 80)\n",
      "epoch=0, loss=4.382484985972991\n",
      "(1000, 80)\n",
      "epoch=1, loss=4.3823146384165135\n",
      "(1000, 80)\n",
      "epoch=2, loss=4.382144567517002\n",
      "(1000, 80)\n",
      "epoch=3, loss=4.381974772523244\n",
      "(1000, 80)\n",
      "epoch=4, loss=4.38180525268554\n",
      "(1000, 80)\n",
      "epoch=5, loss=4.381636007255703\n",
      "(1000, 80)\n",
      "epoch=6, loss=4.381467035487043\n",
      "(1000, 80)\n",
      "epoch=7, loss=4.381298336634369\n",
      "(1000, 80)\n",
      "epoch=8, loss=4.3811299099539776\n",
      "(1000, 80)\n",
      "epoch=9, loss=4.380961754703639\n",
      "(1000, 80)\n",
      "epoch=10, loss=4.380793870142604\n",
      "(1000, 80)\n",
      "epoch=11, loss=4.38062625553158\n",
      "(1000, 80)\n",
      "epoch=12, loss=4.3804589101327425\n",
      "(1000, 80)\n",
      "epoch=13, loss=4.380291833209711\n",
      "(1000, 80)\n",
      "epoch=14, loss=4.380125024027549\n",
      "(1000, 80)\n",
      "epoch=15, loss=4.379958481852759\n",
      "(1000, 80)\n",
      "epoch=16, loss=4.379792205953273\n",
      "(1000, 80)\n",
      "epoch=17, loss=4.379626195598445\n",
      "(1000, 80)\n",
      "epoch=18, loss=4.3794604500590415\n",
      "(1000, 80)\n",
      "epoch=19, loss=4.379294968607241\n",
      "(1000, 80)\n",
      "epoch=20, loss=4.379129750516622\n",
      "(1000, 80)\n",
      "epoch=21, loss=4.3789647950621555\n",
      "(1000, 80)\n",
      "epoch=22, loss=4.378800101520201\n",
      "(1000, 80)\n",
      "epoch=23, loss=4.378635669168497\n",
      "(1000, 80)\n",
      "epoch=24, loss=4.378471497286155\n",
      "(1000, 80)\n",
      "epoch=25, loss=4.378307585153654\n",
      "(1000, 80)\n",
      "epoch=26, loss=4.37814393205283\n",
      "(1000, 80)\n",
      "epoch=27, loss=4.377980537266873\n",
      "(1000, 80)\n",
      "epoch=28, loss=4.377817400080312\n",
      "(1000, 80)\n",
      "epoch=29, loss=4.377654519779025\n",
      "(1000, 80)\n",
      "epoch=30, loss=4.377491895650212\n",
      "(1000, 80)\n",
      "epoch=31, loss=4.3773295269824\n",
      "(1000, 80)\n",
      "epoch=32, loss=4.377167413065435\n",
      "(1000, 80)\n",
      "epoch=33, loss=4.377005553190473\n",
      "(1000, 80)\n",
      "epoch=34, loss=4.376843946649969\n",
      "(1000, 80)\n",
      "epoch=35, loss=4.376682592737682\n",
      "(1000, 80)\n",
      "epoch=36, loss=4.376521490748657\n",
      "(1000, 80)\n",
      "epoch=37, loss=4.3763606399792225\n",
      "(1000, 80)\n",
      "epoch=38, loss=4.376200039726985\n",
      "(1000, 80)\n",
      "epoch=39, loss=4.376039689290818\n",
      "(1000, 80)\n",
      "epoch=40, loss=4.375879587970858\n",
      "(1000, 80)\n",
      "epoch=41, loss=4.3757197350685\n",
      "(1000, 80)\n",
      "epoch=42, loss=4.375560129886388\n",
      "(1000, 80)\n",
      "epoch=43, loss=4.375400771728404\n",
      "(1000, 80)\n",
      "epoch=44, loss=4.3752416598996735\n",
      "(1000, 80)\n",
      "epoch=45, loss=4.375082793706544\n",
      "(1000, 80)\n",
      "epoch=46, loss=4.37492417245659\n",
      "(1000, 80)\n",
      "epoch=47, loss=4.374765795458598\n",
      "(1000, 80)\n",
      "epoch=48, loss=4.3746076620225685\n",
      "(1000, 80)\n",
      "epoch=49, loss=4.374449771459698\n",
      "(1000, 80)\n",
      "epoch=50, loss=4.374292123082385\n",
      "(1000, 80)\n",
      "epoch=51, loss=4.374134716204214\n",
      "(1000, 80)\n",
      "epoch=52, loss=4.373977550139951\n",
      "(1000, 80)\n",
      "epoch=53, loss=4.373820624205542\n",
      "(1000, 80)\n",
      "epoch=54, loss=4.373663937718098\n",
      "(1000, 80)\n",
      "epoch=55, loss=4.373507489995895\n",
      "(1000, 80)\n",
      "epoch=56, loss=4.373351280358364\n",
      "(1000, 80)\n",
      "epoch=57, loss=4.3731953081260855\n",
      "(1000, 80)\n",
      "epoch=58, loss=4.373039572620784\n",
      "(1000, 80)\n",
      "epoch=59, loss=4.372884073165321\n",
      "(1000, 80)\n",
      "epoch=60, loss=4.372728809083687\n",
      "(1000, 80)\n",
      "epoch=61, loss=4.372573779700995\n",
      "(1000, 80)\n",
      "epoch=62, loss=4.3724189843434775\n",
      "(1000, 80)\n",
      "epoch=63, loss=4.372264422338476\n",
      "(1000, 80)\n",
      "epoch=64, loss=4.3721100930144345\n",
      "(1000, 80)\n",
      "epoch=65, loss=4.371955995700897\n",
      "(1000, 80)\n",
      "epoch=66, loss=4.371802129728496\n",
      "(1000, 80)\n",
      "epoch=67, loss=4.371648494428952\n",
      "(1000, 80)\n",
      "epoch=68, loss=4.37149508913506\n",
      "(1000, 80)\n",
      "epoch=69, loss=4.3713419131806885\n",
      "(1000, 80)\n",
      "epoch=70, loss=4.371188965900772\n",
      "(1000, 80)\n",
      "epoch=71, loss=4.371036246631303\n",
      "(1000, 80)\n",
      "epoch=72, loss=4.370883754709325\n",
      "(1000, 80)\n",
      "epoch=73, loss=4.37073148947293\n",
      "(1000, 80)\n",
      "epoch=74, loss=4.370579450261246\n",
      "(1000, 80)\n",
      "epoch=75, loss=4.3704276364144405\n",
      "(1000, 80)\n",
      "epoch=76, loss=4.370276047273703\n",
      "(1000, 80)\n",
      "epoch=77, loss=4.370124682181244\n",
      "(1000, 80)\n",
      "epoch=78, loss=4.369973540480289\n",
      "(1000, 80)\n",
      "epoch=79, loss=4.369822621515072\n",
      "(1000, 80)\n",
      "epoch=80, loss=4.369671924630827\n",
      "(1000, 80)\n",
      "epoch=81, loss=4.369521449173786\n",
      "(1000, 80)\n",
      "epoch=82, loss=4.3693711944911655\n",
      "(1000, 80)\n",
      "epoch=83, loss=4.369221159931168\n",
      "(1000, 80)\n",
      "epoch=84, loss=4.369071344842973\n",
      "(1000, 80)\n",
      "epoch=85, loss=4.368921748576726\n",
      "(1000, 80)\n",
      "epoch=86, loss=4.368772370483538\n",
      "(1000, 80)\n",
      "epoch=87, loss=4.36862320991548\n",
      "(1000, 80)\n",
      "epoch=88, loss=4.368474266225571\n",
      "(1000, 80)\n",
      "epoch=89, loss=4.3683255387677775\n",
      "(1000, 80)\n",
      "epoch=90, loss=4.368177026897001\n",
      "(1000, 80)\n",
      "epoch=91, loss=4.368028729969079\n",
      "(1000, 80)\n",
      "epoch=92, loss=4.367880647340773\n",
      "(1000, 80)\n",
      "epoch=93, loss=4.367732778369765\n",
      "(1000, 80)\n",
      "epoch=94, loss=4.367585122414652\n",
      "(1000, 80)\n",
      "epoch=95, loss=4.3674376788349365\n",
      "(1000, 80)\n",
      "epoch=96, loss=4.3672904469910225\n",
      "(1000, 80)\n",
      "epoch=97, loss=4.367143426244211\n",
      "(1000, 80)\n",
      "epoch=98, loss=4.366996615956689\n",
      "(1000, 80)\n",
      "epoch=99, loss=4.366850015491529\n",
      "(1000, 80)\n",
      "epoch=100, loss=4.366703624212679\n",
      "(1000, 80)\n",
      "epoch=101, loss=4.366557441484955\n",
      "(1000, 80)\n",
      "epoch=102, loss=4.366411466674042\n",
      "(1000, 80)\n",
      "epoch=103, loss=4.366265699146477\n",
      "(1000, 80)\n",
      "epoch=104, loss=4.366120138269655\n",
      "(1000, 80)\n",
      "epoch=105, loss=4.36597478341181\n",
      "(1000, 80)\n",
      "epoch=106, loss=4.365829633942023\n",
      "(1000, 80)\n",
      "epoch=107, loss=4.365684689230202\n",
      "(1000, 80)\n",
      "epoch=108, loss=4.365539948647087\n",
      "(1000, 80)\n",
      "epoch=109, loss=4.365395411564234\n",
      "(1000, 80)\n",
      "epoch=110, loss=4.365251077354018\n",
      "(1000, 80)\n",
      "epoch=111, loss=4.365106945389621\n",
      "(1000, 80)\n",
      "epoch=112, loss=4.3649630150450305\n",
      "(1000, 80)\n",
      "epoch=113, loss=4.364819285695025\n",
      "(1000, 80)\n",
      "epoch=114, loss=4.3646757567151795\n",
      "(1000, 80)\n",
      "epoch=115, loss=4.36453242748185\n",
      "(1000, 80)\n",
      "epoch=116, loss=4.3643892973721705\n",
      "(1000, 80)\n",
      "epoch=117, loss=4.364246365764049\n",
      "(1000, 80)\n",
      "epoch=118, loss=4.3641036320361595\n",
      "(1000, 80)\n",
      "epoch=119, loss=4.363961095567935\n",
      "(1000, 80)\n",
      "epoch=120, loss=4.36381875573956\n",
      "(1000, 80)\n",
      "epoch=121, loss=4.363676611931974\n",
      "(1000, 80)\n",
      "epoch=122, loss=4.363534663526851\n",
      "(1000, 80)\n",
      "epoch=123, loss=4.363392909906604\n",
      "(1000, 80)\n",
      "epoch=124, loss=4.363251350454373\n",
      "(1000, 80)\n",
      "epoch=125, loss=4.363109984554027\n",
      "(1000, 80)\n",
      "epoch=126, loss=4.362968811590148\n",
      "(1000, 80)\n",
      "epoch=127, loss=4.36282783094803\n",
      "(1000, 80)\n",
      "epoch=128, loss=4.362687042013673\n",
      "(1000, 80)\n",
      "epoch=129, loss=4.362546444173775\n",
      "(1000, 80)\n",
      "epoch=130, loss=4.362406036815731\n",
      "(1000, 80)\n",
      "epoch=131, loss=4.362265819327618\n",
      "(1000, 80)\n",
      "epoch=132, loss=4.3621257910981965\n",
      "(1000, 80)\n",
      "epoch=133, loss=4.361985951516906\n",
      "(1000, 80)\n",
      "epoch=134, loss=4.361846299973846\n",
      "(1000, 80)\n",
      "epoch=135, loss=4.361706835859788\n",
      "(1000, 80)\n",
      "epoch=136, loss=4.361567558566156\n",
      "(1000, 80)\n",
      "epoch=137, loss=4.361428467485026\n",
      "(1000, 80)\n",
      "epoch=138, loss=4.361289562009118\n",
      "(1000, 80)\n",
      "epoch=139, loss=4.361150841531791\n",
      "(1000, 80)\n",
      "epoch=140, loss=4.36101230544704\n",
      "(1000, 80)\n",
      "epoch=141, loss=4.360873953149481\n",
      "(1000, 80)\n",
      "epoch=142, loss=4.360735784034356\n",
      "(1000, 80)\n",
      "epoch=143, loss=4.36059779749752\n",
      "(1000, 80)\n",
      "epoch=144, loss=4.360459992935434\n",
      "(1000, 80)\n",
      "epoch=145, loss=4.360322369745167\n",
      "(1000, 80)\n",
      "epoch=146, loss=4.3601849273243785\n",
      "(1000, 80)\n",
      "epoch=147, loss=4.360047665071324\n",
      "(1000, 80)\n",
      "epoch=148, loss=4.359910582384842\n",
      "(1000, 80)\n",
      "epoch=149, loss=4.359773678664349\n",
      "(1000, 80)\n",
      "epoch=150, loss=4.359636953309834\n",
      "(1000, 80)\n",
      "epoch=151, loss=4.359500405721851\n",
      "(1000, 80)\n",
      "epoch=152, loss=4.359364035301518\n",
      "(1000, 80)\n",
      "epoch=153, loss=4.359227841450507\n",
      "(1000, 80)\n",
      "epoch=154, loss=4.359091823571034\n",
      "(1000, 80)\n",
      "epoch=155, loss=4.358955981065863\n",
      "(1000, 80)\n",
      "epoch=156, loss=4.358820313338292\n",
      "(1000, 80)\n",
      "epoch=157, loss=4.358684819792148\n",
      "(1000, 80)\n",
      "epoch=158, loss=4.358549499831785\n",
      "(1000, 80)\n",
      "epoch=159, loss=4.3584143528620745\n",
      "(1000, 80)\n",
      "epoch=160, loss=4.358279378288399\n",
      "(1000, 80)\n",
      "epoch=161, loss=4.35814457551665\n",
      "(1000, 80)\n",
      "epoch=162, loss=4.358009943953216\n",
      "(1000, 80)\n",
      "epoch=163, loss=4.357875483004982\n",
      "(1000, 80)\n",
      "epoch=164, loss=4.35774119207932\n",
      "(1000, 80)\n",
      "epoch=165, loss=4.357607070584087\n",
      "(1000, 80)\n",
      "epoch=166, loss=4.3574731179276105\n",
      "(1000, 80)\n",
      "epoch=167, loss=4.357339333518693\n",
      "(1000, 80)\n",
      "epoch=168, loss=4.357205716766601\n",
      "(1000, 80)\n",
      "epoch=169, loss=4.357072267081055\n",
      "(1000, 80)\n",
      "epoch=170, loss=4.356938983872231\n",
      "(1000, 80)\n",
      "epoch=171, loss=4.356805866550751\n",
      "(1000, 80)\n",
      "epoch=172, loss=4.356672914527673\n",
      "(1000, 80)\n",
      "epoch=173, loss=4.356540127214496\n",
      "(1000, 80)\n",
      "epoch=174, loss=4.356407504023138\n",
      "(1000, 80)\n",
      "epoch=175, loss=4.356275044365945\n",
      "(1000, 80)\n",
      "epoch=176, loss=4.356142747655678\n",
      "(1000, 80)\n",
      "epoch=177, loss=4.356010613305505\n",
      "(1000, 80)\n",
      "epoch=178, loss=4.355878640728999\n",
      "(1000, 80)\n",
      "epoch=179, loss=4.355746829340131\n",
      "(1000, 80)\n",
      "epoch=180, loss=4.355615178553262\n",
      "(1000, 80)\n",
      "epoch=181, loss=4.355483687783138\n",
      "(1000, 80)\n",
      "epoch=182, loss=4.3553523564448895\n",
      "(1000, 80)\n",
      "epoch=183, loss=4.355221183954012\n",
      "(1000, 80)\n",
      "epoch=184, loss=4.355090169726374\n",
      "(1000, 80)\n",
      "epoch=185, loss=4.354959313178204\n",
      "(1000, 80)\n",
      "epoch=186, loss=4.354828613726082\n",
      "(1000, 80)\n",
      "epoch=187, loss=4.354698070786941\n",
      "(1000, 80)\n",
      "epoch=188, loss=4.354567683778054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 80)\n",
      "epoch=189, loss=4.354437452117033\n",
      "(1000, 80)\n",
      "epoch=190, loss=4.354307375221817\n",
      "(1000, 80)\n",
      "epoch=191, loss=4.3541774525106725\n",
      "(1000, 80)\n",
      "epoch=192, loss=4.354047683402183\n",
      "(1000, 80)\n",
      "epoch=193, loss=4.353918067315246\n",
      "(1000, 80)\n",
      "epoch=194, loss=4.3537886036690585\n",
      "(1000, 80)\n",
      "epoch=195, loss=4.353659291883127\n",
      "(1000, 80)\n",
      "epoch=196, loss=4.353530131377243\n",
      "(1000, 80)\n",
      "epoch=197, loss=4.353401121571492\n",
      "(1000, 80)\n",
      "epoch=198, loss=4.353272261886238\n",
      "(1000, 80)\n",
      "epoch=199, loss=4.353143551742117\n",
      "(1000, 80)\n",
      "epoch=200, loss=4.35301499056004\n",
      "(1000, 80)\n",
      "epoch=201, loss=4.352886577761177\n",
      "(1000, 80)\n",
      "epoch=202, loss=4.352758312766958\n",
      "(1000, 80)\n",
      "epoch=203, loss=4.352630194999059\n",
      "(1000, 80)\n",
      "epoch=204, loss=4.352502223879404\n",
      "(1000, 80)\n",
      "epoch=205, loss=4.352374398830154\n",
      "(1000, 80)\n",
      "epoch=206, loss=4.3522467192737\n",
      "(1000, 80)\n",
      "epoch=207, loss=4.352119184632662\n",
      "(1000, 80)\n",
      "epoch=208, loss=4.351991794329879\n",
      "(1000, 80)\n",
      "epoch=209, loss=4.3518645477883995\n",
      "(1000, 80)\n",
      "epoch=210, loss=4.351737444431483\n",
      "(1000, 80)\n",
      "epoch=211, loss=4.351610483682587\n",
      "(1000, 80)\n",
      "epoch=212, loss=4.351483664965366\n",
      "(1000, 80)\n",
      "epoch=213, loss=4.351356987703665\n",
      "(1000, 80)\n",
      "epoch=214, loss=4.3512304513215\n",
      "(1000, 80)\n",
      "epoch=215, loss=4.351104055243075\n",
      "(1000, 80)\n",
      "epoch=216, loss=4.35097779889276\n",
      "(1000, 80)\n",
      "epoch=217, loss=4.350851681695084\n",
      "(1000, 80)\n",
      "epoch=218, loss=4.350725703074737\n",
      "(1000, 80)\n",
      "epoch=219, loss=4.350599862456558\n",
      "(1000, 80)\n",
      "epoch=220, loss=4.350474159265528\n",
      "(1000, 80)\n",
      "epoch=221, loss=4.350348592926772\n",
      "(1000, 80)\n",
      "epoch=222, loss=4.350223162865541\n",
      "(1000, 80)\n",
      "epoch=223, loss=4.350097868507213\n",
      "(1000, 80)\n",
      "epoch=224, loss=4.349972709277282\n",
      "(1000, 80)\n",
      "epoch=225, loss=4.349847684601362\n",
      "(1000, 80)\n",
      "epoch=226, loss=4.349722793905165\n",
      "(1000, 80)\n",
      "epoch=227, loss=4.3495980366145055\n",
      "(1000, 80)\n",
      "epoch=228, loss=4.349473412155294\n",
      "(1000, 80)\n",
      "epoch=229, loss=4.349348919953523\n",
      "(1000, 80)\n",
      "epoch=230, loss=4.34922455943527\n",
      "(1000, 80)\n",
      "epoch=231, loss=4.349100330026682\n",
      "(1000, 80)\n",
      "epoch=232, loss=4.348976231153979\n",
      "(1000, 80)\n",
      "epoch=233, loss=4.348852262243438\n",
      "(1000, 80)\n",
      "epoch=234, loss=4.34872842272139\n",
      "(1000, 80)\n",
      "epoch=235, loss=4.348604712014218\n",
      "(1000, 80)\n",
      "epoch=236, loss=4.348481129548345\n",
      "(1000, 80)\n",
      "epoch=237, loss=4.348357674750227\n",
      "(1000, 80)\n",
      "epoch=238, loss=4.348234347046353\n",
      "(1000, 80)\n",
      "epoch=239, loss=4.34811114586323\n",
      "(1000, 80)\n",
      "epoch=240, loss=4.347988070627383\n",
      "(1000, 80)\n",
      "epoch=241, loss=4.347865120765347\n",
      "(1000, 80)\n",
      "epoch=242, loss=4.347742295703655\n",
      "(1000, 80)\n",
      "epoch=243, loss=4.34761959486884\n",
      "(1000, 80)\n",
      "epoch=244, loss=4.347497017687426\n",
      "(1000, 80)\n",
      "epoch=245, loss=4.347374563585916\n",
      "(1000, 80)\n",
      "epoch=246, loss=4.347252231990789\n",
      "(1000, 80)\n",
      "epoch=247, loss=4.347130022328496\n",
      "(1000, 80)\n",
      "epoch=248, loss=4.347007934025449\n",
      "(1000, 80)\n",
      "epoch=249, loss=4.346885966508018\n",
      "(1000, 80)\n",
      "epoch=250, loss=4.346764119202522\n",
      "(1000, 80)\n",
      "epoch=251, loss=4.346642391535222\n",
      "(1000, 80)\n",
      "epoch=252, loss=4.346520782932317\n",
      "(1000, 80)\n",
      "epoch=253, loss=4.3463992928199335\n",
      "(1000, 80)\n",
      "epoch=254, loss=4.3462779206241215\n",
      "(1000, 80)\n",
      "epoch=255, loss=4.346156665770848\n",
      "(1000, 80)\n",
      "epoch=256, loss=4.346035527685987\n",
      "(1000, 80)\n",
      "epoch=257, loss=4.34591450579532\n",
      "(1000, 80)\n",
      "epoch=258, loss=4.345793599524517\n",
      "(1000, 80)\n",
      "epoch=259, loss=4.3456728082991445\n",
      "(1000, 80)\n",
      "epoch=260, loss=4.345552131544645\n",
      "(1000, 80)\n",
      "epoch=261, loss=4.345431568686339\n",
      "(1000, 80)\n",
      "epoch=262, loss=4.345311119149417\n",
      "(1000, 80)\n",
      "epoch=263, loss=4.345190782358929\n",
      "(1000, 80)\n",
      "epoch=264, loss=4.34507055773978\n",
      "(1000, 80)\n",
      "epoch=265, loss=4.344950444716722\n",
      "(1000, 80)\n",
      "epoch=266, loss=4.3448304427143505\n",
      "(1000, 80)\n",
      "epoch=267, loss=4.344710551157092\n",
      "(1000, 80)\n",
      "epoch=268, loss=4.344590769469203\n",
      "(1000, 80)\n",
      "epoch=269, loss=4.344471097074758\n",
      "(1000, 80)\n",
      "epoch=270, loss=4.344351533397647\n",
      "(1000, 80)\n",
      "epoch=271, loss=4.344232077861561\n",
      "(1000, 80)\n",
      "epoch=272, loss=4.3441127298899955\n",
      "(1000, 80)\n",
      "epoch=273, loss=4.3439934889062375\n",
      "(1000, 80)\n",
      "epoch=274, loss=4.343874354333357\n",
      "(1000, 80)\n",
      "epoch=275, loss=4.3437553255942\n",
      "(1000, 80)\n",
      "epoch=276, loss=4.34363640211139\n",
      "(1000, 80)\n",
      "epoch=277, loss=4.343517583307306\n",
      "(1000, 80)\n",
      "epoch=278, loss=4.343398868604091\n",
      "(1000, 80)\n",
      "epoch=279, loss=4.3432802574236336\n",
      "(1000, 80)\n",
      "epoch=280, loss=4.343161749187566\n",
      "(1000, 80)\n",
      "epoch=281, loss=4.343043343317253\n",
      "(1000, 80)\n",
      "epoch=282, loss=4.342925039233792\n",
      "(1000, 80)\n",
      "epoch=283, loss=4.342806836357997\n",
      "(1000, 80)\n",
      "epoch=284, loss=4.342688734110396\n",
      "(1000, 80)\n",
      "epoch=285, loss=4.342570731911226\n",
      "(1000, 80)\n",
      "epoch=286, loss=4.342452829180421\n",
      "(1000, 80)\n",
      "epoch=287, loss=4.342335025337605\n",
      "(1000, 80)\n",
      "epoch=288, loss=4.342217319802089\n",
      "(1000, 80)\n",
      "epoch=289, loss=4.342099711992858\n",
      "(1000, 80)\n",
      "epoch=290, loss=4.341982201328572\n",
      "(1000, 80)\n",
      "epoch=291, loss=4.341864787227545\n",
      "(1000, 80)\n",
      "epoch=292, loss=4.341747469107755\n",
      "(1000, 80)\n",
      "epoch=293, loss=4.341630246386819\n",
      "(1000, 80)\n",
      "epoch=294, loss=4.3415131184819975\n",
      "(1000, 80)\n",
      "epoch=295, loss=4.341396084810185\n",
      "(1000, 80)\n",
      "epoch=296, loss=4.341279144787898\n",
      "(1000, 80)\n",
      "epoch=297, loss=4.341162297831271\n",
      "(1000, 80)\n",
      "epoch=298, loss=4.341045543356049\n",
      "(1000, 80)\n",
      "epoch=299, loss=4.3409288807775805\n",
      "(1000, 80)\n",
      "epoch=300, loss=4.340812309510804\n",
      "(1000, 80)\n",
      "epoch=301, loss=4.34069582897025\n",
      "(1000, 80)\n",
      "epoch=302, loss=4.340579438570025\n",
      "(1000, 80)\n",
      "epoch=303, loss=4.340463137723809\n",
      "(1000, 80)\n",
      "epoch=304, loss=4.340346925844844\n",
      "(1000, 80)\n",
      "epoch=305, loss=4.340230802345933\n",
      "(1000, 80)\n",
      "epoch=306, loss=4.340114766639419\n",
      "(1000, 80)\n",
      "epoch=307, loss=4.339998818137196\n",
      "(1000, 80)\n",
      "epoch=308, loss=4.33988295625068\n",
      "(1000, 80)\n",
      "epoch=309, loss=4.339767180390822\n",
      "(1000, 80)\n",
      "epoch=310, loss=4.339651489968084\n",
      "(1000, 80)\n",
      "epoch=311, loss=4.339535884392441\n",
      "(1000, 80)\n",
      "epoch=312, loss=4.339420363073365\n",
      "(1000, 80)\n",
      "epoch=313, loss=4.3393049254198255\n",
      "(1000, 80)\n",
      "epoch=314, loss=4.3391895708402775\n",
      "(1000, 80)\n",
      "epoch=315, loss=4.339074298742651\n",
      "(1000, 80)\n",
      "epoch=316, loss=4.338959108534347\n",
      "(1000, 80)\n",
      "epoch=317, loss=4.338843999622227\n",
      "(1000, 80)\n",
      "epoch=318, loss=4.3387289714126105\n",
      "(1000, 80)\n",
      "epoch=319, loss=4.338614023311256\n",
      "(1000, 80)\n",
      "epoch=320, loss=4.338499154723362\n",
      "(1000, 80)\n",
      "epoch=321, loss=4.338384365053557\n",
      "(1000, 80)\n",
      "epoch=322, loss=4.338269653705889\n",
      "(1000, 80)\n",
      "epoch=323, loss=4.3381550200838195\n",
      "(1000, 80)\n",
      "epoch=324, loss=4.338040463590215\n",
      "(1000, 80)\n",
      "epoch=325, loss=4.3379259836273345\n",
      "(1000, 80)\n",
      "epoch=326, loss=4.337811579596831\n",
      "(1000, 80)\n",
      "epoch=327, loss=4.337697250899732\n",
      "(1000, 80)\n",
      "epoch=328, loss=4.337582996936438\n",
      "(1000, 80)\n",
      "epoch=329, loss=4.337468817106713\n",
      "(1000, 80)\n",
      "epoch=330, loss=4.3373547108096755\n",
      "(1000, 80)\n",
      "epoch=331, loss=4.337240677443788\n",
      "(1000, 80)\n",
      "epoch=332, loss=4.337126716406849\n",
      "(1000, 80)\n",
      "epoch=333, loss=4.337012827095992\n",
      "(1000, 80)\n",
      "epoch=334, loss=4.336899008907666\n",
      "(1000, 80)\n",
      "epoch=335, loss=4.336785261237633\n",
      "(1000, 80)\n",
      "epoch=336, loss=4.336671583480958\n",
      "(1000, 80)\n",
      "epoch=337, loss=4.336557975031999\n",
      "(1000, 80)\n",
      "epoch=338, loss=4.336444435284405\n",
      "(1000, 80)\n",
      "epoch=339, loss=4.336330963631097\n",
      "(1000, 80)\n",
      "epoch=340, loss=4.336217559464264\n",
      "(1000, 80)\n",
      "epoch=341, loss=4.336104222175359\n",
      "(1000, 80)\n",
      "epoch=342, loss=4.3359909511550825\n",
      "(1000, 80)\n",
      "epoch=343, loss=4.335877745793376\n",
      "(1000, 80)\n",
      "epoch=344, loss=4.335764605479419\n",
      "(1000, 80)\n",
      "epoch=345, loss=4.335651529601608\n",
      "(1000, 80)\n",
      "epoch=346, loss=4.335538517547562\n",
      "(1000, 80)\n",
      "epoch=347, loss=4.335425568704101\n",
      "(1000, 80)\n",
      "epoch=348, loss=4.335312682457241\n",
      "(1000, 80)\n",
      "epoch=349, loss=4.3351998581921904\n",
      "(1000, 80)\n",
      "epoch=350, loss=4.335087095293338\n",
      "(1000, 80)\n",
      "epoch=351, loss=4.334974393144235\n",
      "(1000, 80)\n",
      "epoch=352, loss=4.334861751127598\n",
      "(1000, 80)\n",
      "epoch=353, loss=4.334749168625296\n",
      "(1000, 80)\n",
      "epoch=354, loss=4.334636645018337\n",
      "(1000, 80)\n",
      "epoch=355, loss=4.334524179686863\n",
      "(1000, 80)\n",
      "epoch=356, loss=4.3344117720101405\n",
      "(1000, 80)\n",
      "epoch=357, loss=4.334299421366549\n",
      "(1000, 80)\n",
      "epoch=358, loss=4.334187127133575\n",
      "(1000, 80)\n",
      "epoch=359, loss=4.334074888687796\n",
      "(1000, 80)\n",
      "epoch=360, loss=4.333962705404878\n",
      "(1000, 80)\n",
      "epoch=361, loss=4.3338505766595645\n",
      "(1000, 80)\n",
      "epoch=362, loss=4.333738501825663\n",
      "(1000, 80)\n",
      "epoch=363, loss=4.33362648027604\n",
      "(1000, 80)\n",
      "epoch=364, loss=4.3335145113826075\n",
      "(1000, 80)\n",
      "epoch=365, loss=4.333402594516317\n",
      "(1000, 80)\n",
      "epoch=366, loss=4.333290729047148\n",
      "(1000, 80)\n",
      "epoch=367, loss=4.333178914344097\n",
      "(1000, 80)\n",
      "epoch=368, loss=4.33306714977517\n",
      "(1000, 80)\n",
      "epoch=369, loss=4.332955434707371\n",
      "(1000, 80)\n",
      "epoch=370, loss=4.332843768506692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 80)\n",
      "epoch=371, loss=4.332732150538105\n",
      "(1000, 80)\n",
      "epoch=372, loss=4.332620580165551\n",
      "(1000, 80)\n",
      "epoch=373, loss=4.332509056751928\n",
      "(1000, 80)\n",
      "epoch=374, loss=4.332397579659083\n",
      "(1000, 80)\n",
      "epoch=375, loss=4.332286148247803\n",
      "(1000, 80)\n",
      "epoch=376, loss=4.332174761877802\n",
      "(1000, 80)\n",
      "epoch=377, loss=4.33206341990771\n",
      "(1000, 80)\n",
      "epoch=378, loss=4.331952121695071\n",
      "(1000, 80)\n",
      "epoch=379, loss=4.33184086659632\n",
      "(1000, 80)\n",
      "epoch=380, loss=4.331729653966782\n",
      "(1000, 80)\n",
      "epoch=381, loss=4.331618483160661\n",
      "(1000, 80)\n",
      "epoch=382, loss=4.331507353531021\n",
      "(1000, 80)\n",
      "epoch=383, loss=4.331396264429787\n",
      "(1000, 80)\n",
      "epoch=384, loss=4.331285215207728\n",
      "(1000, 80)\n",
      "epoch=385, loss=4.331174205214451\n",
      "(1000, 80)\n",
      "epoch=386, loss=4.331063233798379\n",
      "(1000, 80)\n",
      "epoch=387, loss=4.330952300306756\n",
      "(1000, 80)\n",
      "epoch=388, loss=4.330841404085624\n",
      "(1000, 80)\n",
      "epoch=389, loss=4.33073054447982\n",
      "(1000, 80)\n",
      "epoch=390, loss=4.330619720832959\n",
      "(1000, 80)\n",
      "epoch=391, loss=4.33050893248743\n",
      "(1000, 80)\n",
      "epoch=392, loss=4.330398178784379\n",
      "(1000, 80)\n",
      "epoch=393, loss=4.330287459063697\n",
      "(1000, 80)\n",
      "epoch=394, loss=4.330176772664017\n",
      "(1000, 80)\n",
      "epoch=395, loss=4.330066118922698\n",
      "(1000, 80)\n",
      "epoch=396, loss=4.32995549717581\n",
      "(1000, 80)\n",
      "epoch=397, loss=4.3298449067581295\n",
      "(1000, 80)\n",
      "epoch=398, loss=4.329734347003127\n",
      "(1000, 80)\n",
      "epoch=399, loss=4.32962381724295\n",
      "(1000, 80)\n",
      "epoch=400, loss=4.329513316808419\n",
      "(1000, 80)\n",
      "epoch=401, loss=4.329402845029014\n",
      "(1000, 80)\n",
      "epoch=402, loss=4.329292401232855\n",
      "(1000, 80)\n",
      "epoch=403, loss=4.329181984746707\n",
      "(1000, 80)\n",
      "epoch=404, loss=4.329071594895953\n",
      "(1000, 80)\n",
      "epoch=405, loss=4.328961231004588\n",
      "(1000, 80)\n",
      "epoch=406, loss=4.328850892395212\n",
      "(1000, 80)\n",
      "epoch=407, loss=4.32874057838901\n",
      "(1000, 80)\n",
      "epoch=408, loss=4.328630288305743\n",
      "(1000, 80)\n",
      "epoch=409, loss=4.328520021463742\n",
      "(1000, 80)\n",
      "epoch=410, loss=4.3284097771798855\n",
      "(1000, 80)\n",
      "epoch=411, loss=4.328299554769599\n",
      "(1000, 80)\n",
      "epoch=412, loss=4.328189353546832\n",
      "(1000, 80)\n",
      "epoch=413, loss=4.328079172824054\n",
      "(1000, 80)\n",
      "epoch=414, loss=4.327969011912243\n",
      "(1000, 80)\n",
      "epoch=415, loss=4.327858870120862\n",
      "(1000, 80)\n",
      "epoch=416, loss=4.32774874675786\n",
      "(1000, 80)\n",
      "epoch=417, loss=4.327638641129651\n",
      "(1000, 80)\n",
      "epoch=418, loss=4.327528552541109\n",
      "(1000, 80)\n",
      "epoch=419, loss=4.327418480295548\n",
      "(1000, 80)\n",
      "epoch=420, loss=4.327308423694714\n",
      "(1000, 80)\n",
      "epoch=421, loss=4.327198382038771\n",
      "(1000, 80)\n",
      "epoch=422, loss=4.32708835462629\n",
      "(1000, 80)\n",
      "epoch=423, loss=4.326978340754232\n",
      "(1000, 80)\n",
      "epoch=424, loss=4.326868339717944\n",
      "(1000, 80)\n",
      "epoch=425, loss=4.326758350811133\n",
      "(1000, 80)\n",
      "epoch=426, loss=4.326648373325865\n",
      "(1000, 80)\n",
      "epoch=427, loss=4.326538406552546\n",
      "(1000, 80)\n",
      "epoch=428, loss=4.326428449779913\n",
      "(1000, 80)\n",
      "epoch=429, loss=4.326318502295015\n",
      "(1000, 80)\n",
      "epoch=430, loss=4.326208563383207\n",
      "(1000, 80)\n",
      "epoch=431, loss=4.32609863232813\n",
      "(1000, 80)\n",
      "epoch=432, loss=4.325988708411701\n",
      "(1000, 80)\n",
      "epoch=433, loss=4.3258787909141025\n",
      "(1000, 80)\n",
      "epoch=434, loss=4.325768879113763\n",
      "(1000, 80)\n",
      "epoch=435, loss=4.325658972287349\n",
      "(1000, 80)\n",
      "epoch=436, loss=4.325549069709747\n",
      "(1000, 80)\n",
      "epoch=437, loss=4.32543917065405\n",
      "(1000, 80)\n",
      "epoch=438, loss=4.325329274391554\n",
      "(1000, 80)\n",
      "epoch=439, loss=4.325219380191724\n",
      "(1000, 80)\n",
      "epoch=440, loss=4.3251094873222025\n",
      "(1000, 80)\n",
      "epoch=441, loss=4.324999595048782\n",
      "(1000, 80)\n",
      "epoch=442, loss=4.324889702635391\n",
      "(1000, 80)\n",
      "epoch=443, loss=4.324779809344087\n",
      "(1000, 80)\n",
      "epoch=444, loss=4.324669914435037\n",
      "(1000, 80)\n",
      "epoch=445, loss=4.324560017166506\n",
      "(1000, 80)\n",
      "epoch=446, loss=4.324450116794842\n",
      "(1000, 80)\n",
      "epoch=447, loss=4.324340212574458\n",
      "(1000, 80)\n",
      "epoch=448, loss=4.324230303757826\n",
      "(1000, 80)\n",
      "epoch=449, loss=4.324120389595452\n",
      "(1000, 80)\n",
      "epoch=450, loss=4.324010469335872\n",
      "(1000, 80)\n",
      "epoch=451, loss=4.32390054222563\n",
      "(1000, 80)\n",
      "epoch=452, loss=4.323790607509265\n",
      "(1000, 80)\n",
      "epoch=453, loss=4.323680664429298\n",
      "(1000, 80)\n",
      "epoch=454, loss=4.323570712226216\n",
      "(1000, 80)\n",
      "epoch=455, loss=4.323460750138454\n",
      "(1000, 80)\n",
      "epoch=456, loss=4.323350777402389\n",
      "(1000, 80)\n",
      "epoch=457, loss=4.323240793252314\n",
      "(1000, 80)\n",
      "epoch=458, loss=4.323130796920428\n",
      "(1000, 80)\n",
      "epoch=459, loss=4.323020787636824\n",
      "(1000, 80)\n",
      "epoch=460, loss=4.322910764629465\n",
      "(1000, 80)\n",
      "epoch=461, loss=4.32280072712418\n",
      "(1000, 80)\n",
      "epoch=462, loss=4.322690674344638\n",
      "(1000, 80)\n",
      "epoch=463, loss=4.3225806055123375\n",
      "(1000, 80)\n",
      "epoch=464, loss=4.322470519846591\n",
      "(1000, 80)\n",
      "epoch=465, loss=4.322360416564507\n",
      "(1000, 80)\n",
      "epoch=466, loss=4.322250294880978\n",
      "(1000, 80)\n",
      "epoch=467, loss=4.322140154008658\n",
      "(1000, 80)\n",
      "epoch=468, loss=4.3220299931579556\n",
      "(1000, 80)\n",
      "epoch=469, loss=4.32191981153701\n",
      "(1000, 80)\n",
      "epoch=470, loss=4.321809608351679\n",
      "(1000, 80)\n",
      "epoch=471, loss=4.321699382805522\n",
      "(1000, 80)\n",
      "epoch=472, loss=4.321589134099782\n",
      "(1000, 80)\n",
      "epoch=473, loss=4.321478861433372\n",
      "(1000, 80)\n",
      "epoch=474, loss=4.321368564002856\n",
      "(1000, 80)\n",
      "epoch=475, loss=4.321258241002435\n",
      "(1000, 80)\n",
      "epoch=476, loss=4.3211478916239265\n",
      "(1000, 80)\n",
      "epoch=477, loss=4.321037515056756\n",
      "(1000, 80)\n",
      "epoch=478, loss=4.320927110487925\n",
      "(1000, 80)\n",
      "epoch=479, loss=4.320816677102012\n",
      "(1000, 80)\n",
      "epoch=480, loss=4.320706214081142\n",
      "(1000, 80)\n",
      "epoch=481, loss=4.320595720604976\n",
      "(1000, 80)\n",
      "epoch=482, loss=4.320485195850692\n",
      "(1000, 80)\n",
      "epoch=483, loss=4.320374638992971\n",
      "(1000, 80)\n",
      "epoch=484, loss=4.320264049203969\n",
      "(1000, 80)\n",
      "epoch=485, loss=4.320153425653315\n",
      "(1000, 80)\n",
      "epoch=486, loss=4.320042767508081\n",
      "(1000, 80)\n",
      "epoch=487, loss=4.319932073932771\n",
      "(1000, 80)\n",
      "epoch=488, loss=4.319821344089299\n",
      "(1000, 80)\n",
      "epoch=489, loss=4.319710577136977\n",
      "(1000, 80)\n",
      "epoch=490, loss=4.319599772232491\n",
      "(1000, 80)\n",
      "epoch=491, loss=4.319488928529883\n",
      "(1000, 80)\n",
      "epoch=492, loss=4.319378045180543\n",
      "(1000, 80)\n",
      "epoch=493, loss=4.319267121333175\n",
      "(1000, 80)\n",
      "epoch=494, loss=4.319156156133792\n",
      "(1000, 80)\n",
      "epoch=495, loss=4.3190451487256905\n",
      "(1000, 80)\n",
      "epoch=496, loss=4.318934098249434\n",
      "(1000, 80)\n",
      "epoch=497, loss=4.318823003842837\n",
      "(1000, 80)\n",
      "epoch=498, loss=4.3187118646409415\n",
      "(1000, 80)\n",
      "epoch=499, loss=4.318600679776\n",
      "(1000, 80)\n",
      "epoch=500, loss=4.318489448377459\n",
      "(1000, 80)\n",
      "epoch=501, loss=4.318378169571939\n",
      "(1000, 80)\n",
      "epoch=502, loss=4.318266842483212\n",
      "(1000, 80)\n",
      "epoch=503, loss=4.318155466232186\n",
      "(1000, 80)\n",
      "epoch=504, loss=4.318044039936886\n",
      "(1000, 80)\n",
      "epoch=505, loss=4.317932562712435\n",
      "(1000, 80)\n",
      "epoch=506, loss=4.317821033671027\n",
      "(1000, 80)\n",
      "epoch=507, loss=4.317709451921919\n",
      "(1000, 80)\n",
      "epoch=508, loss=4.317597816571404\n",
      "(1000, 80)\n",
      "epoch=509, loss=4.3174861267227955\n",
      "(1000, 80)\n",
      "epoch=510, loss=4.317374381476399\n",
      "(1000, 80)\n",
      "epoch=511, loss=4.317262579929506\n",
      "(1000, 80)\n",
      "epoch=512, loss=4.31715072117636\n",
      "(1000, 80)\n",
      "epoch=513, loss=4.317038804308146\n",
      "(1000, 80)\n",
      "epoch=514, loss=4.3169268284129645\n",
      "(1000, 80)\n",
      "epoch=515, loss=4.3168147925758165\n",
      "(1000, 80)\n",
      "epoch=516, loss=4.316702695878577\n",
      "(1000, 80)\n",
      "epoch=517, loss=4.316590537399981\n",
      "(1000, 80)\n",
      "epoch=518, loss=4.316478316215593\n",
      "(1000, 80)\n",
      "epoch=519, loss=4.316366031397799\n",
      "(1000, 80)\n",
      "epoch=520, loss=4.316253682015777\n",
      "(1000, 80)\n",
      "epoch=521, loss=4.316141267135474\n",
      "(1000, 80)\n",
      "epoch=522, loss=4.3160287858195945\n",
      "(1000, 80)\n",
      "epoch=523, loss=4.3159162371275706\n",
      "(1000, 80)\n",
      "epoch=524, loss=4.315803620115546\n",
      "(1000, 80)\n",
      "epoch=525, loss=4.315690933836351\n",
      "(1000, 80)\n",
      "epoch=526, loss=4.315578177339482\n",
      "(1000, 80)\n",
      "epoch=527, loss=4.315465349671082\n",
      "(1000, 80)\n",
      "epoch=528, loss=4.315352449873913\n",
      "(1000, 80)\n",
      "epoch=529, loss=4.315239476987346\n",
      "(1000, 80)\n",
      "epoch=530, loss=4.315126430047322\n",
      "(1000, 80)\n",
      "epoch=531, loss=4.315013308086347\n",
      "(1000, 80)\n",
      "epoch=532, loss=4.314900110133458\n",
      "(1000, 80)\n",
      "epoch=533, loss=4.314786835214205\n",
      "(1000, 80)\n",
      "epoch=534, loss=4.3146734823506305\n",
      "(1000, 80)\n",
      "epoch=535, loss=4.3145600505612425\n",
      "(1000, 80)\n",
      "epoch=536, loss=4.314446538860997\n",
      "(1000, 80)\n",
      "epoch=537, loss=4.314332946261267\n",
      "(1000, 80)\n",
      "epoch=538, loss=4.314219271769835\n",
      "(1000, 80)\n",
      "epoch=539, loss=4.3141055143908495\n",
      "(1000, 80)\n",
      "epoch=540, loss=4.313991673124821\n",
      "(1000, 80)\n",
      "epoch=541, loss=4.3138777469685845\n",
      "(1000, 80)\n",
      "epoch=542, loss=4.313763734915288\n",
      "(1000, 80)\n",
      "epoch=543, loss=4.3136496359543575\n",
      "(1000, 80)\n",
      "epoch=544, loss=4.313535449071484\n",
      "(1000, 80)\n",
      "epoch=545, loss=4.313421173248594\n",
      "(1000, 80)\n",
      "epoch=546, loss=4.313306807463825\n",
      "(1000, 80)\n",
      "epoch=547, loss=4.313192350691508\n",
      "(1000, 80)\n",
      "epoch=548, loss=4.3130778019021365\n",
      "(1000, 80)\n",
      "epoch=549, loss=4.312963160062342\n",
      "(1000, 80)\n",
      "epoch=550, loss=4.312848424134879\n",
      "(1000, 80)\n",
      "epoch=551, loss=4.312733593078592\n",
      "(1000, 80)\n",
      "epoch=552, loss=4.312618665848395\n",
      "(1000, 80)\n",
      "epoch=553, loss=4.312503641395242\n",
      "(1000, 80)\n",
      "epoch=554, loss=4.312388518666113\n",
      "(1000, 80)\n",
      "epoch=555, loss=4.3122732966039745\n",
      "(1000, 80)\n",
      "epoch=556, loss=4.3121579741477705\n",
      "(1000, 80)\n",
      "epoch=557, loss=4.312042550232381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 80)\n",
      "epoch=558, loss=4.311927023788615\n",
      "(1000, 80)\n",
      "epoch=559, loss=4.31181139374317\n",
      "(1000, 80)\n",
      "epoch=560, loss=4.311695659018611\n",
      "(1000, 80)\n",
      "epoch=561, loss=4.311579818533352\n",
      "(1000, 80)\n",
      "epoch=562, loss=4.311463871201621\n",
      "(1000, 80)\n",
      "epoch=563, loss=4.311347815933442\n",
      "(1000, 80)\n",
      "epoch=564, loss=4.3112316516346\n",
      "(1000, 80)\n",
      "epoch=565, loss=4.311115377206627\n",
      "(1000, 80)\n",
      "epoch=566, loss=4.310998991546767\n",
      "(1000, 80)\n",
      "epoch=567, loss=4.3108824935479495\n",
      "(1000, 80)\n",
      "epoch=568, loss=4.310765882098774\n",
      "(1000, 80)\n",
      "epoch=569, loss=4.31064915608347\n",
      "(1000, 80)\n",
      "epoch=570, loss=4.31053231438188\n",
      "(1000, 80)\n",
      "epoch=571, loss=4.310415355869425\n",
      "(1000, 80)\n",
      "epoch=572, loss=4.310298279417089\n",
      "(1000, 80)\n",
      "epoch=573, loss=4.310181083891383\n",
      "(1000, 80)\n",
      "epoch=574, loss=4.3100637681543175\n",
      "(1000, 80)\n",
      "epoch=575, loss=4.309946331063384\n",
      "(1000, 80)\n",
      "epoch=576, loss=4.309828771471519\n",
      "(1000, 80)\n",
      "epoch=577, loss=4.309711088227081\n",
      "(1000, 80)\n",
      "epoch=578, loss=4.309593280173827\n",
      "(1000, 80)\n",
      "epoch=579, loss=4.309475346150873\n",
      "(1000, 80)\n",
      "epoch=580, loss=4.309357284992683\n",
      "(1000, 80)\n",
      "epoch=581, loss=4.3092390955290245\n",
      "(1000, 80)\n",
      "epoch=582, loss=4.309120776584954\n",
      "(1000, 80)\n",
      "epoch=583, loss=4.309002326980779\n",
      "(1000, 80)\n",
      "epoch=584, loss=4.308883745532041\n",
      "(1000, 80)\n",
      "epoch=585, loss=4.308765031049476\n",
      "(1000, 80)\n",
      "epoch=586, loss=4.308646182338995\n",
      "(1000, 80)\n",
      "epoch=587, loss=4.308527198201649\n",
      "(1000, 80)\n",
      "epoch=588, loss=4.308408077433606\n",
      "(1000, 80)\n",
      "epoch=589, loss=4.30828881882612\n",
      "(1000, 80)\n",
      "epoch=590, loss=4.308169421165503\n",
      "(1000, 80)\n",
      "epoch=591, loss=4.3080498832330925\n",
      "(1000, 80)\n",
      "epoch=592, loss=4.307930203805231\n",
      "(1000, 80)\n",
      "epoch=593, loss=4.307810381653229\n",
      "(1000, 80)\n",
      "epoch=594, loss=4.30769041554334\n",
      "(1000, 80)\n",
      "epoch=595, loss=4.307570304236729\n",
      "(1000, 80)\n",
      "epoch=596, loss=4.307450046489448\n",
      "(1000, 80)\n",
      "epoch=597, loss=4.307329641052398\n",
      "(1000, 80)\n",
      "epoch=598, loss=4.3072090866713095\n",
      "(1000, 80)\n",
      "epoch=599, loss=4.307088382086706\n",
      "(1000, 80)\n",
      "epoch=600, loss=4.306967526033875\n",
      "(1000, 80)\n",
      "epoch=601, loss=4.306846517242845\n",
      "(1000, 80)\n",
      "epoch=602, loss=4.3067253544383455\n",
      "(1000, 80)\n",
      "epoch=603, loss=4.306604036339784\n",
      "(1000, 80)\n",
      "epoch=604, loss=4.306482561661213\n",
      "(1000, 80)\n",
      "epoch=605, loss=4.3063609291113005\n",
      "(1000, 80)\n",
      "epoch=606, loss=4.3062391373933036\n",
      "(1000, 80)\n",
      "epoch=607, loss=4.30611718520503\n",
      "(1000, 80)\n",
      "epoch=608, loss=4.305995071238815\n",
      "(1000, 80)\n",
      "epoch=609, loss=4.3058727941814885\n",
      "(1000, 80)\n",
      "epoch=610, loss=4.305750352714343\n",
      "(1000, 80)\n",
      "epoch=611, loss=4.305627745513102\n",
      "(1000, 80)\n",
      "epoch=612, loss=4.3055049712478946\n",
      "(1000, 80)\n",
      "epoch=613, loss=4.305382028583223\n",
      "(1000, 80)\n",
      "epoch=614, loss=4.305258916177923\n",
      "(1000, 80)\n",
      "epoch=615, loss=4.305135632685148\n",
      "(1000, 80)\n",
      "epoch=616, loss=4.305012176752322\n",
      "(1000, 80)\n",
      "epoch=617, loss=4.304888547021123\n",
      "(1000, 80)\n",
      "epoch=618, loss=4.304764742127441\n",
      "(1000, 80)\n",
      "epoch=619, loss=4.304640760701351\n",
      "(1000, 80)\n",
      "epoch=620, loss=4.304516601367083\n",
      "(1000, 80)\n",
      "epoch=621, loss=4.304392262742987\n",
      "(1000, 80)\n",
      "epoch=622, loss=4.304267743441505\n",
      "(1000, 80)\n",
      "epoch=623, loss=4.304143042069134\n",
      "(1000, 80)\n",
      "epoch=624, loss=4.304018157226403\n",
      "(1000, 80)\n",
      "epoch=625, loss=4.30389308750783\n",
      "(1000, 80)\n",
      "epoch=626, loss=4.303767831501902\n",
      "(1000, 80)\n",
      "epoch=627, loss=4.303642387791033\n",
      "(1000, 80)\n",
      "epoch=628, loss=4.30351675495154\n",
      "(1000, 80)\n",
      "epoch=629, loss=4.303390931553604\n",
      "(1000, 80)\n",
      "epoch=630, loss=4.303264916161244\n",
      "(1000, 80)\n",
      "epoch=631, loss=4.303138707332281\n",
      "(1000, 80)\n",
      "epoch=632, loss=4.303012303618308\n",
      "(1000, 80)\n",
      "epoch=633, loss=4.302885703564654\n",
      "(1000, 80)\n",
      "epoch=634, loss=4.302758905710359\n",
      "(1000, 80)\n",
      "epoch=635, loss=4.302631908588132\n",
      "(1000, 80)\n",
      "epoch=636, loss=4.302504710724327\n",
      "(1000, 80)\n",
      "epoch=637, loss=4.302377310638909\n",
      "(1000, 80)\n",
      "epoch=638, loss=4.302249706845416\n",
      "(1000, 80)\n",
      "epoch=639, loss=4.302121897850933\n",
      "(1000, 80)\n",
      "epoch=640, loss=4.301993882156056\n",
      "(1000, 80)\n",
      "epoch=641, loss=4.30186565825486\n",
      "(1000, 80)\n",
      "epoch=642, loss=4.301737224634868\n",
      "(1000, 80)\n",
      "epoch=643, loss=4.301608579777016\n",
      "(1000, 80)\n",
      "epoch=644, loss=4.301479722155621\n",
      "(1000, 80)\n",
      "epoch=645, loss=4.301350650238351\n",
      "(1000, 80)\n",
      "epoch=646, loss=4.301221362486187\n",
      "(1000, 80)\n",
      "epoch=647, loss=4.3010918573533985\n",
      "(1000, 80)\n",
      "epoch=648, loss=4.300962133287498\n",
      "(1000, 80)\n",
      "epoch=649, loss=4.300832188729224\n",
      "(1000, 80)\n",
      "epoch=650, loss=4.300702022112493\n",
      "(1000, 80)\n",
      "epoch=651, loss=4.300571631864381\n",
      "(1000, 80)\n",
      "epoch=652, loss=4.300441016405077\n",
      "(1000, 80)\n",
      "epoch=653, loss=4.300310174147861\n",
      "(1000, 80)\n",
      "epoch=654, loss=4.300179103499067\n",
      "(1000, 80)\n",
      "epoch=655, loss=4.300047802858052\n",
      "(1000, 80)\n",
      "epoch=656, loss=4.299916270617154\n",
      "(1000, 80)\n",
      "epoch=657, loss=4.299784505161677\n",
      "(1000, 80)\n",
      "epoch=658, loss=4.29965250486984\n",
      "(1000, 80)\n",
      "epoch=659, loss=4.299520268112762\n",
      "(1000, 80)\n",
      "epoch=660, loss=4.299387793254407\n",
      "(1000, 80)\n",
      "epoch=661, loss=4.299255078651579\n",
      "(1000, 80)\n",
      "epoch=662, loss=4.299122122653864\n",
      "(1000, 80)\n",
      "epoch=663, loss=4.298988923603611\n",
      "(1000, 80)\n",
      "epoch=664, loss=4.298855479835899\n",
      "(1000, 80)\n",
      "epoch=665, loss=4.298721789678501\n",
      "(1000, 80)\n",
      "epoch=666, loss=4.298587851451852\n",
      "(1000, 80)\n",
      "epoch=667, loss=4.298453663469017\n",
      "(1000, 80)\n",
      "epoch=668, loss=4.298319224035661\n",
      "(1000, 80)\n",
      "epoch=669, loss=4.298184531450014\n",
      "(1000, 80)\n",
      "epoch=670, loss=4.29804958400284\n",
      "(1000, 80)\n",
      "epoch=671, loss=4.297914379977402\n",
      "(1000, 80)\n",
      "epoch=672, loss=4.2977789176494365\n",
      "(1000, 80)\n",
      "epoch=673, loss=4.297643195287115\n",
      "(1000, 80)\n",
      "epoch=674, loss=4.2975072111510135\n",
      "(1000, 80)\n",
      "epoch=675, loss=4.297370963494084\n",
      "(1000, 80)\n",
      "epoch=676, loss=4.297234450561622\n",
      "(1000, 80)\n",
      "epoch=677, loss=4.297097670591227\n",
      "(1000, 80)\n",
      "epoch=678, loss=4.296960621812785\n",
      "(1000, 80)\n",
      "epoch=679, loss=4.296823302448424\n",
      "(1000, 80)\n",
      "epoch=680, loss=4.2966857107124925\n",
      "(1000, 80)\n",
      "epoch=681, loss=4.296547844811517\n",
      "(1000, 80)\n",
      "epoch=682, loss=4.296409702944186\n",
      "(1000, 80)\n",
      "epoch=683, loss=4.296271283301307\n",
      "(1000, 80)\n",
      "epoch=684, loss=4.296132584065777\n",
      "(1000, 80)\n",
      "epoch=685, loss=4.29599360341256\n",
      "(1000, 80)\n",
      "epoch=686, loss=4.295854339508647\n",
      "(1000, 80)\n",
      "epoch=687, loss=4.2957147905130295\n",
      "(1000, 80)\n",
      "epoch=688, loss=4.29557495457667\n",
      "(1000, 80)\n",
      "epoch=689, loss=4.295434829842471\n",
      "(1000, 80)\n",
      "epoch=690, loss=4.2952944144452445\n",
      "(1000, 80)\n",
      "epoch=691, loss=4.295153706511685\n",
      "(1000, 80)\n",
      "epoch=692, loss=4.295012704160332\n",
      "(1000, 80)\n",
      "epoch=693, loss=4.294871405501554\n",
      "(1000, 80)\n",
      "epoch=694, loss=4.2947298086375065\n",
      "(1000, 80)\n",
      "epoch=695, loss=4.294587911662109\n",
      "(1000, 80)\n",
      "epoch=696, loss=4.294445712661014\n",
      "(1000, 80)\n",
      "epoch=697, loss=4.2943032097115825\n",
      "(1000, 80)\n",
      "epoch=698, loss=4.294160400882853\n",
      "(1000, 80)\n",
      "epoch=699, loss=4.2940172842355055\n",
      "(1000, 80)\n",
      "epoch=700, loss=4.293873857821849\n",
      "(1000, 80)\n",
      "epoch=701, loss=4.293730119685782\n",
      "(1000, 80)\n",
      "epoch=702, loss=4.293586067862771\n",
      "(1000, 80)\n",
      "epoch=703, loss=4.293441700379815\n",
      "(1000, 80)\n",
      "epoch=704, loss=4.293297015255431\n",
      "(1000, 80)\n",
      "epoch=705, loss=4.2931520104996155\n",
      "(1000, 80)\n",
      "epoch=706, loss=4.293006684113825\n",
      "(1000, 80)\n",
      "epoch=707, loss=4.292861034090947\n",
      "(1000, 80)\n",
      "epoch=708, loss=4.2927150584152765\n",
      "(1000, 80)\n",
      "epoch=709, loss=4.292568755062483\n",
      "(1000, 80)\n",
      "epoch=710, loss=4.2924221219995955\n",
      "(1000, 80)\n",
      "epoch=711, loss=4.292275157184971\n",
      "(1000, 80)\n",
      "epoch=712, loss=4.2921278585682705\n",
      "(1000, 80)\n",
      "epoch=713, loss=4.291980224090433\n",
      "(1000, 80)\n",
      "epoch=714, loss=4.2918322516836565\n",
      "(1000, 80)\n",
      "epoch=715, loss=4.291683939271368\n",
      "(1000, 80)\n",
      "epoch=716, loss=4.291535284768205\n",
      "(1000, 80)\n",
      "epoch=717, loss=4.291386286079989\n",
      "(1000, 80)\n",
      "epoch=718, loss=4.291236941103701\n",
      "(1000, 80)\n",
      "epoch=719, loss=4.291087247727466\n",
      "(1000, 80)\n",
      "epoch=720, loss=4.290937203830524\n",
      "(1000, 80)\n",
      "epoch=721, loss=4.29078680728321\n",
      "(1000, 80)\n",
      "epoch=722, loss=4.290636055946934\n",
      "(1000, 80)\n",
      "epoch=723, loss=4.290484947674158\n",
      "(1000, 80)\n",
      "epoch=724, loss=4.29033348030838\n",
      "(1000, 80)\n",
      "epoch=725, loss=4.2901816516841045\n",
      "(1000, 80)\n",
      "epoch=726, loss=4.290029459626832\n",
      "(1000, 80)\n",
      "epoch=727, loss=4.289876901953035\n",
      "(1000, 80)\n",
      "epoch=728, loss=4.289723976470141\n",
      "(1000, 80)\n",
      "epoch=729, loss=4.289570680976511\n",
      "(1000, 80)\n",
      "epoch=730, loss=4.28941701326142\n",
      "(1000, 80)\n",
      "epoch=731, loss=4.289262971105049\n",
      "(1000, 80)\n",
      "epoch=732, loss=4.289108552278457\n",
      "(1000, 80)\n",
      "epoch=733, loss=4.288953754543568\n",
      "(1000, 80)\n",
      "epoch=734, loss=4.288798575653156\n",
      "(1000, 80)\n",
      "epoch=735, loss=4.288643013350826\n",
      "(1000, 80)\n",
      "epoch=736, loss=4.288487065371002\n",
      "(1000, 80)\n",
      "epoch=737, loss=4.288330729438912\n",
      "(1000, 80)\n",
      "epoch=738, loss=4.288174003270571\n",
      "(1000, 80)\n",
      "epoch=739, loss=4.288016884572765\n",
      "(1000, 80)\n",
      "epoch=740, loss=4.287859371043045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 80)\n",
      "epoch=741, loss=4.287701460369708\n",
      "(1000, 80)\n",
      "epoch=742, loss=4.287543150231789\n",
      "(1000, 80)\n",
      "epoch=743, loss=4.287384438299043\n",
      "(1000, 80)\n",
      "epoch=744, loss=4.287225322231941\n",
      "(1000, 80)\n",
      "epoch=745, loss=4.287065799681655\n",
      "(1000, 80)\n",
      "epoch=746, loss=4.286905868290048\n",
      "(1000, 80)\n",
      "epoch=747, loss=4.286745525689664\n",
      "(1000, 80)\n",
      "epoch=748, loss=4.286584769503722\n",
      "(1000, 80)\n",
      "epoch=749, loss=4.286423597346107\n",
      "(1000, 80)\n",
      "epoch=750, loss=4.2862620068213575\n",
      "(1000, 80)\n",
      "epoch=751, loss=4.286099995524664\n",
      "(1000, 80)\n",
      "epoch=752, loss=4.285937561041857\n",
      "(1000, 80)\n",
      "epoch=753, loss=4.285774700949412\n",
      "(1000, 80)\n",
      "epoch=754, loss=4.2856114128144265\n",
      "(1000, 80)\n",
      "epoch=755, loss=4.2854476941946285\n",
      "(1000, 80)\n",
      "epoch=756, loss=4.285283542638374\n",
      "(1000, 80)\n",
      "epoch=757, loss=4.285118955684626\n",
      "(1000, 80)\n",
      "epoch=758, loss=4.284953930862979\n",
      "(1000, 80)\n",
      "epoch=759, loss=4.284788465693633\n",
      "(1000, 80)\n",
      "epoch=760, loss=4.284622557687402\n",
      "(1000, 80)\n",
      "epoch=761, loss=4.2844562043457115\n",
      "(1000, 80)\n",
      "epoch=762, loss=4.284289403160603\n",
      "(1000, 80)\n",
      "epoch=763, loss=4.284122151614727\n",
      "(1000, 80)\n",
      "epoch=764, loss=4.283954447181347\n",
      "(1000, 80)\n",
      "epoch=765, loss=4.283786287324347\n",
      "(1000, 80)\n",
      "epoch=766, loss=4.283617669498225\n",
      "(1000, 80)\n",
      "epoch=767, loss=4.283448591148105\n",
      "(1000, 80)\n",
      "epoch=768, loss=4.28327904970973\n",
      "(1000, 80)\n",
      "epoch=769, loss=4.283109042609485\n",
      "(1000, 80)\n",
      "epoch=770, loss=4.28293856726438\n",
      "(1000, 80)\n",
      "epoch=771, loss=4.282767621082075\n",
      "(1000, 80)\n",
      "epoch=772, loss=4.282596201460881\n",
      "(1000, 80)\n",
      "epoch=773, loss=4.282424305789759\n",
      "(1000, 80)\n",
      "epoch=774, loss=4.282251931448342\n",
      "(1000, 80)\n",
      "epoch=775, loss=4.282079075806942\n",
      "(1000, 80)\n",
      "epoch=776, loss=4.281905736226549\n",
      "(1000, 80)\n",
      "epoch=777, loss=4.281731910058857\n",
      "(1000, 80)\n",
      "epoch=778, loss=4.281557594646263\n",
      "(1000, 80)\n",
      "epoch=779, loss=4.28138278732189\n",
      "(1000, 80)\n",
      "epoch=780, loss=4.281207485409592\n",
      "(1000, 80)\n",
      "epoch=781, loss=4.281031686223972\n",
      "(1000, 80)\n",
      "epoch=782, loss=4.2808553870704\n",
      "(1000, 80)\n",
      "epoch=783, loss=4.2806785852450195\n",
      "(1000, 80)\n",
      "epoch=784, loss=4.280501278034773\n",
      "(1000, 80)\n",
      "epoch=785, loss=4.280323462717419\n",
      "(1000, 80)\n",
      "epoch=786, loss=4.280145136561538\n",
      "(1000, 80)\n",
      "epoch=787, loss=4.279966296826573\n",
      "(1000, 80)\n",
      "epoch=788, loss=4.2797869407628255\n",
      "(1000, 80)\n",
      "epoch=789, loss=4.279607065611497\n",
      "(1000, 80)\n",
      "epoch=790, loss=4.279426668604696\n",
      "(1000, 80)\n",
      "epoch=791, loss=4.279245746965468\n",
      "(1000, 80)\n",
      "epoch=792, loss=4.279064297907814\n",
      "(1000, 80)\n",
      "epoch=793, loss=4.278882318636719\n",
      "(1000, 80)\n",
      "epoch=794, loss=4.278699806348174\n",
      "(1000, 80)\n",
      "epoch=795, loss=4.278516758229201\n",
      "(1000, 80)\n",
      "epoch=796, loss=4.278333171457885\n",
      "(1000, 80)\n",
      "epoch=797, loss=4.278149043203393\n",
      "(1000, 80)\n",
      "epoch=798, loss=4.2779643706260115\n",
      "(1000, 80)\n",
      "epoch=799, loss=4.2777791508771665\n",
      "(1000, 80)\n",
      "epoch=800, loss=4.27759338109946\n",
      "(1000, 80)\n",
      "epoch=801, loss=4.2774070584267\n",
      "(1000, 80)\n",
      "epoch=802, loss=4.277220179983929\n",
      "(1000, 80)\n",
      "epoch=803, loss=4.277032742887459\n",
      "(1000, 80)\n",
      "epoch=804, loss=4.276844744244907\n",
      "(1000, 80)\n",
      "epoch=805, loss=4.276656181155224\n",
      "(1000, 80)\n",
      "epoch=806, loss=4.2764670507087335\n",
      "(1000, 80)\n",
      "epoch=807, loss=4.2762773499871685\n",
      "(1000, 80)\n",
      "epoch=808, loss=4.276087076063708\n",
      "(1000, 80)\n",
      "epoch=809, loss=4.27589622600301\n",
      "(1000, 80)\n",
      "epoch=810, loss=4.275704796861259\n",
      "(1000, 80)\n",
      "epoch=811, loss=4.275512785686192\n",
      "(1000, 80)\n",
      "epoch=812, loss=4.275320189517156\n",
      "(1000, 80)\n",
      "epoch=813, loss=4.275127005385137\n",
      "(1000, 80)\n",
      "epoch=814, loss=4.274933230312802\n",
      "(1000, 80)\n",
      "epoch=815, loss=4.274738861314548\n",
      "(1000, 80)\n",
      "epoch=816, loss=4.274543895396542\n",
      "(1000, 80)\n",
      "epoch=817, loss=4.274348329556767\n",
      "(1000, 80)\n",
      "epoch=818, loss=4.274152160785063\n",
      "(1000, 80)\n",
      "epoch=819, loss=4.2739553860631805\n",
      "(1000, 80)\n",
      "epoch=820, loss=4.273758002364822\n",
      "(1000, 80)\n",
      "epoch=821, loss=4.273560006655689\n",
      "(1000, 80)\n",
      "epoch=822, loss=4.273361395893533\n",
      "(1000, 80)\n",
      "epoch=823, loss=4.273162167028207\n",
      "(1000, 80)\n",
      "epoch=824, loss=4.272962317001713\n",
      "(1000, 80)\n",
      "epoch=825, loss=4.27276184274825\n",
      "(1000, 80)\n",
      "epoch=826, loss=4.272560741194271\n",
      "(1000, 80)\n",
      "epoch=827, loss=4.272359009258532\n",
      "(1000, 80)\n",
      "epoch=828, loss=4.2721566438521466\n",
      "(1000, 80)\n",
      "epoch=829, loss=4.271953641878642\n",
      "(1000, 80)\n",
      "epoch=830, loss=4.271750000234007\n",
      "(1000, 80)\n",
      "epoch=831, loss=4.271545715806757\n",
      "(1000, 80)\n",
      "epoch=832, loss=4.271340785477982\n",
      "(1000, 80)\n",
      "epoch=833, loss=4.271135206121405\n",
      "(1000, 80)\n",
      "epoch=834, loss=4.27092897460345\n",
      "(1000, 80)\n",
      "epoch=835, loss=4.27072208778328\n",
      "(1000, 80)\n",
      "epoch=836, loss=4.2705145425128785\n",
      "(1000, 80)\n",
      "epoch=837, loss=4.270306335637089\n",
      "(1000, 80)\n",
      "epoch=838, loss=4.270097463993691\n",
      "(1000, 80)\n",
      "epoch=839, loss=4.269887924413454\n",
      "(1000, 80)\n",
      "epoch=840, loss=4.269677713720197\n",
      "(1000, 80)\n",
      "epoch=841, loss=4.269466828730859\n",
      "(1000, 80)\n",
      "epoch=842, loss=4.269255266255552\n",
      "(1000, 80)\n",
      "epoch=843, loss=4.26904302309763\n",
      "(1000, 80)\n",
      "epoch=844, loss=4.268830096053756\n",
      "(1000, 80)\n",
      "epoch=845, loss=4.268616481913958\n",
      "(1000, 80)\n",
      "epoch=846, loss=4.268402177461707\n",
      "(1000, 80)\n",
      "epoch=847, loss=4.268187179473966\n",
      "(1000, 80)\n",
      "epoch=848, loss=4.26797148472127\n",
      "(1000, 80)\n",
      "epoch=849, loss=4.267755089967794\n",
      "(1000, 80)\n",
      "epoch=850, loss=4.267537991971407\n",
      "(1000, 80)\n",
      "epoch=851, loss=4.26732018748375\n",
      "(1000, 80)\n",
      "epoch=852, loss=4.2671016732503055\n",
      "(1000, 80)\n",
      "epoch=853, loss=4.266882446010461\n",
      "(1000, 80)\n",
      "epoch=854, loss=4.266662502497583\n",
      "(1000, 80)\n",
      "epoch=855, loss=4.2664418394390795\n",
      "(1000, 80)\n",
      "epoch=856, loss=4.26622045355648\n",
      "(1000, 80)\n",
      "epoch=857, loss=4.265998341565501\n",
      "(1000, 80)\n",
      "epoch=858, loss=4.265775500176113\n",
      "(1000, 80)\n",
      "epoch=859, loss=4.26555192609262\n",
      "(1000, 80)\n",
      "epoch=860, loss=4.265327616013726\n",
      "(1000, 80)\n",
      "epoch=861, loss=4.265102566632612\n",
      "(1000, 80)\n",
      "epoch=862, loss=4.264876774636997\n",
      "(1000, 80)\n",
      "epoch=863, loss=4.264650236709227\n",
      "(1000, 80)\n",
      "epoch=864, loss=4.264422949526334\n",
      "(1000, 80)\n",
      "epoch=865, loss=4.264194909760115\n",
      "(1000, 80)\n",
      "epoch=866, loss=4.263966114077212\n",
      "(1000, 80)\n",
      "epoch=867, loss=4.2637365591391685\n",
      "(1000, 80)\n",
      "epoch=868, loss=4.26350624160252\n",
      "(1000, 80)\n",
      "epoch=869, loss=4.263275158118862\n",
      "(1000, 80)\n",
      "epoch=870, loss=4.263043305334925\n",
      "(1000, 80)\n",
      "epoch=871, loss=4.262810679892647\n",
      "(1000, 80)\n",
      "epoch=872, loss=4.262577278429251\n",
      "(1000, 80)\n",
      "epoch=873, loss=4.262343097577313\n",
      "(1000, 80)\n",
      "epoch=874, loss=4.262108133964852\n",
      "(1000, 80)\n",
      "epoch=875, loss=4.261872384215387\n",
      "(1000, 80)\n",
      "epoch=876, loss=4.2616358449480245\n",
      "(1000, 80)\n",
      "epoch=877, loss=4.26139851277753\n",
      "(1000, 80)\n",
      "epoch=878, loss=4.261160384314397\n",
      "(1000, 80)\n",
      "epoch=879, loss=4.260921456164937\n",
      "(1000, 80)\n",
      "epoch=880, loss=4.260681724931337\n",
      "(1000, 80)\n",
      "epoch=881, loss=4.2604411872117485\n",
      "(1000, 80)\n",
      "epoch=882, loss=4.260199839600356\n",
      "(1000, 80)\n",
      "epoch=883, loss=4.259957678687452\n",
      "(1000, 80)\n",
      "epoch=884, loss=4.259714701059514\n",
      "(1000, 80)\n",
      "epoch=885, loss=4.259470903299282\n",
      "(1000, 80)\n",
      "epoch=886, loss=4.259226281985826\n",
      "(1000, 80)\n",
      "epoch=887, loss=4.258980833694628\n",
      "(1000, 80)\n",
      "epoch=888, loss=4.258734554997652\n",
      "(1000, 80)\n",
      "epoch=889, loss=4.258487442463421\n",
      "(1000, 80)\n",
      "epoch=890, loss=4.258239492657089\n",
      "(1000, 80)\n",
      "epoch=891, loss=4.257990702140517\n",
      "(1000, 80)\n",
      "epoch=892, loss=4.25774106747235\n",
      "(1000, 80)\n",
      "epoch=893, loss=4.25749058520808\n",
      "(1000, 80)\n",
      "epoch=894, loss=4.257239251900133\n",
      "(1000, 80)\n",
      "epoch=895, loss=4.256987064097934\n",
      "(1000, 80)\n",
      "epoch=896, loss=4.256734018347977\n",
      "(1000, 80)\n",
      "epoch=897, loss=4.256480111193913\n",
      "(1000, 80)\n",
      "epoch=898, loss=4.2562253391765985\n",
      "(1000, 80)\n",
      "epoch=899, loss=4.255969698834194\n",
      "(1000, 80)\n",
      "epoch=900, loss=4.255713186702215\n",
      "(1000, 80)\n",
      "epoch=901, loss=4.255455799313611\n",
      "(1000, 80)\n",
      "epoch=902, loss=4.255197533198843\n",
      "(1000, 80)\n",
      "epoch=903, loss=4.2549383848859454\n",
      "(1000, 80)\n",
      "epoch=904, loss=4.254678350900594\n",
      "(1000, 80)\n",
      "epoch=905, loss=4.254417427766193\n",
      "(1000, 80)\n",
      "epoch=906, loss=4.254155612003922\n",
      "(1000, 80)\n",
      "epoch=907, loss=4.2538929001328265\n",
      "(1000, 80)\n",
      "epoch=908, loss=4.253629288669869\n",
      "(1000, 80)\n",
      "epoch=909, loss=4.2533647741300085\n",
      "(1000, 80)\n",
      "epoch=910, loss=4.253099353026269\n",
      "(1000, 80)\n",
      "epoch=911, loss=4.2528330218698\n",
      "(1000, 80)\n",
      "epoch=912, loss=4.252565777169949\n",
      "(1000, 80)\n",
      "epoch=913, loss=4.25229761543433\n",
      "(1000, 80)\n",
      "epoch=914, loss=4.25202853316888\n",
      "(1000, 80)\n",
      "epoch=915, loss=4.251758526877941\n",
      "(1000, 80)\n",
      "epoch=916, loss=4.25148759306431\n",
      "(1000, 80)\n",
      "epoch=917, loss=4.2512157282293135\n",
      "(1000, 80)\n",
      "epoch=918, loss=4.25094292887287\n",
      "(1000, 80)\n",
      "epoch=919, loss=4.250669191493554\n",
      "(1000, 80)\n",
      "epoch=920, loss=4.250394512588657\n",
      "(1000, 80)\n",
      "epoch=921, loss=4.250118888654253\n",
      "(1000, 80)\n",
      "epoch=922, loss=4.2498423161852665\n",
      "(1000, 80)\n",
      "epoch=923, loss=4.249564791675523\n",
      "(1000, 80)\n",
      "epoch=924, loss=4.249286311617822\n",
      "(1000, 80)\n",
      "epoch=925, loss=4.249006872503996\n",
      "(1000, 80)\n",
      "epoch=926, loss=4.248726470824963\n",
      "(1000, 80)\n",
      "epoch=927, loss=4.248445103070799\n",
      "(1000, 80)\n",
      "epoch=928, loss=4.248162765730792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 80)\n",
      "epoch=929, loss=4.247879455293502\n",
      "(1000, 80)\n",
      "epoch=930, loss=4.247595168246818\n",
      "(1000, 80)\n",
      "epoch=931, loss=4.247309901078023\n",
      "(1000, 80)\n",
      "epoch=932, loss=4.247023650273846\n",
      "(1000, 80)\n",
      "epoch=933, loss=4.246736412320525\n",
      "(1000, 80)\n",
      "epoch=934, loss=4.2464481837038575\n",
      "(1000, 80)\n",
      "epoch=935, loss=4.246158960909268\n",
      "(1000, 80)\n",
      "epoch=936, loss=4.2458687404218525\n",
      "(1000, 80)\n",
      "epoch=937, loss=4.245577518726447\n",
      "(1000, 80)\n",
      "epoch=938, loss=4.245285292307668\n",
      "(1000, 80)\n",
      "epoch=939, loss=4.2449920576499895\n",
      "(1000, 80)\n",
      "epoch=940, loss=4.244697811237777\n",
      "(1000, 80)\n",
      "epoch=941, loss=4.244402549555352\n",
      "(1000, 80)\n",
      "epoch=942, loss=4.244106269087047\n",
      "(1000, 80)\n",
      "epoch=943, loss=4.243808966317262\n",
      "(1000, 80)\n",
      "epoch=944, loss=4.243510637730507\n",
      "(1000, 80)\n",
      "epoch=945, loss=4.243211279811467\n",
      "(1000, 80)\n",
      "epoch=946, loss=4.242910889045052\n",
      "(1000, 80)\n",
      "epoch=947, loss=4.242609461916447\n",
      "(1000, 80)\n",
      "epoch=948, loss=4.242306994911167\n",
      "(1000, 80)\n",
      "epoch=949, loss=4.242003484515111\n",
      "(1000, 80)\n",
      "epoch=950, loss=4.241698927214613\n",
      "(1000, 80)\n",
      "epoch=951, loss=4.241393319496489\n",
      "(1000, 80)\n",
      "epoch=952, loss=4.241086657848101\n",
      "(1000, 80)\n",
      "epoch=953, loss=4.240778938757394\n",
      "(1000, 80)\n",
      "epoch=954, loss=4.2404701587129585\n",
      "(1000, 80)\n",
      "epoch=955, loss=4.240160314204076\n",
      "(1000, 80)\n",
      "epoch=956, loss=4.239849401720778\n",
      "(1000, 80)\n",
      "epoch=957, loss=4.2395374177538825\n",
      "(1000, 80)\n",
      "epoch=958, loss=4.239224358795063\n",
      "(1000, 80)\n",
      "epoch=959, loss=4.23891022133689\n",
      "(1000, 80)\n",
      "epoch=960, loss=4.238595001872876\n",
      "(1000, 80)\n",
      "epoch=961, loss=4.238278696897543\n",
      "(1000, 80)\n",
      "epoch=962, loss=4.237961302906461\n",
      "(1000, 80)\n",
      "epoch=963, loss=4.237642816396302\n",
      "(1000, 80)\n",
      "epoch=964, loss=4.237323233864891\n",
      "(1000, 80)\n",
      "epoch=965, loss=4.237002551811265\n",
      "(1000, 80)\n",
      "epoch=966, loss=4.236680766735708\n",
      "(1000, 80)\n",
      "epoch=967, loss=4.23635787513982\n",
      "(1000, 80)\n",
      "epoch=968, loss=4.23603387352656\n",
      "(1000, 80)\n",
      "epoch=969, loss=4.2357087584003015\n",
      "(1000, 80)\n",
      "epoch=970, loss=4.235382526266876\n",
      "(1000, 80)\n",
      "epoch=971, loss=4.23505517363364\n",
      "(1000, 80)\n",
      "epoch=972, loss=4.234726697009514\n",
      "(1000, 80)\n",
      "epoch=973, loss=4.234397092905048\n",
      "(1000, 80)\n",
      "epoch=974, loss=4.23406635783246\n",
      "(1000, 80)\n",
      "epoch=975, loss=4.233734488305707\n",
      "(1000, 80)\n",
      "epoch=976, loss=4.2334014808405245\n",
      "(1000, 80)\n",
      "epoch=977, loss=4.233067331954488\n",
      "(1000, 80)\n",
      "epoch=978, loss=4.232732038167067\n",
      "(1000, 80)\n",
      "epoch=979, loss=4.232395595999682\n",
      "(1000, 80)\n",
      "epoch=980, loss=4.232058001975754\n",
      "(1000, 80)\n",
      "epoch=981, loss=4.231719252620769\n",
      "(1000, 80)\n",
      "epoch=982, loss=4.231379344462329\n",
      "(1000, 80)\n",
      "epoch=983, loss=4.231038274030214\n",
      "(1000, 80)\n",
      "epoch=984, loss=4.230696037856434\n",
      "(1000, 80)\n",
      "epoch=985, loss=4.230352632475295\n",
      "(1000, 80)\n",
      "epoch=986, loss=4.2300080544234495\n",
      "(1000, 80)\n",
      "epoch=987, loss=4.229662300239964\n",
      "(1000, 80)\n",
      "epoch=988, loss=4.229315366466378\n",
      "(1000, 80)\n",
      "epoch=989, loss=4.228967249646761\n",
      "(1000, 80)\n",
      "epoch=990, loss=4.228617946327781\n",
      "(1000, 80)\n",
      "epoch=991, loss=4.228267453058761\n",
      "(1000, 80)\n",
      "epoch=992, loss=4.227915766391746\n",
      "(1000, 80)\n",
      "epoch=993, loss=4.227562882881566\n",
      "(1000, 80)\n",
      "epoch=994, loss=4.2272087990859015\n",
      "(1000, 80)\n",
      "epoch=995, loss=4.226853511565354\n",
      "(1000, 80)\n",
      "epoch=996, loss=4.226497016883501\n",
      "(1000, 80)\n",
      "epoch=997, loss=4.226139311606976\n",
      "(1000, 80)\n",
      "epoch=998, loss=4.225780392305532\n",
      "(1000, 80)\n",
      "epoch=999, loss=4.225420255552112\n",
      "(1000, 80)\n",
      "epoch=1000, loss=4.2250588979229144\n",
      "(1000, 80)\n",
      "epoch=1001, loss=4.224696315997474\n",
      "(1000, 80)\n",
      "epoch=1002, loss=4.224332506358727\n",
      "(1000, 80)\n",
      "epoch=1003, loss=4.2239674655930886\n",
      "(1000, 80)\n",
      "epoch=1004, loss=4.223601190290525\n",
      "(1000, 80)\n",
      "epoch=1005, loss=4.223233677044627\n",
      "(1000, 80)\n",
      "epoch=1006, loss=4.222864922452694\n",
      "(1000, 80)\n",
      "epoch=1007, loss=4.222494923115806\n",
      "(1000, 80)\n",
      "epoch=1008, loss=4.2221236756389\n",
      "(1000, 80)\n",
      "epoch=1009, loss=4.221751176630856\n",
      "(1000, 80)\n",
      "epoch=1010, loss=4.2213774227045775\n",
      "(1000, 80)\n",
      "epoch=1011, loss=4.221002410477066\n",
      "(1000, 80)\n",
      "epoch=1012, loss=4.220626136569518\n",
      "(1000, 80)\n",
      "epoch=1013, loss=4.220248597607391\n",
      "(1000, 80)\n",
      "epoch=1014, loss=4.21986979022051\n",
      "(1000, 80)\n",
      "epoch=1015, loss=4.219489711043136\n",
      "(1000, 80)\n",
      "epoch=1016, loss=4.2191083567140675\n",
      "(1000, 80)\n",
      "epoch=1017, loss=4.218725723876721\n",
      "(1000, 80)\n",
      "epoch=1018, loss=4.218341809179227\n",
      "(1000, 80)\n",
      "epoch=1019, loss=4.217956609274519\n",
      "(1000, 80)\n",
      "epoch=1020, loss=4.217570120820424\n",
      "(1000, 80)\n",
      "epoch=1021, loss=4.217182340479767\n",
      "(1000, 80)\n",
      "epoch=1022, loss=4.216793264920452\n",
      "(1000, 80)\n",
      "epoch=1023, loss=4.216402890815571\n",
      "(1000, 80)\n",
      "epoch=1024, loss=4.216011214843497\n",
      "(1000, 80)\n",
      "epoch=1025, loss=4.215618233687978\n",
      "(1000, 80)\n",
      "epoch=1026, loss=4.215223944038254\n",
      "(1000, 80)\n",
      "epoch=1027, loss=4.2148283425891355\n",
      "(1000, 80)\n",
      "epoch=1028, loss=4.214431426041129\n",
      "(1000, 80)\n",
      "epoch=1029, loss=4.21403319110053\n",
      "(1000, 80)\n",
      "epoch=1030, loss=4.213633634479525\n",
      "(1000, 80)\n",
      "epoch=1031, loss=4.213232752896309\n",
      "(1000, 80)\n",
      "epoch=1032, loss=4.212830543075191\n",
      "(1000, 80)\n",
      "epoch=1033, loss=4.212427001746697\n",
      "(1000, 80)\n",
      "epoch=1034, loss=4.212022125647687\n",
      "(1000, 80)\n",
      "epoch=1035, loss=4.211615911521466\n",
      "(1000, 80)\n",
      "epoch=1036, loss=4.211208356117901\n",
      "(1000, 80)\n",
      "epoch=1037, loss=4.2107994561935245\n",
      "(1000, 80)\n",
      "epoch=1038, loss=4.210389208511666\n",
      "(1000, 80)\n",
      "epoch=1039, loss=4.209977609842557\n",
      "(1000, 80)\n",
      "epoch=1040, loss=4.2095646569634555\n",
      "(1000, 80)\n",
      "epoch=1041, loss=4.209150346658765\n",
      "(1000, 80)\n",
      "epoch=1042, loss=4.208734675720155\n",
      "(1000, 80)\n",
      "epoch=1043, loss=4.208317640946684\n",
      "(1000, 80)\n",
      "epoch=1044, loss=4.207899239144923\n",
      "(1000, 80)\n",
      "epoch=1045, loss=4.2074794671290805\n",
      "(1000, 80)\n",
      "epoch=1046, loss=4.207058321721126\n",
      "(1000, 80)\n",
      "epoch=1047, loss=4.206635799750924\n",
      "(1000, 80)\n",
      "epoch=1048, loss=4.206211898056355\n",
      "(1000, 80)\n",
      "epoch=1049, loss=4.20578661348345\n",
      "(1000, 80)\n",
      "epoch=1050, loss=4.205359942886518\n",
      "(1000, 80)\n",
      "epoch=1051, loss=4.204931883128282\n",
      "(1000, 80)\n",
      "epoch=1052, loss=4.20450243108001\n",
      "(1000, 80)\n",
      "epoch=1053, loss=4.20407158362165\n",
      "(1000, 80)\n",
      "epoch=1054, loss=4.203639337641964\n",
      "(1000, 80)\n",
      "epoch=1055, loss=4.203205690038665\n",
      "(1000, 80)\n",
      "epoch=1056, loss=4.202770637718558\n",
      "(1000, 80)\n",
      "epoch=1057, loss=4.202334177597675\n",
      "(1000, 80)\n",
      "epoch=1058, loss=4.201896306601418\n",
      "(1000, 80)\n",
      "epoch=1059, loss=4.201457021664695\n",
      "(1000, 80)\n",
      "epoch=1060, loss=4.20101631973207\n",
      "(1000, 80)\n",
      "epoch=1061, loss=4.200574197757896\n",
      "(1000, 80)\n",
      "epoch=1062, loss=4.200130652706468\n",
      "(1000, 80)\n",
      "epoch=1063, loss=4.199685681552166\n",
      "(1000, 80)\n",
      "epoch=1064, loss=4.199239281279597\n",
      "(1000, 80)\n",
      "epoch=1065, loss=4.198791448883744\n",
      "(1000, 80)\n",
      "epoch=1066, loss=4.1983421813701165\n",
      "(1000, 80)\n",
      "epoch=1067, loss=4.197891475754896\n",
      "(1000, 80)\n",
      "epoch=1068, loss=4.19743932906509\n",
      "(1000, 80)\n",
      "epoch=1069, loss=4.196985738338675\n",
      "(1000, 80)\n",
      "epoch=1070, loss=4.196530700624759\n",
      "(1000, 80)\n",
      "epoch=1071, loss=4.1960742129837225\n"
     ]
    }
   ],
   "source": [
    "loss = CategoricalCrossEntropyLoss()\n",
    "lr_initial=0.1\n",
    "#optimizer = SGDOptimizer(lr_schedule=LRConstantSchedule(lr_initial))\n",
    "\n",
    "n_epochs = 10000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    scores = rnn.forward(x)\n",
    "    #print(a.shape)\n",
    "    data_loss = loss.compute_loss(scores, y)\n",
    "    print(f\"epoch={epoch}, loss={data_loss}\")\n",
    "    params_train = {\"mode\": \"train\", \"seed\": None}\n",
    "    rnn.backward(loss.grad(), **params_train)\n",
    "\n",
    "    trainable_params=rnn.get_learnable_params()\n",
    "    grads=rnn.get_learnable_params_grads()\n",
    "\n",
    "    for k,v in trainable_params.items():\n",
    "        trainable_params[k] = deepcopy(v - lr_initial * grads[\"d\"+k])\n",
    "\n",
    "    rnn.set_learnable_params(**trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "(1, 80)\n",
      "(80,)\n",
      "ri-YHge4Qs?\"Eoxr:joN 9Ac0g474•xr6lTw(u}ZYC0T):\tH9,Jbtkv?Adyo2,/h\"KqtJsd\"d3AX^!A?tSv?YM'hyqHmCX^zuü61\n"
     ]
    }
   ],
   "source": [
    "synhthetizer = Synhthetizer(rnn, onehot_encoder)\n",
    "sequence= synhthetizer(ts=100, init_idx=1)\n",
    "print(\"\".join(hpdata.decode(sequence.flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_blocks_env",
   "language": "python",
   "name": "nn_blocks_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
