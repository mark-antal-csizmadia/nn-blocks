[![build](https://github.com/mark-antal-csizmadia/nn-blocks/actions/workflows/main.yml/badge.svg)](https://github.com/mark-antal-csizmadia/nn-blocks/actions/workflows/main.yml)

# nn-blocks

A neural network library built from scratch, without dedicated deep learning packages. Training and testing deep neural networks and utilizing deep learning best practices for multi-class classification with fully connected neural networks and text generation with recurrent neural networks.

- one-layer:
    + one layer networks (hinge and cross ent)
    + dynamics of lr and l2 on performance (no search)

- two-layer:
    + two layer cross ent
    + xavier init
    + cyclical lr schedule
    + ada grad?
    + search with hyperopt
    
- k-layer with bn
    + k-layer
    + all data
    + bn
    + dropout
    + imgaug
    
- rnn
    + rnn stuff
    + grad clip and loss smoothing
    
- regression
    + regression stuff
